/****************************************************************************
*
*    Copyright (c) 2005 - 2019 by Vivante Corp.  All rights reserved.
*
*    The material in this file is confidential and contains trade secrets
*    of Vivante Corporation. This is proprietary information owned by
*    Vivante Corporation. No part of this work may be disclosed,
*    reproduced, copied, transmitted, or used in any way for any purpose,
*    without the express written permission of Vivante Corporation.
*
*****************************************************************************/


#include <gc_vx_common.h>
#if gcdUSE_VXC_BINARY
#include "nnvxc_binary_interface.h"
#endif
#include <gc_vx_layer.h>
#include <gc_vx_nn_util.h>

#define _GC_OBJ_ZONE            gcdZONE_VX_LAYER

#define IMG_MAX_WIDTH 65536
#define SHADER_THREAD_COUNT  (4)
#define MAX_MULTIPLIER_NUM      (65535)
#define MAX_POST_SHIFT_BITS     (31)

#define _vxcFILENAME_MAX 1024

#if gcdUSE_VXC_BINARY
static void * getVXCKernelInfo(vx_context context, nnvxc_kernel_enum type, vx_uint32_ptr len)
{
    gceSTATUS status = gcvSTATUS_OK;

    GetBinaryPtr_FUNC funcHandle = VX_NULL;
    status = gcoOS_GetProcAddress(gcvNULL, context->libNNVXCKernelHandle, "GetBinaryPtr", &funcHandle);
    if (status != gcvSTATUS_OK)
    {
        vxError("Can't get binary pointer!\n");
        return VX_NULL;
    }

    void *ptr = funcHandle(type, len);

    return ptr;
}
#endif
vx_char* loadSources(const vx_char *filename, vx_size *programSize)
{
    FILE *pFile = NULL;
    vx_char *programSource = NULL;

    gcmHEADER_ARG("filename=%s, programSize=%p", filename, programSize);

    pFile = fopen(filename, "rb");
    if (pFile != NULL && programSize)
    {
        vx_int32 size = 0;
        /* obtain file size:*/
        fseek(pFile, 0, SEEK_END);
        *programSize = ftell(pFile);
        rewind(pFile);

        size = (int)(*programSize + 1);
        programSource = (char*)vxAllocateAndZeroMemory(sizeof(char)*(size));
        if (programSource == NULL)
        {
            fclose(pFile);
            vxFree(programSource);
            gcmFOOTER_NO();
            return NULL;
        }

        fread(programSource, sizeof(char), *programSize, pFile);
        programSource[*programSize] = '\0';
        fclose(pFile);
    }
    else
    {
        vxError("[%s line %d] Open %s failed.\n", __FILE__, __LINE__, filename);
        fclose(pFile);
    }

    gcmFOOTER_ARG("programSource=%s", programSource);
    return programSource;
}

vx_status getFilePath(const char subfix[], char path[])
{
    char* env = gcvNULL;
    gcmHEADER_ARG("subfix=%s, path=%s", subfix, path);
    gcoOS_GetEnv(gcvNULL, "VIVANTE_SDK_DIR", &env);

    if (env) {
        vx_size len;
        len = gcoOS_StrLen(env, gcvNULL);
        gcoOS_StrCopySafe(path, len + 1, env);

        gcoOS_StrCatSafe(path, _vxcFILENAME_MAX, "/");
        gcoOS_StrCatSafe(path, _vxcFILENAME_MAX, subfix);
        gcmFOOTER_ARG("%d", VX_SUCCESS);
        return VX_SUCCESS;
    }
    else
    {
        vxError("Error: Make sure the environment variable VIVANTE_SDK_DIR is set to the same directory when compiling and executing.\n");
        gcmFOOTER_ARG("%d", VX_FAILURE);
        return VX_FAILURE;
    }
}

/********vxcBatchNormalization****************************************************/
vxnne_shader_executable vxnneGetBatchNormShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               weights,
    vx_tensor               biases,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference    parameters[4]              = {(vx_reference)input, (vx_reference)weights, (vx_reference)biases, (vx_reference)output};
    vx_uint32       dims                       = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32       width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32       height                     = (dims > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32       depth                      = (dims > 2) ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_uint32       batch                      = (dims > 3) ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_enum         inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum         outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int32        input_ZP                   = TENSOR_TF_ZEROPOINT(input);
    vx_tensor       input_rs                   = NULL;
    vx_tensor       output_rs                  = NULL;
    vx_int32        sizes[4]                   = {1, 1, 1, 1};
    vx_bool         useImage2DFlag             = (vx_bool)(width * height < IMG_MAX_WIDTH);
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, weights=%p, biases=%p, output=%p", context, kernelEnum, borderMode, input, weights, biases, output);

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        input_ZP       = 0;
    }
    else if (inputFormat == VX_TYPE_FLOAT16)
    {
        input_ZP       = 0;
    }

    if (useImage2DFlag)
    {
        sizes[0] = width * height;
        sizes[1] = depth;
        sizes[2] = 1;
        sizes[3] = batch;

        input_rs = vxoTensor_ReshapeTensor(input, sizes, dims);
        output_rs = vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)input_rs;
        parameters[3] = (vx_reference)output_rs;
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, BatchNorm, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/BatchNorm.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        vxmONERROR(vxGetStatus((vx_reference)program));

        vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension"));

        vxmONERROR_NULLPTR(kernel = vxnneAddKernelShadersInProgram(context, "vxcBatchNorm", program, 4, kernelEnum));

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
    {
        vx_uint32 uniInt8toFp32Part0_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8toFp32Part1_4x4[16] = {
            0x03030303, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8toFp32Part2_4x4[16] = {
            0x03030303, // TCfg
            0x04040404, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8toFp32Part3_4x4[16] = {
            0x03030303, // TCfg
            0x04040404, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8toFp32Part0_4x4", 1, uniInt8toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8toFp32Part1_4x4", 1, uniInt8toFp32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8toFp32Part2_4x4", 1, uniInt8toFp32Part2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8toFp32Part3_4x4", 1, uniInt8toFp32Part3_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniFp16toFp32Part0_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32Part1_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32Part0_4x4", 1, uniFp16toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32Part1_4x4", 1, uniFp16toFp32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int16_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint32 uniUInt8toFp32Part0_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8toFp32Part1_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8toFp32Part2_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8toFp32Part3_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part0_4x4", 1, uniUInt8toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part1_4x4", 1, uniUInt8toFp32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part2_4x4", 1, uniUInt8toFp32Part2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part3_4x4", 1, uniUInt8toFp32Part3_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_zeroPoint", 1, &input_ZP);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat != outputFormat)
    {
        char kernelName[1024];
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part0_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part1_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        switch (inputFormat)
        {
        case VX_TYPE_FLOAT16:
            sprintf(kernelName, "_Fp16");
            break;
        case VX_TYPE_INT8:
            sprintf(kernelName, "_Int8");
            break;
        case VX_TYPE_UINT8:
            sprintf(kernelName, "_UInt8");
            break;
        case VX_TYPE_INT16:
            sprintf(kernelName, "_Int16");
            break;
        default:
            break;
        }

        switch (outputFormat)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "toFp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "toInt8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "toUInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "toInt16" );
            break;
        default:
            break;
        }

        if (useImage2DFlag)
        {
            strcat(kernelName, "_2D" );

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 1;
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_zeroPoint", 1, &input_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part0_4x4", 1, uniDataSubZPtoFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part1_4x4", 1, uniDataSubZPtoFp32Part1_4x4);
        if (outputFormat == VX_TYPE_FLOAT16)
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtractHalf8_2x8);
        else
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);

        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("shaderExecutable=%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReorg****************************************************/
vxnne_shader_executable vxnneGetReorgShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               stride,
    vx_scalar               outc,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]              = {(vx_reference)input, (vx_reference)stride, (vx_reference)outc, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int8       input_fractionLengthValue  = TENSOR_POS(input);
    vx_int8       output_fractionLengthValue = TENSOR_POS(output);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_float32    heighto_scale              = 1.0f / (vx_float32)output_height;
    vx_int8       div_fractionLengthValue    = output_fractionLengthValue - input_fractionLengthValue;
    vx_float32    div_scale                  = 1.0f;
    vx_uint32     factor                     = 1;
    vx_uint32     maxWorkGroupSize           = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, stride=%p, outc=%p, output=%p", context, kernelEnum, borderMode, input, stride, outc, output);

    if ((inputFormat != VX_TYPE_FLOAT16 && inputFormat != VX_TYPE_INT8) || (outputFormat != VX_TYPE_FLOAT16 && outputFormat != VX_TYPE_INT8))
    {
        vxError("input or output's format is not support");
        goto OnError;
    }
    if (div_fractionLengthValue >= 0)
    {
        div_scale = (vx_float32) (1 << div_fractionLengthValue);
    }
    else
    {
        div_scale = 1.0f / (vx_float32) (1 << -div_fractionLengthValue);
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Reorg, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Reorg.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcReorg", program, 4, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }
    if (inputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 UniPackFP16even_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 UniPackFP16odd_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x07050301, 0x07050301, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 UniFp16xFp16toS8_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_for0str2Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_for0str2Fp16toInt8", borderMode);
            if (!shaderExecutable) goto OnError;
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16xFp16toS8_dp2x8", 1, UniFp16xFp16toS8_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackFP16even_2x8", 1, UniPackFP16even_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackFP16odd_2x8", 1, UniPackFP16odd_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else
    {
        vx_uint32 UniPackS8even_dp2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniPackS8odd_dp2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x07050301, 0x07050301, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniS8xFp16_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_for0str2Int8toFp16", borderMode);
            if (!shaderExecutable) goto OnError;
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16_dp2x8", 1, UniS8xFp16_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_for0str2Int8toInt8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackS8even_dp2x8", 1, UniPackS8even_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackS8odd_dp2x8", 1, UniPackS8odd_dp2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "height_in", 1, &input_height);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "height_out", 1, &output_height);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "heighto_scale", 1, &heighto_scale);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "div_scale", 1, &div_scale);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 16;
    execution_parameters.globalWorkScale[1]  = 2;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.localWorkSize[0]    = 1;
    execution_parameters.localWorkSize[1]    = 1;
    if (input_depth <= maxWorkGroupSize)
        execution_parameters.localWorkSize[2]    = input_depth;
    else if (checkGetDataFactor(input_depth, &factor, 2, maxWorkGroupSize, 8) == VX_SUCCESS)
        execution_parameters.localWorkSize[2]    = factor;
    else
        execution_parameters.localWorkSize[2]    = 1;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((input_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]);
    execution_parameters.globalWorkSize[1]   = gcmALIGN((input_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    execution_parameters.globalWorkSize[2]   = input_depth;


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("shaderExecutable=%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcRnn****************************************/
vxnne_shader_executable vxnneGetRnnShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               bias,
    vx_tensor               weight,
    vx_tensor               hidden,
    vx_tensor               recurrent,
    vx_tensor               activation,
    vx_tensor               state_out,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[8]              = {(vx_reference)input, (vx_reference)weight, (vx_reference)recurrent, (vx_reference)bias, (vx_reference)hidden, (vx_reference)activation, (vx_reference)state_out, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_enum       biasFormat                 = TENSOR_DATA_TYPE(bias);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(weight, 1);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_int32      output_ZP                  = TENSOR_TF_ZEROPOINT(output);
    vx_int32      input_ZP                   = TENSOR_TF_ZEROPOINT(input);
    vx_int32      bias_ZP                    = TENSOR_TF_ZEROPOINT(bias);
    vx_int32      weight_ZP                  = TENSOR_TF_ZEROPOINT(weight);
    vx_int32      hidden_ZP                  = TENSOR_TF_ZEROPOINT(hidden);
    vx_int32      recurrent_ZP               = TENSOR_TF_ZEROPOINT(recurrent);
    vx_float32    inputScale                 = TENSOR_TF_SCALE(input);
    vx_float32    biasScale                  = TENSOR_TF_SCALE(bias);
    vx_float32    weightScale                = TENSOR_TF_SCALE(weight);
    vx_float32    hiddenScale                = TENSOR_TF_SCALE(hidden);
    vx_float32    recurrentScale             = TENSOR_TF_SCALE(recurrent);
    vx_float32    outputScale                = TENSOR_TF_SCALE(output);
    vx_tensor     bias_rs                    = NULL;
    vx_tensor     act_rs                     = NULL;
    vx_int32      bs_sizes[4]                = {1, 1, 1, 1};
    vx_uint32     bs_dims                    = TENSOR_DIM_NUM(bias);
    vx_uint32     bs_dims_rs                 = TENSOR_DIM_NUM(bias) == 1 ? 2 : TENSOR_DIM_NUM(bias);
    vx_int32      act_sizes[4]               = {1, 1, 1, 1};
    vx_uint32     act_dims                   = TENSOR_DIM_NUM(activation);
    vx_uint32     act_dims_rs                = TENSOR_DIM_NUM(activation) == 1 ? 2 : TENSOR_DIM_NUM(activation);
    vx_uint32     i                          = 0;
    char *programSources = NULL;

     gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, hidden=%p, recurrent=%p, activation=%p, state_out=%p, output=%p",
         context, kernelEnum, borderMode, input, hidden, recurrent, activation, state_out, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    if (((inputFormat != VX_TYPE_FLOAT16) && (inputFormat != VX_TYPE_FLOAT32) && (inputFormat != VX_TYPE_UINT8)) ||
        ((outputFormat != VX_TYPE_FLOAT16) && (outputFormat != VX_TYPE_FLOAT32) && (outputFormat != VX_TYPE_UINT8))
        )
    {
        vxError("input or output's format is not support");
        goto OnError;
    }

    if (bs_dims == 1)
    {
        for(i = 0; i < bs_dims; ++i)
        {
            bs_sizes[0] *= TENSOR_VIEW_SIZE_INDEX(bias, i);
        }
        bias_rs = vxoTensor_ReshapeTensor(bias, bs_sizes, bs_dims_rs);
        parameters[3] = (vx_reference)bias_rs;
    }

    if (act_dims == 1)
    {
        for(i = 0; i < act_dims; ++i)
        {
            act_sizes[0] *= TENSOR_VIEW_SIZE_INDEX(activation, i);
        }
        act_rs = vxoTensor_ReshapeTensor(activation, act_sizes, act_dims_rs);
        parameters[5] = (vx_reference)act_rs;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;

    if ((inputFormat == VX_TYPE_UINT8) && (outputFormat == VX_TYPE_UINT8))
        execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((output_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (output_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Rnn, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Rnn.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcRnn", program, 8, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniMulAccAddFp16Fp16_8x2[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvertFstFp16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        vx_uint32 uniConvertUint8ToFp32_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertSubZpUint8Fp32_4x4[16] = {
            0x09090905, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0xbc003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((inputFormat == VX_TYPE_FLOAT32) && (outputFormat == VX_TYPE_FLOAT32))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp32", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if ((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16))
        {
            if (biasFormat == VX_TYPE_FLOAT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_row4", borderMode);
            else
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_biasFp32_row4", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if ((inputFormat == VX_TYPE_UINT8) && (outputFormat == VX_TYPE_UINT8))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            goto OnError;
        }

        if ((inputFormat == VX_TYPE_UINT8) && (outputFormat == VX_TYPE_UINT8))
        {
            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8ToFp32_4x4", 1, uniConvertUint8ToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSubZpUint8Fp32_4x4", 1, uniConvertSubZpUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias_ZP", 1, &bias_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "weight_ZP", 1, &weight_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "hidden_ZP", 1, &hidden_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "recurrent_ZP", 1, &recurrent_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &inputScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "biasScale", 1, &biasScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "weightScale", 1, &weightScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "hiddenScale", 1, &hiddenScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "recurrentScale", 1, &recurrentScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAccAddFp16Fp16_8x2", 1, uniMulAccAddFp16Fp16_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertFstFp16Fp32_4x4", 1, uniConvertFstFp16Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_size", 1, &input_width);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_size", 1, &output_width);

        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 8);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (act_rs) vxoTensor_ReleaseTensor(&act_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (act_rs) vxoTensor_ReleaseTensor(&act_rs);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcSvdf****************************************/
vxnne_shader_executable vxnneGetSvdfShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               bias,
    vx_tensor               weight,
    vx_tensor               recurrent,
    vx_tensor               activation,
    vx_tensor               rank,
    vx_tensor               state_in,
    vx_tensor               state_out,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[9]              = {(vx_reference)input, (vx_reference)bias, (vx_reference)weight, (vx_reference)recurrent, (vx_reference)activation,
                                                (vx_reference)rank, (vx_reference)state_in, (vx_reference)state_out, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_enum       biasFormat                 = TENSOR_DATA_TYPE(bias);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    //vx_uint32     num_filter                 = TENSOR_VIEW_SIZE_INDEX(weight, 1);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     memory_size                = TENSOR_VIEW_SIZE_INDEX(recurrent, 0);
    vx_uint32     stride_state               = TENSOR_VIEW_SIZE_INDEX(state_in, 0);
    vx_tensor     bias_rs                    = NULL;
    vx_tensor     act_rs                     = NULL;
    vx_tensor     rank_rs                    = NULL;
    vx_int32      bs_sizes[4]                = {1, 1, 1, 1};
    vx_uint32     bs_dims                    = TENSOR_DIM_NUM(bias);
    vx_int32      act_sizes[4]               = {1, 1, 1, 1};
    vx_uint32     act_dims                   = TENSOR_DIM_NUM(activation);
    vx_uint32     rank_dims                  = TENSOR_DIM_NUM(rank);
    vx_uint32     memory_size_minus1         = memory_size - 1;
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(output, 0);
    char *programSources = NULL;

   gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, bias=%p, weight=%p, output=%p",
         context, kernelEnum, borderMode, input, bias, weight, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    if (!((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16)))
    {
        vxError("input or output's format is not support");
        goto OnError;
    }

    if (bs_dims == 1)
    {
        bs_sizes[0] = TENSOR_VIEW_SIZE_INDEX(bias, 0);
        bias_rs = vxoTensor_ReshapeTensor(bias, bs_sizes, 2);
        parameters[1] = (vx_reference)bias_rs;
    }

    if (act_dims == 1)
    {
        act_sizes[0] = TENSOR_VIEW_SIZE_INDEX(activation, 0);
        act_rs = vxoTensor_ReshapeTensor(activation, act_sizes, 2);
        parameters[4] = (vx_reference)act_rs;
    }

    if(rank_dims == 1)
    {
        act_sizes[0] = TENSOR_VIEW_SIZE_INDEX(rank, 0);
        rank_rs = vxoTensor_ReshapeTensor(rank, act_sizes, 2);
        parameters[5] = (vx_reference)rank_rs;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((output_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (output_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Svdf, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Svdf.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcSvdf", program, 9, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniMulAccAddFp16Fp16_8x2[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16) && (biasFormat == VX_TYPE_FLOAT16))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if ((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16) && (biasFormat == VX_TYPE_FLOAT32))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_biasFp32", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            goto OnError;
        }
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAccAddFp16Fp16_8x2", 1, uniMulAccAddFp16Fp16_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_size", 1, &input_width);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "memory_size", 1, &memory_size);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "memory_size_minus1", 1, &memory_size_minus1);
        //status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "rank", 1, &rank);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, &stride_state);

        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 9);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (act_rs) vxoTensor_ReleaseTensor(&act_rs);
    if (rank_rs) vxoTensor_ReleaseTensor(&rank_rs);
    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (act_rs) vxoTensor_ReleaseTensor(&act_rs);
    if (rank_rs) vxoTensor_ReleaseTensor(&rank_rs);

    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReverse****************************************/
vxnne_shader_executable vxnneGetReverseShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               output,
    vx_uint32               axsisNum,
    vx_uint32*              axsis
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]              = {(vx_reference)input, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_uint32     channel                    = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     height                     = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      rs_sizes[4]                = {1, 1, 1, 1};
    vx_uint32     cur_axis_sz_sub8           = width - 8;
    vx_uint32     cur_axis_sz_sub16          = width - 16;
    vx_uint32     cur_axis_sz_sub1           = 0;
    vx_uint32     cur_axis1_sz_sub1          = 0;
    vx_uint32     cur_axis2_sz_sub1          = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);
    borderMode->mode = VX_BORDER_REPLICATE;

    if (dims == 1)
    {
        rs_sizes[0]   = width;
        input_rs      = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        output_rs     = vxoTensor_ReshapeTensor(output, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;
    }

    if (axsis[0] == 1)
        cur_axis_sz_sub1 = height - 1;
    else if (axsis[0] == 2)
        cur_axis_sz_sub1 = channel - 1;

    if (axsis[1] == 1)
        cur_axis1_sz_sub1 = height - 1;
    else if (axsis[1] == 2)
        cur_axis1_sz_sub1 = channel - 1;

    if (axsis[2] == 1)
        cur_axis2_sz_sub1 = height - 1;
    else if (axsis[2] == 2)
        cur_axis2_sz_sub1 = channel - 1;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Reverse, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Reverse.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorReverse", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
    {
        if (axsisNum == 1)
        {
            if (axsis[0] == 0)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis0_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub8", 1, &cur_axis_sz_sub8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 1)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis1_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis2_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }
        }
        else if (axsisNum == 2)
        {
            if (axsis[0] == 0 && axsis[1] == 1)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis01_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub8", 1, &cur_axis_sz_sub8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 0 && axsis[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis02_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub8", 1, &cur_axis_sz_sub8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 1 && axsis[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis12_16bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis1_sz_sub1", 1, &cur_axis1_sz_sub1);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (axsisNum == 3)
        {
            if (axsis[0] == 0 && axsis[1] == 1 && axsis[2] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis012_16bits", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub8", 1, &cur_axis_sz_sub8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis1_sz_sub1", 1, &cur_axis1_sz_sub1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis2_sz_sub1", 1, &cur_axis2_sz_sub1);
            if (status != VX_SUCCESS) goto OnError;
        }

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if ((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
    {
        if (axsisNum == 1)
        {
            if (axsis[0] == 0)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis0_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub16", 1, &cur_axis_sz_sub16);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 1)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis1_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis2_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }
        }
        else if (axsisNum == 2)
        {
            if (axsis[0] == 0 && axsis[1] == 1)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis01_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub16", 1, &cur_axis_sz_sub16);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 0 && axsis[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis02_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub16", 1, &cur_axis_sz_sub16);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (axsis[0] == 1 && axsis[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis12_8bits", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub1", 1, &cur_axis_sz_sub1);
                if (status != VX_SUCCESS) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis1_sz_sub1", 1, &cur_axis1_sz_sub1);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (axsisNum == 3)
        {
            if (axsis[0] == 0 && axsis[1] == 1 && axsis[2] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_axis012_8bits", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis_sz_sub16", 1, &cur_axis_sz_sub16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis1_sz_sub1", 1, &cur_axis1_sz_sub1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "cur_axis2_sz_sub1", 1, &cur_axis2_sz_sub1);
            if (status != VX_SUCCESS) goto OnError;
        }

        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }


    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = channel;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcFloor****************************************/
vxnne_shader_executable vxnneGetFloorShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               mode,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]              = {(vx_reference)input, (vx_reference)mode, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      in_sizes[4]                = {1, 1, 1, 1};
    vx_uint32     in_dims                    = TENSOR_DIM_NUM(input);
    vx_int32      out_sizes[4]               = {1, 1, 1, 1};
    vx_uint32     out_dims                   = TENSOR_DIM_NUM(output);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(input, 2);
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    if (!((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16)))
    {
        vxError("input or output's format is not support");
        goto OnError;
    }

    if (in_dims == 1)
    {
        in_sizes[0] = TENSOR_VIEW_SIZE_INDEX(input, 0);
        input_rs = vxoTensor_ReshapeTensor(input, in_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (out_dims == 1)
    {
        out_sizes[0] = TENSOR_VIEW_SIZE_INDEX(output, 0);
        output_rs = vxoTensor_ReshapeTensor(output, out_sizes, 2);
        parameters[2] = (vx_reference)output_rs;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 8;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((input_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (input_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = input_depth;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Floor, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Floor.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcFloor", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniConvertFstFp16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertSecFp16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((inputFormat == VX_TYPE_FLOAT16) && (outputFormat == VX_TYPE_FLOAT16))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertFstFp16Fp32_4x4", 1, &uniConvertFstFp16Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSecFp16Fp32_4x4", 1, &uniConvertSecFp16Fp32_4x4);

        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReorg2 Space2Depth****************************************/
vxnne_shader_executable vxnneGetSpace2DepthShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               stride,
    vx_scalar               outc,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]              = {(vx_reference)input, (vx_reference)stride, (vx_reference)outc, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     input_batch                = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32     input_dimz                 = 0;

    vx_float32    uint8_zp                   = 0.0f;
    vx_float32    uint8_scale                = 0.0f;
    vx_float32    out_scale                  = 1.0f;
    vx_float32    in_scale                   = TENSOR_TF_SCALE(input);
    vx_int32      in_zeros_point             = TENSOR_TF_ZEROPOINT(input);
    vx_int32      out_zeros_point            = TENSOR_TF_ZEROPOINT(output);
    vx_bool       sameFlg                    = vx_true_e;
    vx_uint32     block_size                 = stride->value->u32;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;

    if (!((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
       || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
       || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
       || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        )
    {
        vxError("input or output's format is not support(space to depth)");
        goto OnError;
    }

    input_batch = (input_batch == 0) ? 1 : input_batch;
    input_dimz = input_batch * input_depth;

    out_scale = TENSOR_TF_SCALE(output);
    uint8_scale = in_scale / out_scale;
    uint8_zp = out_zeros_point - in_zeros_point * uint8_scale;

    if (out_scale != in_scale || out_zeros_point != in_zeros_point)
        sameFlg = vx_false_e;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    if (block_size == 2)
    {
        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;

        if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
            execution_parameters.globalWorkScale[0]  = 8;
    }
    else
    {
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    execution_parameters.globalWorkSize[0]   = gcmALIGN((input_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (input_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = input_dimz;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Space2Depth, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Space2Depth.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcReorg2", program, 4, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
    {
        vx_uint32 uniConvertDirUint8Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertEndUint8Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniExtractEvenUint8Stride2_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x06040200, 0x0e0c0a08, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000700, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };
        vx_uint32 uniExtractOddUint8Stride2_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x07050301, 0x0f0d0b09, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000700, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        if (sameFlg && block_size == 2)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_stride2_noFl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (block_size == 2)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_stride2", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (sameFlg)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_general_noFl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_general", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirUint8Fp32_4x4", 1, uniConvertDirUint8Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndUint8Fp32_4x4", 1, uniConvertEndUint8Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractEvenUint8Stride2_2x8", 1, uniExtractEvenUint8Stride2_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractOddUint8Stride2_2x8", 1, uniExtractOddUint8Stride2_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "block_size", 1, &block_size);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpScale", 1, &uint8_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZP", 1, &uint8_zp);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
    {
        vx_uint32 uniExtractEvenFp16Stride2_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniExtractOddFp16Stride2_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00030001, 0x00070005, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };

        if (block_size == 2)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_fp16_stride2", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_fp16_general", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractEvenFp16Stride2_4x4", 1, uniExtractEvenFp16Stride2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractOddFp16Stride2_4x4", 1, uniExtractOddFp16Stride2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "block_size", 1, &block_size);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReorg2 Depth2Space****************************************/
vxnne_shader_executable vxnneGetDepth2SpaceShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               block_sizes,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]              = {(vx_reference)input, (vx_reference)block_sizes, (vx_reference)output};
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32     output_depth               = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_float32    in_scale                   = TENSOR_TF_SCALE(input);
    vx_int32      in_zeros_point             = TENSOR_TF_ZEROPOINT(input);
    vx_float32    out_scale                  = TENSOR_TF_SCALE(output);
    vx_int32      out_zeros_point            = TENSOR_TF_ZEROPOINT(output);
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     block_size                 = block_sizes->value->u32;

    vx_float32    divScale                   = in_scale / out_scale;
    vx_float32    cbZP                       = out_zeros_point - in_zeros_point * divScale;
    vx_int32      outDepth2x                 = output_depth * 2;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Depth2Space, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Depth2Space.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcReorg2", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniU8toFp32Lo_dp4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt32toUint8_dp2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackU8EvenOdd_dp2x8[16] = {
            0x33333333, // TCfg
            0x10101010, // ASelt
            0x01010000, 0x03030202, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackS16EvenOdd_dp2x8[16] = {
            0x33333333, // TCfg
            0x10101010, // ASelt
            0x01010000, 0x03030202, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (block_size == 2 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && in_scale == out_scale && in_zeros_point == out_zeros_point)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceU8toU8Block2_sp", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (block_size == 2 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceU8toU8Block2", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && in_scale == out_scale && in_zeros_point == out_zeros_point)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceU8toU8Generic_sp", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceU8toU8Generic", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (block_size == 2 && inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceF16toF16Block2", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Depth2SpaceF16toF16Generic", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8toFp32Lo_dp4x4", 1, uniU8toFp32Lo_dp4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt32toUint8_dp2x8", 1, uniInt32toUint8_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackU8EvenOdd_dp2x8", 1, uniPackU8EvenOdd_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "divScale", 1, &divScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "cbZP", 1, &cbZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outDepth", 1, &output_depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outDepth2x", 1, &outDepth2x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackS16EvenOdd_dp2x8", 1, uniPackS16EvenOdd_dp2x8);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    if (block_size == 2)
    {
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 2;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else
    {
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }

    execution_parameters.globalWorkSize[0]   = gcmALIGN((output_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (output_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = output_depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReorg2 Space2Batch****************************************/
vxnne_shader_executable vxnneGetSpace2BatchShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               stride,
    vx_tensor               pad,
    vx_scalar               outc,
    vx_tensor               output,
    vx_uint32*              padList)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[5]              = {(vx_reference)input, (vx_reference)stride, (vx_reference)pad, (vx_reference)output, (vx_reference)outc};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     input_batch                = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32     output_dim                 = TENSOR_DIM_NUM(output);
    vx_uint32     stride_dim                 = TENSOR_DIM_NUM(stride);
    vx_uint32     pad_dim                    = TENSOR_DIM_NUM(pad);
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32     output_depth               = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32     output_batch               = TENSOR_VIEW_SIZE_INDEX(output, 3);
    vx_uint32     stride_width               = TENSOR_VIEW_SIZE_INDEX(stride, 0);
    vx_uint32     pad_width                  = TENSOR_VIEW_SIZE_INDEX(pad, 0);
    vx_uint32     input_dimz                 = 0;
    vx_int32      sizes[4]                   = {output_width, output_height, output_depth * output_batch, 1};

    vx_float32    uint8_zp                   = 0.0f;
    vx_float32    uint8_scale                = 0.0f;
    vx_float32    out_scale                  = 1.0f;
    vx_float32    in_scale                   = TENSOR_TF_SCALE(input);
    vx_int32      in_zeros_point             = TENSOR_TF_ZEROPOINT(input);
    vx_int32      out_zeros_point            = TENSOR_TF_ZEROPOINT(output);
    vx_bool       sameFlg                    = vx_true_e;
    vx_tensor     output_rs                  = NULL;
    vx_tensor     stride_rs                  = NULL;
    vx_tensor     pad_rs                     = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;

    if (!((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
       || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
       || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
       || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        )
    {
        vxError("input or output's format is not support(space to depth)");
        goto OnError;
    }

    input_batch = (input_batch == 0) ? 1 : input_batch;
    input_dimz = input_batch * input_depth;

    if (output_dim == 4)
    {
        output_rs        = vxoTensor_ReshapeTensor(output, sizes, 3);
        parameters[3]    = (vx_reference)output_rs;
    }

    if (stride_dim == 1)
    {
        sizes[0] = stride_width;
        sizes[1] = 1;
        sizes[2] = 1;
        sizes[3] = 1;
        stride_rs        = vxoTensor_ReshapeTensor(stride, sizes, 2);
        parameters[1]    = (vx_reference)stride_rs;
    }

    if (pad_dim == 1)
    {
        sizes[0] = pad_width;
        sizes[1] = 1;
        sizes[2] = 1;
        sizes[3] = 1;
        pad_rs        = vxoTensor_ReshapeTensor(pad, sizes, 2);
        parameters[2]    = (vx_reference)pad_rs;
    }

    out_scale = TENSOR_TF_SCALE(output);
    uint8_scale = in_scale / out_scale;
    uint8_zp = out_zeros_point - in_zeros_point * uint8_scale;

    if (out_scale != in_scale || out_zeros_point != in_zeros_point)
        sameFlg = vx_false_e;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0] = input_width + padList[0] + padList[1];
    execution_parameters.globalWorkSize[1] = input_height + padList[2] + padList[3];
    execution_parameters.globalWorkSize[2]   = input_dimz;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Space2Batch, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Space2Batch.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcSpace2Batch", program, 5, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
    {
        if (sameFlg)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_general_noFl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_uint8_general", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpScale", 1, &uint8_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZP", 1, &uint8_zp);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_width", 1, &input_width);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_height", 1, &input_height);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_fp16_general", borderMode);
        if (!shaderExecutable) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 5);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (stride_rs) vxoTensor_ReleaseTensor(&stride_rs);
    if (pad_rs) vxoTensor_ReleaseTensor(&pad_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (stride_rs) vxoTensor_ReleaseTensor(&stride_rs);
    if (pad_rs) vxoTensor_ReleaseTensor(&pad_rs);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcReorg2 Batch2Space****************************************/
vxnne_shader_executable vxnneGetBatch2SpaceShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               stride,
    vx_tensor               pad,
    vx_scalar               outc,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]              = {(vx_reference)input, (vx_reference)stride, (vx_reference)output, (vx_reference)outc};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     input_batch                = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32     input_dim                  = TENSOR_DIM_NUM(input);
    vx_uint32     output_dim                 = TENSOR_DIM_NUM(output);
    vx_uint32     stride_dim                 = TENSOR_DIM_NUM(stride);
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32     output_depth               = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32     output_batch               = TENSOR_VIEW_SIZE_INDEX(output, 3);
    vx_uint32     stride_width               = TENSOR_VIEW_SIZE_INDEX(stride, 0);
    vx_uint32     input_dimz                 = 0;
    vx_int32      sizes[4]                   = {output_width, output_height, output_depth * output_batch, 1};

    vx_float32    uint8_zp                   = 0.0f;
    vx_float32    uint8_scale                = 0.0f;
    vx_float32    out_scale                  = 1.0f;
    vx_float32    in_scale                   = TENSOR_TF_SCALE(input);
    vx_int32      in_zeros_point             = TENSOR_TF_ZEROPOINT(input);
    vx_int32      out_zeros_point            = TENSOR_TF_ZEROPOINT(output);
    vx_bool       sameFlg                    = vx_true_e;
    vx_tensor     input_rs                  = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_tensor     stride_rs                  = NULL;
    vx_tensor     pad_rs                     = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;

    if (!((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
       || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
       || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
       || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        )
    {
        vxError("input or output's format is not support(space to depth)");
        goto OnError;
    }

    input_batch = (input_batch == 0) ? 1 : input_batch;
    input_dimz = input_batch * input_depth;

    if (output_dim == 4)
    {
        output_rs        = vxoTensor_ReshapeTensor(output, sizes, 3);
        parameters[2]    = (vx_reference)output_rs;
    }

    if (input_dim == 4)
    {
        sizes[0] = input_width;
        sizes[1] = input_height;
        sizes[2] = input_depth * input_batch;
        sizes[3] = 1;
        input_rs        = vxoTensor_ReshapeTensor(input, sizes, 3);
        parameters[0]    = (vx_reference)input_rs;
    }

    if (stride_dim == 1)
    {
        sizes[0] = stride_width;
        sizes[1] = 1;
        sizes[2] = 1;
        sizes[3] = 1;
        stride_rs        = vxoTensor_ReshapeTensor(stride, sizes, 2);
        parameters[1]    = (vx_reference)stride_rs;
    }

    out_scale = TENSOR_TF_SCALE(output);
    uint8_scale = in_scale / out_scale;
    uint8_zp = out_zeros_point - in_zeros_point * uint8_scale;

    if (out_scale != in_scale || out_zeros_point != in_zeros_point)
        sameFlg = vx_false_e;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0]   = input_width;
    execution_parameters.globalWorkSize[1]   = input_height;
    execution_parameters.globalWorkSize[2]   = input_dimz;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Batch2Space, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Batch2Space.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcBatch2Space", program, 5, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
    {
        if (sameFlg)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8_u8_general_noFl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8_u8_general", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpScale", 1, &uint8_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZP", 1, &uint8_zp);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_fp16_general", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_width", 1, &output_width);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_height", 1, &output_height);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (stride_rs) vxoTensor_ReleaseTensor(&stride_rs);
    if (pad_rs) vxoTensor_ReleaseTensor(&pad_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (stride_rs) vxoTensor_ReleaseTensor(&stride_rs);
    if (pad_rs) vxoTensor_ReleaseTensor(&pad_rs);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcActivation****************************************************/
vxnne_shader_executable vxnneGetActivationShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_enum                 funcType,
    vx_tensor               input,
    vx_float32              minVal,
    vx_float32              maxVal,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference   parameters[2]    = {(vx_reference)input, (vx_reference)output};
    vx_enum        inputFormat      = TENSOR_DATA_TYPE(input);
    vx_enum        outputFormat     = TENSOR_DATA_TYPE(output);
    vx_uint32      width            = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32      height           = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32      depth            = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32      batch            = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32      dims             = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor      input_rs         = NULL;
    vx_tensor      output_rs        = NULL;
    vx_int8        srcFixPointPos   = TENSOR_POS(input);
    vx_int8        dstFixPointPos   = TENSOR_POS(output);
    vx_bool        useImage2DFlag   = (vx_bool)((width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH);
    vx_float32     scaleOut         = 1.0f;
    vx_float32     scaleIn          = 1.0f;
    vx_int32       sizes[4]         = {width * height, depth, 1, batch};
    vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
    vx_bool        enalbe_relu      = (vx_bool)(funcType == VX_NN_ACTIVATION_RELU || funcType == VX_NN_ACTIVATION_RELU1 || funcType == VX_NN_ACTIVATION_RELU6);
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    borderMode->mode = VX_BORDER_REPLICATE;
    input_rs         = vxoTensor_ReshapeTensor(input, sizes, dims);
    output_rs        = vxoTensor_ReshapeTensor(output, sizes, dims);

    if (useImage2DFlag)
    {
        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Activation, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/Activation.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "vxcActivation", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enalbe_relu && inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        vx_float32 scaleInt16toInt16 = scaleIn * scaleOut;
        vx_uint16 minData  = 0;
        vx_uint16 maxData  = 0;
        vx_int32 packedMin = (minData << 16) | (minData);
        vx_int32 packedMax = (maxData << 16) | (maxData);
        vx_int32 packedMinData[4];
        vx_int32 packedMaxData[4];
        vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        calculateActivationRangeInt16(funcType, dstFixPointPos, (vx_int16*)(&minData), (vx_int16*)(&maxData), VX_ROUND_POLICY_TO_NEAREST_EVEN);
        packedMin = (minData << 16) | (minData);
        packedMax = (maxData << 16) | (maxData);

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluInt16_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluInt16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinDataInt16", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxDataInt16", 1, packedMaxData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16", 1, &scaleInt16toInt16);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (funcType == VX_NN_ACTIVATION_RELU)
    {
        if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            vx_float32 scaleInt8toInt8 = scaleIn * scaleOut;
            vx_uint32 uniS8MulS16toFp16_2x8_lo[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniS8MulS16toFp16_2x8_hi[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x0b0a0908, 0x0f0e0d0c, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Int8toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8MulS16toFp16_2x8_lo", 1, uniS8MulS16toFp16_2x8_lo);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8MulS16toFp16_2x8_hi", 1, uniS8MulS16toFp16_2x8_hi);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8toInt8", 1, &scaleInt8toInt8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Fp16toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
        {
            vx_uint32 uniS16MulS16toInt8_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Fp16toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Fp16toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16MulS16toInt8_2x8", 1, uniS16MulS16toInt8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleOut", 1, &scaleOut);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniS8MulS16toFp16_2x8_lo[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniS8MulS16toFp16_2x8_hi[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x0b0a0908, 0x0f0e0d0c, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Int8toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Relu_Int8toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8MulS16toFp16_2x8_lo", 1, uniS8MulS16toFp16_2x8_lo);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8MulS16toFp16_2x8_hi", 1, uniS8MulS16toFp16_2x8_hi);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleIn", 1, &scaleIn);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (funcType == VX_NN_ACTIVATION_HYPERBOLIC_TAN)
    {
        float max2Val = maxVal * 2 * logE;
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            float minValArray[4];
            vx_uint32 uniunPackedF16MulF16Lo_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedF16MulF16Hi_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tanh_Fp16toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tanh_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            minValArray[0] = minValArray[1] = minValArray[2] = minValArray[3] = minVal;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedF16MulF16Lo_4x4", 1, uniunPackedF16MulF16Lo_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedF16MulF16Hi_4x4", 1, uniunPackedF16MulF16Hi_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "minVal", 1, minValArray);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxVal", 1, &max2Val);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            float scaleTanhIn_Int8toInt8  = scaleIn * max2Val;
            float scaleTanhOut_Int8toInt8 = scaleOut * minVal;
            vx_uint32 unPackedTanhData0to3_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 unPackedTanhData4to7_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 unPackedTanhData8to11_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00090008, 0x000b000a, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 unPackedTanhData12to15_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x000d000c, 0x000f000e, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractTanhHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tanh_Int8toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tanh_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "unPackedTanhData0to3_4x4", 1, unPackedTanhData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "unPackedTanhData4to7_4x4", 1, unPackedTanhData4to7_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "unPackedTanhData8to11_4x4", 1, unPackedTanhData8to11_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "unPackedTanhData12to15_4x4", 1, unPackedTanhData12to15_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractTanhHalf8_2x8", 1, uniExtractTanhHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleTanhIn_Int8toInt8", 1, &scaleTanhIn_Int8toInt8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleTanhOut_Int8toInt8", 1, &scaleTanhOut_Int8toInt8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        {
            float scaleInt16toInt16_In  = scaleIn * max2Val;
            float scaleInt16toInt16_Out = scaleOut * minVal;
            vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtact16Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_tanh_Int16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_tanh_Int16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_In", 1, &scaleInt16toInt16_In);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_Out", 1, &scaleInt16toInt16_Out);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (funcType == VX_NN_ACTIVATION_LOGISTIC)
    {
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniunPackedLoData_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x0000bc00, 0x00000000, 0x0000bc00, 0x00000000, 0x0000bc00, 0x00000000, 0x0000bc00, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedHiData_4x4[16] = {
                0x02020202, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sigmoid_Fp16toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sigmoid_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedLoData_4x4", 1, uniunPackedLoData_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedHiData_4x4", 1, uniunPackedHiData_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &logE);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            float scaleIn_Int8toInt8 = logE * scaleIn;
            vx_uint32 uniunPackedData8to11_4x4[16] = {
                0x02020202, // TCfg
                0x00000000, // ASelt
                0x00090008, 0x000b000a, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData4to7_4x4[16] = {
                0x02020202, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData12to15_4x4[16] = {
                0x02020202, // TCfg
                0x00000000, // ASelt
                0x000d000c, 0x000f000e, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData0to3_4x4[16] = {
                0x02020202, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sigmoid_Int8toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sigmoid_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData8to11_4x4", 1, uniunPackedData8to11_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData4to7_4x4", 1, uniunPackedData4to7_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData12to15_4x4", 1, uniunPackedData12to15_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData0to3_4x4", 1, uniunPackedData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleIn_Int8toInt8", 1, &scaleIn_Int8toInt8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleOut_Int8toInt8", 1, &scaleOut);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        {
            float scaleInt16toInt16_In  = scaleIn * logE;
            float scaleInt16toInt16_Out = scaleOut;
            vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtact16Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_sigmoid_Int16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_sigmoid_Int16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_In", 1, &scaleInt16toInt16_In);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_Out", 1, &scaleInt16toInt16_Out);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (funcType == VX_NN_ACTIVATION_SQRT || funcType == VX_NN_ACTIVATION_RSQRT)
    {
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniUnpackedLoFP32_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniUnpackedHiFP32_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sqrt_Fp16toFp16_2D", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Rsqrt_Fp16toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sqrt_Fp16toFp16", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Rsqrt_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedLoFP32_4x4", 1, uniUnpackedLoFP32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedHiFP32_4x4", 1, uniUnpackedHiFP32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &logE);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            vx_uint32 uniunPackedData0to3_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData4to7_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData8to11_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00090008, 0x000b000a, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniunPackedData12to15_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x000d000c, 0x000f000e, // ABin
                0x01010101, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (useImage2DFlag)
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sqrt_Int8toInt8_2D", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Rsqrt_Int8toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
            }
            else
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Sqrt_Int8toInt8", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Rsqrt_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData8to11_4x4", 1, uniunPackedData8to11_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData4to7_4x4", 1, uniunPackedData4to7_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData12to15_4x4", 1, uniunPackedData12to15_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniunPackedData0to3_4x4", 1, uniunPackedData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleIn_Int8toInt8", 1, &scaleIn);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleOut_Int8toInt8", 1, &scaleOut);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        {
            vx_float32 scaleInt16toInt16_In  = scaleIn;
            vx_float32 scaleInt16toInt16_Out = scaleOut;
            vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
                0x03030303, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtact16Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (useImage2DFlag)
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_sqrt_Int16_2D", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_rsqrt_Int16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                if (funcType == VX_NN_ACTIVATION_SQRT)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_sqrt_Int16", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_rsqrt_Int16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
            status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
            status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_In", 1, &scaleInt16toInt16_In);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_Out", 1, &scaleInt16toInt16_Out);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else
    {
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint16 minTmp   = 0;
            vx_uint16 maxTmp   = 0;
            vx_int32 packedMin = 0;
            vx_int32 packedMax = 0;
            vx_int32 packedMinData_FP16[4];
            vx_int32 packedMaxData_FP16[4];
            vx_int32 i;

            calculateActivationRangeFloat16(funcType, (vx_int16*)(&minTmp), (vx_int16*)(&maxTmp));
            packedMin = (minTmp << 16) | (minTmp);
            packedMax = (maxTmp << 16) | (maxTmp);

            for (i = 0;i < 4; i++)
            {
                packedMinData_FP16[i] = packedMin;
                packedMaxData_FP16[i] = packedMax;
            }

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluAtoB_Fp16toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluAtoB_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData_FP16", 1, packedMinData_FP16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData_FP16", 1, packedMaxData_FP16);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            vx_float32 scaleInt8toInt8 = scaleIn * scaleOut;
            vx_uint8 minData   = 0;
            vx_uint8 maxData   = 0;
            vx_int32 packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
            vx_int32 packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);
            vx_int32 packedMinData[4];
            vx_int32 packedMaxData[4];
            vx_uint32 uniInt8ScaletoInt8Lo_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniInt8ScaletoInt8Hi_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x0b0a0908, 0x0f0e0d0c, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            calculateActivationRangeInt8(funcType, dstFixPointPos, (vx_int8*)(&minData), (vx_int8*)(&maxData), VX_ROUND_POLICY_TO_NEAREST_EVEN);
            packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
            packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);

            packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
            packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

            if (useImage2DFlag)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluAtoB_Int8toInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.workDim             = 2;
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluAtoB_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8ScaletoInt8Lo_2x8", 1, uniInt8ScaletoInt8Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8ScaletoInt8Hi_2x8", 1, uniInt8ScaletoInt8Hi_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8toInt8", 1, &scaleInt8toInt8);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    if (useImage2DFlag)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcActivation_UInt8****************************************************/
vxnne_shader_executable vxnneGetActivation_UInt8ShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_enum                 funcType,
    vx_tensor               input,
    vx_float32              minVal,
    vx_float32              maxVal,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference   parameters[2]    = {(vx_reference)input, (vx_reference)output};
    vx_enum        inputFormat      = TENSOR_DATA_TYPE(input);
    vx_enum        outputFormat     = TENSOR_DATA_TYPE(output);
    vx_uint32      width            = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32      height           = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32      depth            = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32      batch            = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32      dims             = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor      input_rs         = NULL;
    vx_tensor      output_rs        = NULL;
    vx_int32       input_ZP         = TENSOR_TF_ZEROPOINT(input);
    vx_int32       output_ZP        = TENSOR_TF_ZEROPOINT(output);
    vx_int8        srcFixPointPos   = TENSOR_POS(input);
    vx_int8        dstFixPointPos   = TENSOR_POS(output);
    vx_bool        useImage2DFlag   = (vx_bool)((width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH);
    vx_float32     scaleOut         = 1.0f;
    vx_float32     scaleIn          = 1.0f;
    vx_int32       sizes[4]         = {width * height, depth, 1, batch};
    vx_bool        enalbe_relu      = (vx_bool)(funcType == VX_NN_ACTIVATION_RELU || funcType == VX_NN_ACTIVATION_RELU1 || funcType == VX_NN_ACTIVATION_RELU6 || funcType == VX_NN_ACTIVATION_BRELU);
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16 || inputFormat == VX_TYPE_UINT8)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }

        if (inputFormat == VX_TYPE_UINT8)
            scaleIn = TENSOR_TF_SCALE(input);
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16|| outputFormat == VX_TYPE_UINT8)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }

        if (outputFormat == VX_TYPE_UINT8)
            scaleOut = TENSOR_TF_SCALE(output);

    }

    borderMode->mode = VX_BORDER_REPLICATE;
    input_rs         = vxoTensor_ReshapeTensor(input, sizes, dims);
    output_rs        = vxoTensor_ReshapeTensor(output, sizes, dims);

    if (useImage2DFlag)
    {
        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Activation_UInt8, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Activation_UInt8.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcActivation", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enalbe_relu && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint8   minData          = 0;
        vx_uint8   maxData          = 0;
        vx_int32   packedMin        = 0;
        vx_int32   packedMax        = 0;
        vx_int32   packedMinData[4];
        vx_int32   packedMaxData[4];
        vx_float32 uint8Scale = scaleIn / scaleOut;
        vx_uint16  M0                   = 0;
        vx_int8    postShift            = 0;
        vx_uint32    multAndoutZP[2]    = {0};
        vx_uint32 uniU8MulAndPostShift_Lo_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x13121110, 0x17161514, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002600, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniU8MulAndPostShift_Hi_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x1b1a1918, 0x1f1e1d1c, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002600, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        getFP32M0AndN(uint8Scale, &M0, &postShift);
        multAndoutZP[0] = (vx_uint32)(M0);
        multAndoutZP[1] = (vx_uint32)((output_ZP << postShift) - input_ZP * M0);

        uniU8MulAndPostShift_Lo_2x8[7] |= (postShift & 0x1F);
        uniU8MulAndPostShift_Hi_2x8[7] |= (postShift & 0x1F);

        calculateActivationRangeUInt8(funcType, scaleOut, output_ZP, &minData, &maxData, minVal, maxVal);
        packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
        packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluUInt8_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ReluUInt8", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_Lo_2x8", 1, uniU8MulAndPostShift_Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_Hi_2x8", 1, uniU8MulAndPostShift_Hi_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (funcType == VX_NN_ACTIVATION_HYPERBOLIC_TAN || funcType == VX_NN_ACTIVATION_LOGISTIC || funcType == VX_NN_ACTIVATION_SQRT || funcType == VX_NN_ACTIVATION_RSQRT || funcType == VX_NN_ACTIVATION_SOFTRELU)
    {
        vx_float32 logE              = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32 uint8scale_In     = scaleIn;
        vx_float32 uint8qscale_Out   = 1 / scaleOut;
        vx_int32   uint8ZP_In        = input_ZP;
        vx_float32 uint8ZP_Out       = (vx_float32)output_ZP;
        char kernelName[100];
        vx_uint32  uniUInt8toFp32Part0_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8toFp32Part1_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (funcType == VX_NN_ACTIVATION_HYPERBOLIC_TAN)
        {
            uint8scale_In   *= logE * 2 * maxVal;
            uint8qscale_Out *= minVal;
            sprintf(kernelName, "_tanh_UInt8");
            if (useImage2DFlag)
                sprintf(kernelName, "_tanh_UInt8_2D");
            else
                sprintf(kernelName, "_tanh_UInt8");
        }
        else if (funcType == VX_NN_ACTIVATION_LOGISTIC)
        {
            uint8scale_In   *= logE;
            if (useImage2DFlag)
                sprintf(kernelName, "_sigmoid_UInt8_2D");
            else
                sprintf(kernelName, "_sigmoid_UInt8");
        }
        else if (funcType == VX_NN_ACTIVATION_SOFTRELU)
        {
            uint8scale_In   *= logE;
            uint8qscale_Out /= logE;
            if (useImage2DFlag)
                sprintf(kernelName, "_softRelu_UInt8_2D");
            else
                sprintf(kernelName, "_softRelu_UInt8");
        }
        else if (funcType == VX_NN_ACTIVATION_SQRT)
        {
            if (useImage2DFlag)
                sprintf(kernelName, "_sqrt_UInt8_2D");
            else
                sprintf(kernelName, "_sqrt_UInt8");
        }
        else if (funcType == VX_NN_ACTIVATION_RSQRT)
        {
            if (useImage2DFlag)
                sprintf(kernelName, "_rsqrt_UInt8_2D");
            else
                sprintf(kernelName, "_rsqrt_UInt8");
        }

        if (useImage2DFlag)
        {
            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part0_4x4", 1, uniUInt8toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part1_4x4", 1, uniUInt8toFp32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8scale_In", 1, &uint8scale_In);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8qscale_Out", 1, &uint8qscale_Out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ZP_In", 1, &uint8ZP_In);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ZP_Out", 1, &uint8ZP_Out);
        if (status != VX_SUCCESS) goto OnError;
    }


    if (useImage2DFlag)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcEmbeddingLUT****************************************/
vxnne_shader_executable vxnneGetEmbeddingLUTShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               value,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]              = {(vx_reference)input, (vx_reference)value, (vx_reference)output};
    vx_enum       valueFormat                = TENSOR_DATA_TYPE(value);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int8       srcFixPointPos             = TENSOR_POS(value);
    vx_int8       dstFixPointPos             = TENSOR_POS(output);
    vx_float32    input_scale                = TENSOR_TF_SCALE(value);
    vx_float32    output_scale               = TENSOR_TF_SCALE(output);
    vx_int32      inputZP                    = TENSOR_TF_ZEROPOINT(value);
    vx_int32      outputZP                   = TENSOR_TF_ZEROPOINT(output);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_uint32     channel                    = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     height                     = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_count                = 0;
    vx_uint32     vDims                      = TENSOR_DIM_NUM(value);
    vx_uint32     vc                         = vDims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(value, 2);
    vx_uint32     vh                         = TENSOR_VIEW_SIZE_INDEX(value, 1);
    vx_uint32     vw                         = TENSOR_VIEW_SIZE_INDEX(value, 0);
    vx_uint32     oDims                      = TENSOR_DIM_NUM(output);
    vx_uint32     ow                         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     value_rs                   = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      rs_sizes[4]                = {1, 1, 1, 1};
    vx_bool       isSameFlg                  = vx_false_e;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    if (!((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        || (valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        ))
    {
        vxError("input or output's format is not support");
        goto OnError;
    }

    if (((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        && (input_scale == output_scale)
        && (inputZP == outputZP))
        || (((valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
          || (valueFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
         && (srcFixPointPos == dstFixPointPos))
        )
    {
        isSameFlg = vx_true_e;
    }

    if (dims == 1)
    {
        rs_sizes[0] = width;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (dims == 2)
    {
        rs_sizes[0] = width * height;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (dims == 3)
    {
        rs_sizes[0] = width * height * channel;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 3);
        parameters[0] = (vx_reference)input_rs;
    }
    input_count = rs_sizes[0];

    if (vDims == 1)
    {
        rs_sizes[0] = vw;
        value_rs = vxoTensor_ReshapeTensor(value, rs_sizes, 2);
        parameters[1] = (vx_reference)value_rs;
    }

    if (oDims == 1)
    {
        rs_sizes[0] = ow;
        output_rs = vxoTensor_ReshapeTensor(output, rs_sizes, 2);
        parameters[2] = (vx_reference)output_rs;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 16;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    if ((valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        || (valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
        execution_parameters.globalWorkScale[0]  = 8;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((vw  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (vh + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = (input_count + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, EmbeddingLUT, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/EmbeddingLUT.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcEmbeddingLUT", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniConvert1stUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert2ndUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert3rdUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert4thUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };

        uint32_t uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
            && isSameFlg)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8_nofl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            vx_float32 scale_inOut_u8 = input_scale / output_scale;
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_inOut_u8", 1, &scale_inOut_u8);

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert1stUint8SubZpToFp32_4x4", 1, uniConvert1stUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert2ndUint8SubZpToFp32_4x4", 1, uniConvert2ndUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert3rdUint8SubZpToFp32_4x4", 1, uniConvert3rdUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert4thUint8SubZpToFp32_4x4", 1, uniConvert4thUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        }
        else if (valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "value_rows", 1, &vc);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (value_rs) vxoTensor_ReleaseTensor(&value_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (value_rs) vxoTensor_ReleaseTensor(&value_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcHashLUT****************************************/
vxnne_shader_executable vxnneGetHashLUTShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               key,
    vx_tensor               value,
    vx_tensor               hit,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[5]              = {(vx_reference)input, (vx_reference)key, (vx_reference)value, (vx_reference)hit, (vx_reference)output};
    vx_enum       valueFormat                = TENSOR_DATA_TYPE(value);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int8       srcFixPointPos             = TENSOR_POS(value);
    vx_int8       dstFixPointPos             = TENSOR_POS(output);
    vx_float32    input_scale                = TENSOR_TF_SCALE(value);
    vx_float32    output_scale               = TENSOR_TF_SCALE(output);
    vx_int32      inputZP                    = TENSOR_TF_ZEROPOINT(value);
    vx_int32      outputZP                   = TENSOR_TF_ZEROPOINT(output);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_uint32     channel                    = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     height                     = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     input_count                = 0;
    vx_uint32     key_count                  = 0;
    vx_uint32     kDims                      = TENSOR_DIM_NUM(key);
    vx_uint32     kc                         = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(key, 2);
    vx_uint32     kh                         = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(key, 1);
    vx_uint32     kw                         = TENSOR_VIEW_SIZE_INDEX(key, 0);
    vx_uint32     vDims                      = TENSOR_DIM_NUM(value);
    vx_uint32     vw                         = TENSOR_VIEW_SIZE_INDEX(value, 0);
    vx_uint32     oDims                      = TENSOR_DIM_NUM(output);
    vx_uint32     ow                         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     tDims                      = TENSOR_DIM_NUM(hit);
    vx_uint32     tw                         = TENSOR_VIEW_SIZE_INDEX(hit, 0);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     key_rs                     = NULL;
    vx_tensor     value_rs                   = NULL;
    vx_tensor     hit_rs                     = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      rs_sizes[4]                = {1, 1, 1, 1};
    vx_bool       isSameFlg                  = vx_false_e;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    borderMode->constant_value.S32 = 0;
    if (!((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        || (valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
        || (valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)))
    {
        gcmPRINT("input or output's format is not support");
        goto OnError;
    }

    if (((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        && (input_scale == output_scale)
        && (inputZP == outputZP))
        || (((valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
          || (valueFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8))
         && (srcFixPointPos == dstFixPointPos))
        )
    {
        isSameFlg = vx_true_e;
    }

    if (dims == 1)
    {
        rs_sizes[0] = width;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (dims == 2)
    {
        rs_sizes[0] = width * height;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (dims == 3)
    {
        rs_sizes[0] = width * height * channel;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 3);
        parameters[0] = (vx_reference)input_rs;
    }
    input_count = rs_sizes[0];

    if (kDims == 1)
    {
        rs_sizes[0] = kw;
        key_rs = vxoTensor_ReshapeTensor(key, rs_sizes, 2);
        parameters[1] = (vx_reference)key_rs;
    }

    if (kDims == 2)
    {
        rs_sizes[0] = kw * kh;
        key_rs = vxoTensor_ReshapeTensor(key, rs_sizes, 2);
        parameters[1] = (vx_reference)key_rs;
    }

    if (kDims == 3)
    {
        rs_sizes[0] = kw * kh * kc;
        key_rs = vxoTensor_ReshapeTensor(key, rs_sizes, 3);
        parameters[1] = (vx_reference)key_rs;
    }
    key_count = rs_sizes[0];

    if (vDims == 1)
    {
        rs_sizes[0] = vw;
        value_rs = vxoTensor_ReshapeTensor(value, rs_sizes, 2);
        parameters[2] = (vx_reference)value_rs;
    }

    if (tDims == 1)
    {
        rs_sizes[0] = tw;
        hit_rs = vxoTensor_ReshapeTensor(hit, rs_sizes, 2);
        parameters[3] = (vx_reference)hit_rs;
    }

    if (oDims == 1)
    {
        rs_sizes[0] = ow;
        output_rs = vxoTensor_ReshapeTensor(output, rs_sizes, 2);
        parameters[4] = (vx_reference)output_rs;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 16;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    if ((valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        ||(valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        execution_parameters.globalWorkScale[0]  = 8;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((vw  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (input_count + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = (channel + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, HashLUT, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/HashLUT.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcHashLUT", program, 5, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniConvert1stUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert2ndUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert3rdUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert4thUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };

        uint32_t uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
            && isSameFlg)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8_nofl", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (valueFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            vx_float32 scale_inOut_u8 = input_scale / output_scale;
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8", borderMode);
            if (!shaderExecutable) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            //status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale", 1, &input_scale);
            //status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_scale", 1, &output_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_inOut_u8", 1, &scale_inOut_u8);

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert1stUint8SubZpToFp32_4x4", 1, uniConvert1stUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert2ndUint8SubZpToFp32_4x4", 1, uniConvert2ndUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert3rdUint8SubZpToFp32_4x4", 1, uniConvert3rdUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert4thUint8SubZpToFp32_4x4", 1, uniConvert4thUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        }
        else if ((valueFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
               ||(valueFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "key_count", 1, &key_count);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 5);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (key_rs) vxoTensor_ReleaseTensor(&key_rs);
    if (value_rs) vxoTensor_ReleaseTensor(&value_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (hit_rs) vxoTensor_ReleaseTensor(&hit_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (key_rs) vxoTensor_ReleaseTensor(&key_rs);
    if (value_rs) vxoTensor_ReleaseTensor(&value_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (hit_rs) vxoTensor_ReleaseTensor(&hit_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcMeanStddevNormalization****************************************/
vxnne_shader_executable vxnneGetMeanStddevNormalizationShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_float32              eps,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]              = {(vx_reference)input, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_uint32     channel                    = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     height                     = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     oDims                      = TENSOR_DIM_NUM(output);
    vx_uint32     ow                         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      rs_sizes[4]                = {1, 1, 1, 1};
    vx_float32    dimRatio                   = 0;
    vx_float32    rsEps                      = (vx_float32)(1.0f / sqrt(eps));
    char *programSources = NULL;

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    borderMode->constant_value.S32 = 0;
    if (!(inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
    {
        gcmPRINT("input or output's format is not support");
        goto OnError;
    }

    if (dims == 1)
    {
        rs_sizes[0] = width;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
    }

    if (oDims == 1)
    {
        rs_sizes[0] = ow;
        output_rs = vxoTensor_ReshapeTensor(output, rs_sizes, 2);
        parameters[1] = (vx_reference)output_rs;
    }
    dimRatio = (float)(1.0f / (width));

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 8;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.localWorkSize[0]    = 16;
    execution_parameters.localWorkSize[1]    = 1;
    execution_parameters.localWorkSize[2]    = 1;
    execution_parameters.globalWorkSize[0]   = 16;
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = (channel + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, MeanStddevNorm, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/MeanStddevNorm.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcMeanStddevNorm", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniFp16SumSqr_dp8x2[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x5555aaaa, // BSelt
            0x00000000, 0x76543210, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniFP16toFP32Lo4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertEndInt16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        uint32_t uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if(inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16SumSqr_dp8x2", 1, uniFp16SumSqr_dp8x2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Lo4_dp4x4", 1, UniFP16toFP32Lo4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "width", 1, &width);
        //status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "height", 1, &height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dimRatio", 1, &dimRatio);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "rsEps", 1, &rsEps);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    return VX_NULL;
}
/********vxcTensorAddMeanStddevNormalization****************************************/
vxnne_shader_executable vxnneGetTensorAddMeanStdNormalizationShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               input1,
    vx_float32              eps,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]              = {(vx_reference)input, (vx_reference)input1, (vx_reference)output};
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(output);
    vx_float32    input_scale                = TENSOR_TF_SCALE(input);
    vx_float32    input_scale1               = TENSOR_TF_SCALE(input1);
    vx_float32    output_scale               = TENSOR_TF_SCALE(output);
    vx_int32      inputZP                    = TENSOR_TF_ZEROPOINT(input);
    vx_int32      inputZP1                   = TENSOR_TF_ZEROPOINT(input1);
    vx_int32      outputZP                   = TENSOR_TF_ZEROPOINT(output);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_uint32     channel                    = dims < 3 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     height                     = dims < 2 ? 1 : TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     oDims                      = TENSOR_DIM_NUM(output);
    vx_uint32     ow                         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_tensor     input_rs                   = NULL;
    vx_tensor     input_rs1                  = NULL;
    vx_tensor     output_rs                  = NULL;
    vx_int32      rs_sizes[4]                = {1, 1, 1, 1};
    vx_float32    dimRatio                   = 0;
    vx_float32    rsEps                      = (vx_float32)(1.0f / sqrt(eps));
    char *programSources = NULL;

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;
    borderMode->constant_value.S16 = 0;
    borderMode->constant_value.S32 = 0;
    if (!(inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
    {
        gcmPRINT("input or output's format is not support");
        goto OnError;
    }

    if (dims == 1)
    {
        rs_sizes[0] = width;
        input_rs = vxoTensor_ReshapeTensor(input, rs_sizes, 2);
        parameters[0] = (vx_reference)input_rs;
        input_rs1 = vxoTensor_ReshapeTensor(input1, rs_sizes, 2);
        parameters[1] = (vx_reference)input_rs1;
    }

    if (oDims == 1)
    {
        rs_sizes[0] = ow;
        output_rs = vxoTensor_ReshapeTensor(output, rs_sizes, 2);
        parameters[2] = (vx_reference)output_rs;
    }
    dimRatio = (float)(1.0f / (width));

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 8;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.localWorkSize[0]    = 16;
    execution_parameters.localWorkSize[1]    = 1;
    execution_parameters.localWorkSize[2]    = 1;
    execution_parameters.globalWorkSize[0]   = 16;
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = (channel + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorAddMeanStddevNorm, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorAddMeanStddevNorm.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorAddMeanStdNorm", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_uint32 uniAddFp16_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };
        vx_uint32 uniFp16SumSqr_dp8x2[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x5555aaaa, // BSelt
            0x00000000, 0x76543210, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAddFp16toFp32Lo_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniAddFp16toFp32Hi_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        uint32_t uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if(inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint16  M0                   = 0;
            vx_int8    postShift            = 0;
            vx_uint32    multAndoutZP0[2]   = {0};
            vx_uint32    multAndoutZP1[2]   = {0};

            vx_uint32 uniU8MulAndPostShift_0_Lo_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002600, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniU8MulAndPostShift_1_Lo_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002600, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8_fp16", borderMode);
            if (!shaderExecutable) goto OnError;

            getFP32M0AndN(input_scale / output_scale, &M0, &postShift);
            multAndoutZP0[0] = (vx_uint32)(M0);
            multAndoutZP0[1] = (vx_uint32)((outputZP << postShift) - inputZP * M0);
            uniU8MulAndPostShift_0_Lo_2x8[7] |= (postShift & 0x1F);

            getFP32M0AndN(input_scale1 / output_scale, &M0, &postShift);
            multAndoutZP1[0] = (vx_uint32)(M0);
            multAndoutZP1[1] = (vx_uint32)((outputZP << postShift) - inputZP1 * M0);
            uniU8MulAndPostShift_1_Lo_2x8[7] |= (postShift & 0x1F);

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_0_Lo_2x8", 1, uniU8MulAndPostShift_0_Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP0", 1, multAndoutZP0);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_1_Lo_2x8", 1, uniU8MulAndPostShift_1_Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP1", 1, multAndoutZP1);
        }
        else if(inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAddFp16_2x8", 1, uniAddFp16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16SumSqr_dp8x2", 1, uniFp16SumSqr_dp8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAddFp16toFp32Lo_4x4", 1, uniAddFp16toFp32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAddFp16toFp32Hi_4x4", 1, uniAddFp16toFp32Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "width", 1, &width);
        //status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "height", 1, &height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dimRatio", 1, &dimRatio);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "rsEps", 1, &rsEps);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (input_rs1) vxoTensor_ReleaseTensor(&input_rs1);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (input_rs1) vxoTensor_ReleaseTensor(&input_rs1);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    return VX_NULL;
}
/********vxcActivationSoftRelu****************************************************/
vxnne_shader_executable vxnneGetActivationSoftReluShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference   parameters[2]    = {(vx_reference)input, (vx_reference)output};
    vx_enum        inputFormat      = TENSOR_DATA_TYPE(input);
    vx_enum        outputFormat     = TENSOR_DATA_TYPE(output);
    vx_uint32      in_width         = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32      in_height        = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32      depth            = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32      channel          = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32      dims             = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor      inputReshaped    = NULL;
    vx_tensor      outputReshaped   = NULL;
    vx_int8        srcFixPointPos   = TENSOR_POS(input);
    vx_int8        dstFixPointPos   = TENSOR_POS(output);
    vx_float32     outputScale      = 1.0f;
    vx_float32     inputScale       = 1.0f;
    char *programSources = NULL;

    // uniforms
    vx_uint32 fp16ToFp32_high4[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00050004, 0x00070006, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000100, // AccumType, ConstantType, and PostShift
        0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
    };
    vx_uint32 fp16ToFp32_low4[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000100, // AccumType, ConstantType, and PostShift
        0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
    };
    vx_uint32 halfToVxcHalf_8[16] = {
        0x11111111, // TCfg
        0x11110000, // ASelt
        0x06040200, 0x06040200, // ABin
        0x22222222, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000100, // AccumType, ConstantType, and PostShift
        0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
    };
    vx_uint32 fp16MulFp16ToFp16_8x1[16] = {
        0x11111111, // TCfg
        0x00000000, // ASelt
        0x03020100, 0x07060504, // ABin
        0x11111111, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 int8MulFp16ToFp16_8x1[16] = {
        0x11111111, // TCfg
        0x00000000, // ASelt
        0x03020100, 0x07060504, // ABin
        0x11111111, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            inputScale    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            inputScale    = (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            outputScale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            outputScale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    borderMode->mode = VX_BORDER_REPLICATE;
    {
        vx_int32 sizeReshaped[4] = {in_width*in_height, depth, 1, channel};
        inputReshaped  = vxoTensor_ReshapeTensor(input, sizeReshaped, dims);
        outputReshaped = vxoTensor_ReshapeTensor(output, sizeReshaped, dims);
    }

    parameters[0] = (vx_reference)inputReshaped;
    parameters[1] = (vx_reference)outputReshaped;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, ActivationSoftRelu, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/ActivationSoftRelu.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcActivationSoftRelu", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_2D", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 4;

        inputScale *= logE;
        outputScale /= logE;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_In", 1, &inputScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_Out", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;

    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
    {

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toInt8", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
    {

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
    {
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toInt8", borderMode);
        if (!shaderExecutable) goto OnError;

        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
    {
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toFp16", borderMode);
        if (!shaderExecutable) goto OnError;

        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkSize[0]   = gcmALIGN((in_width * in_height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ToFp32_low4", 1, fp16ToFp32_low4);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ToFp32_high4", 1, fp16ToFp32_high4);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "halfToVxcHalf_8", 1, halfToVxcHalf_8);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16ToFp16_8x1", 1, fp16MulFp16ToFp16_8x1);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "int8MulFp16ToFp16_8x1", 1, int8MulFp16ToFp16_8x1);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &inputScale);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (inputReshaped) vxoTensor_ReleaseTensor(&inputReshaped);
    if (outputReshaped) vxoTensor_ReleaseTensor(&outputReshaped);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (inputReshaped) vxoTensor_ReleaseTensor(&inputReshaped);
    if (outputReshaped) vxoTensor_ReleaseTensor(&outputReshaped);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcLeakyRelu****************************************************/
vxnne_shader_executable vxnneGetLeakyReluShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               alpha,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference    parameters[3]              = {(vx_reference)input, (vx_reference)alpha, (vx_reference)output};
    vx_enum         inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum         outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int8         srcFixPointPos             = TENSOR_POS(input);
    vx_int8         dstFixPointPos             = TENSOR_POS(output);
    vx_uint32       dims                       = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor       reInput                    = NULL;
    vx_tensor       reOutput                   = NULL;
    vx_uint32       width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32       height                     = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32       depth                      = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32       batch                      = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_bool         useImage2DFlag             = (vx_bool)((width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH);
    vx_int32        input_ZP                   = TENSOR_TF_ZEROPOINT(input);
    vx_int32        output_ZP                  = TENSOR_TF_ZEROPOINT(output);
    vx_float32      scaleIn                    = 1.0f;
    vx_float32      scaleOut                   = 1.0f;
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (useImage2DFlag)
    {
        vx_int32 resize[4] = {width * height, depth, 1, batch};
        reInput  = vxoTensor_ReshapeTensor(input, resize, dims);
        reOutput = vxoTensor_ReshapeTensor(output, resize, dims);

        parameters[0] = (vx_reference)reInput;
        parameters[2] = (vx_reference)reOutput;
    }

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn = TENSOR_TF_SCALE(input);
    }


    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut = TENSOR_TF_SCALE(output);
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LeakyRelu, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/LeakyRelu.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLeakyRelu", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_float32 uint8scale_In     = scaleIn;
        vx_float32 uint8qscale_Out   = 1 / scaleOut;
        vx_int32   uint8ZP_In        = input_ZP;
        vx_float32 uint8ZP_Out       = (vx_float32)output_ZP;

        vx_uint32  uniUInt8toFp32Part0_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8toFp32Part1_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part0_4x4", 1, uniUInt8toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8toFp32Part1_4x4", 1, uniUInt8toFp32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8scale_In", 1, &uint8scale_In);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8qscale_Out", 1, &uint8qscale_Out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ZP_In", 1, &uint8ZP_In);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ZP_Out", 1, &uint8ZP_Out);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        float scaleInt16toInt16_In  = scaleIn;
        float scaleInt16toInt16_Out = scaleOut;
        vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.workDim             = 2;
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_In", 1, &scaleInt16toInt16_In);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16_Out", 1, &scaleInt16toInt16_Out);
        if (status != VX_SUCCESS) goto OnError;
    }
    else
    {
        vx_uint32       UniFP16Mul_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32       UniS8xFp16toFp16_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 1;

            if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16Image", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toInt8Image", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toFp16Image", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toInt8Image", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                vxError("input or output's format is not support");
                goto OnError;
            }

            execution_parameters.workDim = 2;
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;

            if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16Tensor", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toInt8Tensor", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toFp16Tensor", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toInt8Tensor", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                vxError("input or output's format is not support");
                goto OnError;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16Mul_dp2x8", 1, UniFP16Mul_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16toFp16_dp2x8", 1, UniS8xFp16toFp16_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &scaleIn);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale", 1, &scaleOut);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (reInput)  vxoTensor_ReleaseTensor(&reInput);
    if (reOutput) vxoTensor_ReleaseTensor(&reOutput);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (reInput)  vxoTensor_ReleaseTensor(&reInput);
    if (reOutput) vxoTensor_ReleaseTensor(&reOutput);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcFullyConnected****************************************************/
vxnne_shader_executable vxnneGetFullyConnectedShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               weights,
    vx_tensor               bias,
    vx_int32                activation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[5]   = {(vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)output};
    vx_scalar     dRelu_s        = NULL;
    vx_int32      dRelu          = 0;
    vx_bool       enable_bias    = (bias == NULL) ? vx_false_e : vx_true_e;
    vx_enum       output_format  = TENSOR_DATA_TYPE(output);
    vx_enum       input_format   = TENSOR_DATA_TYPE(input);
    vx_enum       weights_format = TENSOR_DATA_TYPE(weights);
    vx_enum       bias_format    = enable_bias ? TENSOR_DATA_TYPE(bias) : VX_TYPE_INVALID;
    vx_uint32     input_dims     = TENSOR_DIM_NUM(input);
    vx_uint32     batch0         = (input_dims > 3) ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_uint32     weight_dims    = TENSOR_DIM_NUM(weights) == 1 ? 2 : TENSOR_DIM_NUM(weights);
    vx_uint32     bias_dims      = enable_bias ? (TENSOR_DIM_NUM(bias) == 1 ? 2 : TENSOR_DIM_NUM(bias)) : 0;
    vx_uint32     output_dims    = TENSOR_DIM_NUM(output);
    vx_uint32     width_wei      = TENSOR_VIEW_SIZE_INDEX(weights, 0);
    vx_uint32     height_wei     = (weight_dims > 1) ? TENSOR_VIEW_SIZE_INDEX(weights, 1) : 1;
    vx_uint32     depth_wei      = (weight_dims > 2) ? TENSOR_VIEW_SIZE_INDEX(weights, 2) : 1;
    vx_uint32     batch1         = (weight_dims > 3) ? TENSOR_VIEW_SIZE_INDEX(weights, 3) : 1;
    vx_uint32     tensorSize     = width_wei * height_wei * depth_wei * batch1;
    vx_uint32     num_units      = 0;
    vx_float32    in_scale       = 0;
    vx_tensor     input_rs       = NULL;
    vx_tensor     weight_rs      = NULL;
    vx_tensor     bias_rs        = NULL;
    vx_tensor     output_rs      = NULL;
    vx_uint32     input_ZP       = TENSOR_TF_ZEROPOINT(input);
    vx_uint32     weight_ZP      = TENSOR_TF_ZEROPOINT(weights);
    vx_uint32     output_ZP      = TENSOR_TF_ZEROPOINT(output);
    vx_float32    input_scale    = TENSOR_TF_SCALE(input);
    vx_float32    weight_scale   = TENSOR_TF_SCALE(weights);
    vx_float32    output_scale   = TENSOR_TF_SCALE(output);
    vx_uint32     sizes[4]       = {1, 1, 1, 1};
    vx_uint32     inputSize      = 0;
    vx_uint32     batch          = 0;
    vx_uint32     paramNum       = enable_bias ? 5 : 4;
    vx_uint32     paramIdx       = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    input_dims = TENSOR_DIM_NUM(input);
    switch(input_dims)
    {
    case 1:
        inputSize = TENSOR_VIEW_SIZE_INDEX(input, 0);
        batch   = 1;
        break;
    case 2:
        inputSize = TENSOR_VIEW_SIZE_INDEX(input, 0);
        batch     = TENSOR_VIEW_SIZE_INDEX(input, 1);
        break;
    case 3:
        inputSize   = TENSOR_VIEW_SIZE_INDEX(input, 0) * TENSOR_VIEW_SIZE_INDEX(input, 1) * TENSOR_VIEW_SIZE_INDEX(input, 2);
        batch   = 1;
        break;
    case 4:
        inputSize   = TENSOR_VIEW_SIZE_INDEX(input, 0) * TENSOR_VIEW_SIZE_INDEX(input, 1) * TENSOR_VIEW_SIZE_INDEX(input, 2);
        batch   = batch0;
        batch0  = 1;
        break;
    default:
        vxError("Input tensor OnError dimension[%u]\n", input_dims);
        goto OnError;
    }

    num_units     = tensorSize / inputSize;

    input_dims    = (input_dims == 1 ) ? 2 : TENSOR_DIM_NUM(input);
    output_dims   = (output_dims == 1) ? 2 : TENSOR_DIM_NUM(output);

    sizes[0]      = inputSize;
    sizes[1]      = batch;
    sizes[2]      = 1;
    sizes[3]      = batch0;
    input_rs      = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, input_dims);
    sizes[0]      = inputSize;
    sizes[1]      = num_units;
    sizes[2]      = 1;
    sizes[3]      = 1;
    weight_dims   = 2;
    weight_rs     = vxoTensor_ReshapeTensor(weights, (vx_int32*)sizes, weight_dims);

    if (enable_bias)
    {
        sizes[0]      = num_units;
        sizes[1]      = 1;
        bias_dims     = 2;
        bias_rs       = vxoTensor_ReshapeTensor(bias, (vx_int32*)sizes, bias_dims);
    }

    sizes[0]      = num_units;
    sizes[1]      = batch;
    sizes[2]      = 1;
    sizes[3]      = batch0;
    output_rs     = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, output_dims);
    dRelu_s = vxCreateScalar(context, VX_TYPE_INT32, &dRelu);

    parameters[paramIdx ++] = (vx_reference)input_rs;
    parameters[paramIdx ++] = (vx_reference)weight_rs;
    if (enable_bias)
        parameters[paramIdx ++] = (vx_reference)bias_rs;
    parameters[paramIdx ++] = (vx_reference)dRelu_s;
    parameters[paramIdx ++] = (vx_reference)output_rs;

    if ((input_format == VX_TYPE_INT8  &&  weights_format ==  VX_TYPE_INT8  && bias_format == VX_TYPE_INT32  && output_format == VX_TYPE_INT8) ||
        (input_format == VX_TYPE_INT16 &&  weights_format ==  VX_TYPE_INT16 && bias_format == VX_TYPE_INT32  && output_format == VX_TYPE_INT16))
    {
        vx_int8   srcFixedPointPos    = TENSOR_POS(input);
        vx_int8   weiFixedPointPos    = TENSOR_POS(weights);
        vx_int8   dstFixedPointPos    = TENSOR_POS(output);
        vx_int32  multiplicator       = 0;

        multiplicator                 = multiplicator - srcFixedPointPos;
        multiplicator                 = multiplicator - weiFixedPointPos;
        multiplicator                 = multiplicator + dstFixedPointPos;

        if (multiplicator < 0)
            in_scale = 1.0f / (vx_float32) (1 << -multiplicator);
        else
            in_scale = (vx_float32) (1 << multiplicator);

        borderMode->mode = VX_BORDER_CONSTANT;
        borderMode->constant_value.U8 = 0;
        borderMode->constant_value.S16 = 0;
    }
    else if (input_format == VX_TYPE_FLOAT16)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        borderMode->constant_value.S16 = 0;
    }
    else if (input_format == VX_TYPE_UINT8)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        borderMode->constant_value.U8 = (vx_uint8)input_ZP;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, FullyConnected, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/FullyConnected.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcFullyConnected", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16 && weights_format == VX_TYPE_FLOAT16  && (bias_format == VX_TYPE_FLOAT16 || enable_bias == vx_false_e)  && output_format == VX_TYPE_FLOAT16)
    {
        vx_int32 input_size_align32 = 0;
        vx_uint32 uniAccF16MulFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32_16x1[16] = {
            0x00000001, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000002, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_bias && bias_format == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_all", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_noBias", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccF16MulFp16_16x1", 1, uniAccF16MulFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_16x1", 1, uniFp16toFp32_16x1);
        if (status != VX_SUCCESS) goto OnError;

        input_size_align32   = gcmALIGN(inputSize, 32);
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_size_align32", 1, &input_size_align32);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (input_format == VX_TYPE_FLOAT16 && weights_format == VX_TYPE_FLOAT16 && bias_format == VX_TYPE_FLOAT32  && output_format == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniMulAcc[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_NoRelu", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc", 1, uniMulAcc);
        if (status != VX_SUCCESS) goto OnError;

        inputSize   = gcmALIGN(inputSize, 32);
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles", 1, &inputSize);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (input_format == VX_TYPE_INT8 &&  weights_format ==  VX_TYPE_INT8 && bias_format == VX_TYPE_INT32  && output_format == VX_TYPE_INT8)
    {
        vx_uint32 uniMulAcc_Int8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_NoReluInt8", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc_Int8", 1, uniMulAcc_Int8);
        if (status != VX_SUCCESS) goto OnError;

        inputSize   = gcmALIGN(inputSize, 64);
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles", 1, &inputSize);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (input_format == VX_TYPE_INT16 &&  weights_format ==  VX_TYPE_INT16 && bias_format == VX_TYPE_INT32  && output_format == VX_TYPE_INT16)
    {
        vx_uint32 uniMulAccInt16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_NoReluInt16", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAccInt16_16x1", 1, uniMulAccInt16_16x1);
        if (status != VX_SUCCESS) goto OnError;

        inputSize   = gcmALIGN(inputSize, 32);
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles", 1, &inputSize);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (input_format == VX_TYPE_UINT8 &&  weights_format ==  VX_TYPE_UINT8 && bias_format == VX_TYPE_INT32  && output_format == VX_TYPE_UINT8)
    {
        vx_uint8   minVal          = 0;
        vx_uint8   maxVal          = 0;
        vx_uint32  minData         = 0;
        vx_uint32  maxData         = 0;
        vx_uint32  packedZ1        = (weight_ZP << 24) | (weight_ZP << 16) | (weight_ZP << 8) | (weight_ZP);
        vx_uint32  packedZ0        = (input_ZP << 24) | (input_ZP << 16) | (input_ZP << 8) | (input_ZP);
        vx_int32   nZ1Z2           = gcmALIGN(inputSize, 64) * input_ZP * weight_ZP;
        vx_float32 uint8Scale      = input_scale * weight_scale / output_scale;
        vx_float32 outputZP        = (vx_float32)output_ZP;
        vx_uint32  uniAccQ1MulQ2_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccQaMulZb_16x2[16] = {
            0xaaaaaaaa, 0xaaaaaaaa, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000700, // AccumType, ConstantType, and PostShift
            packedZ1, packedZ1, packedZ1, packedZ1, packedZ0, packedZ0, packedZ0, packedZ0 // Constant
        };

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

        minData = (vx_uint32)minVal;
        maxData = (vx_uint32)maxVal;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_NoReluUInt8", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQ1MulQ2_16x1", 1, uniAccQ1MulQ2_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQaMulZb_16x2", 1, uniAccQaMulZb_16x2);
        if (status != VX_SUCCESS) goto OnError;

        inputSize   = gcmALIGN(inputSize, 64);
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles", 1, &inputSize);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nZ1Z2", 1, &nZ1Z2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (dRelu_s) vxReleaseScalar(&dRelu_s);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (weight_rs) vxoTensor_ReleaseTensor(&weight_rs);
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (dRelu_s) vxReleaseScalar(&dRelu_s);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (weight_rs) vxoTensor_ReleaseTensor(&weight_rs);
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcAvgPooling****************************************************/
vxnne_shader_executable vxnneGetAvgPoolingShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               poolType,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pool_pad_x_left,
    vx_uint32               pool_pad_y_top,
    vx_scalar               rounding,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[3]      = {(vx_reference)input, VX_NULL, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch              = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    dims               = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    stride_v           = stride_s->value->u32;
    vx_uint32    kernel_v           = poolSizeX->value->u32;
    vx_uint32    kernel_size_y      = poolSizeY->value->u32;
    vx_uint32    pad_v              = pool_pad_x_left;
    vx_uint32    pad_y              = pool_pad_y_top;
    vx_scalar    in_heights         = NULL;
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_bool      globalPooling_flag = (vx_bool)(out_width == 1 && out_height == 1 && kernel_v == in_width && kernel_size_y == in_height);
    vx_float32   div_scale          = 1.0f;
    vx_uint32    height             = (out_height - 1) * stride_v + kernel_size_y - 2 * pad_y;
    vx_uint32    width              = (out_width - 1) * stride_v + kernel_v - 2 * pad_v;
    vx_uint32    globalWorkSize1    = 1;
    vx_bool      useImage2DFlag     = (vx_bool)(in_width * in_height < IMG_MAX_WIDTH);

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    globalPooling_flag = (vx_bool)(globalPooling_flag & useImage2DFlag);

    if (height != in_height)
    {
        if (out_height < height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }
    else
    {
        if (out_height < in_height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &in_height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }

    parameters[1] = (vx_reference)in_heights;

    if (inputFormat == VX_TYPE_INT8)
    {
        if (srcFixPointPos >= 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            div_scale *= (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixPointPos >= 0)
        {
            div_scale *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    if (globalPooling_flag)
    {
        vx_int32 src_sizes[4] = {in_width * in_height, depth, 1, batch};
        vx_int32 dst_sizes[4] = {1, depth, 1, batch};
        borderMode->mode = VX_BORDER_CONSTANT;
        input_rs         = vxoTensor_ReshapeTensor(input, src_sizes, dims);
        output_rs        = vxoTensor_ReshapeTensor(output, dst_sizes, dims);

        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }

        parameters[0] = (vx_reference)input_rs;
        parameters[2] = (vx_reference)output_rs;
    }
    else if (pad_v != 0 || height != in_height || width != in_width)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }
    }
    else
    {
        borderMode->mode = VX_BORDER_REPLICATE;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, AvgPooling, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        if ((inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
            || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
            || (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
            || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
        {
            vxmONERROR(getFilePath("nnvxc_kernels/AvgPooling.vx", path));

            vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

            vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

            if (programSources)
            {
                vxFree(programSources);
                programSources = NULL;
            }
        }
        else
        {
            vxError("data format not support %s line %d", __FUNCTION__, __LINE__);
            goto OnError;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcPooling", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (globalPooling_flag && ((outputFormat == VX_TYPE_FLOAT16 && (kernel_v <= 13 && kernel_size_y <= 13)) || (kernel_v <= 8 && kernel_size_y <= 8)) )
    {
        vx_float32    scale_globalPool = div_scale * (1 / (float)(kernel_v * kernel_size_y));
        vx_uint32 uniInt8AddInt8_32x1[16] = {
            0xffffffff, 0xffffffff, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uni2S16Dot1FP16_KernelLE8_16x1[16] = {
            0x00000005, // TCfg
            0x00000000, // ASelt
            0x00000010, 0x00000000, // ABin
            0x00000005, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uni6S16Dot1FP16_KernelLE8_16x1[16] = {
            0x00000555, // TCfg
            0x00000000, // ASelt
            0x00543210, 0x00000000, // ABin
            0x00000555, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16_16x1[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniFp16AddFp16_16x1[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };

        if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16 && kernel_v <= 8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgInt8toFp16KernelLE8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16 && kernel_v <= 13)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgInt8toFp16KernelLE13", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && kernel_v <= 8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgFp16toFp16KernelLE8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && kernel_v <= 13)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgFp16toFp16KernelLE13", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgInt8toInt8KernelLE8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgFp16toInt8KernelLE8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8_32x1", 1, uniInt8AddInt8_32x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uni2S16Dot1FP16_KernelLE8_16x1", 1, uni2S16Dot1FP16_KernelLE8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uni6S16Dot1FP16_KernelLE8_16x1", 1, uni6S16Dot1FP16_KernelLE8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16_16x1", 1, uniS16AddS16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16_16x1", 1, uniFp16AddFp16_16x1);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_globalPool", 1, &scale_globalPool);
        if (status != VX_SUCCESS) goto OnError;

    }
    else  if (globalPooling_flag )
    {
        vx_float32    scale_global_pool = div_scale * (1 / (float)(kernel_v * kernel_size_y));
        int pool_size  = gcmALIGN_SAFE(kernel_v * kernel_size_y, 32);
        vx_uint32 uniAcc32S8_32x1[16] = {
            0xffffffff, 0xffffffff, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAcc16Fp16_16x1[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };

        if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            pool_size  = gcmALIGN_SAFE(kernel_v * kernel_size_y, 64);
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_globalAvgPooling_Int8toInt8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_globalAvgPooling_Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
        {
            pool_size  = gcmALIGN_SAFE(kernel_v * kernel_size_y, 64);
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_globalAvgPooling_Int8toFp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_globalAvgPooling_Fp16toInt8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc32S8_32x1", 1, uniAcc32S8_32x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc16Fp16_16x1", 1, uniAcc16Fp16_16x1);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_global_pool", 1, &scale_global_pool);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pool_size", 1, &pool_size);
        if (status != VX_SUCCESS) goto OnError;

    }
    else if (inputFormat == VX_TYPE_FLOAT16 && kernel_v == 2 && kernel_size_y == 2 && stride_v == 2 &&  pad_v == 0)
    {
        vx_float32    scale2x2_FP16toINT8 = div_scale;
        vx_uint32 uniAvg2x2_Stride2_4x4[16] = {
            0x55555555, // TCfg
            0x50505050, // ASelt
            0x32321010, 0x76765454, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000102, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };
        vx_uint32 uniFp16MulFp16toInt8_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toFp16ker2str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (outputFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toInt8ker2str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAvg2x2_Stride2_4x4", 1, uniAvg2x2_Stride2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulFp16toInt8_2x8", 1, uniFp16MulFp16toInt8_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale2x2_FP16toINT8", 1, &scale2x2_FP16toINT8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && kernel_v == 2 && kernel_size_y == 2 && stride_v == 2 &&  pad_v == 0)
    {
        vx_float32    scale2x2_INT8toINT8 = div_scale;
        vx_uint32 uniAvg2x2_Stride2_4x8[16] = {
            0xffffffff, 0xffffffff, // TCfg
            0x8628c020, 0x6ad0a49c, 0xe128bd8e, 0xacde96ac, 0xff9eeef1, // BinSelect
            0x00004402, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16MulFp16toInt8_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toInt8ker2str2pad0", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAvg2x2_Stride2_4x8", 1, uniAvg2x2_Stride2_4x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulFp16toInt8_2x8", 1, uniFp16MulFp16toInt8_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale2x2_INT8toINT8", 1, &scale2x2_INT8toINT8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && kernel_v == 5 && kernel_size_y == 5 && stride_v == 3)
    {
        vx_float32    scaleK5S3_INT8toINT8 = div_scale / (float)(kernel_v * kernel_v);
        vx_uint32 uniInt8AddInt8_k5s3_8x4[16] = {
            0x03ff03ff, 0x03ff03ff, // TCfg
            0x00418820, 0x73148300, 0xa0e60000, 0x490000a4, 0x0000d62d, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16mulF16_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16hi_8x4[16] = {
            0x003f003f, 0x003f003f, // TCfg
            0x00003080, 0x0034a100, 0x38c20000, 0xe3000000, 0x0000003c, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16Lo_8x4[16] = {
            0x003f003f, 0x003f003f, // TCfg
            0x00002080, 0x0024a100, 0x28c20000, 0xe3000000, 0x0000002c, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toInt8ker5str3", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8_k5s3_8x4", 1, uniInt8AddInt8_k5s3_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16mulF16_4x4", 1, uniS16mulF16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16hi_8x4", 1, uniS16AddS16hi_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16Lo_8x4", 1, uniS16AddS16Lo_8x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleK5S3_INT8toINT8", 1, &scaleK5S3_INT8toINT8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && kernel_v == 5 && kernel_size_y == 5 && stride_v == 3)
    {
        vx_float32    scaleK5S3_Fp16toFp16 = 1 / (float)(kernel_v * kernel_v);
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddFp16_k5s3Lo_8x2[16] = {
            0x01550155, // TCfg
            0x00000000, // ASelt
            0x00043210, 0x00076543, // ABin
            0x02aa02aa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x00003c00, 0x00000000, 0x3c003c00, 0x3c003c00, 0x00003c00, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toFp16ker5str3", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16_k5s3Lo_8x2", 1, uniFp16AddFp16_k5s3Lo_8x2);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleK5S3_Fp16toFp16", 1, &scaleK5S3_Fp16toFp16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && kernel_v == 5 && kernel_size_y == 5 && stride_v == 2)
    {
        vx_float32    scalek5s2p0_fp16tofp16 = 1 / (float)(kernel_v * kernel_v);
        vx_uint32 uniFp16AddFp16_k5s2p0Lo_8x2[16] = {
            0x01550155, // TCfg
            0x00000000, // ASelt
            0x00043210, 0x00065432, // ABin
            0x02aa02aa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x00003c00, 0x00000000, 0x3c003c00, 0x3c003c00, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toFp16ker5str2", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16_k5s2p0Lo_8x2", 1, uniFp16AddFp16_k5s2p0Lo_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scalek5s2p0_fp16tofp16", 1, &scalek5s2p0_fp16tofp16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && kernel_v == 3 && kernel_size_y == 3 && stride_v == 1)
    {
        vx_float32    scale_fp16tofp16 = 1 / (float)(kernel_v * kernel_v);
        vx_uint32 uniFp16AddFp16_4x4[16] = {
            0x15151515, // TCfg
            0x00000000, // ASelt
            0x03210210, 0x05430432, // ABin
            0x2a2a2a2a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000001, 0x00010001, 0x00000001, 0x00010001, 0x00000001, 0x00010001, 0x00000001 // Constant
        };
        vx_uint32 uniPackedHalf4_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toFp16ker3str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16_4x4", 1, uniFp16AddFp16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedHalf4_2x8", 1, uniPackedHalf4_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_fp16tofp16", 1, &scale_fp16tofp16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && in_width == 8 && kernel_v == 3 && kernel_size_y == 3 && stride_v == 1 &&  pad_v == 1)
    {
        vx_float32    scaleInt8_Int8_3_1_1 = div_scale * (1 / (float)(kernel_v * kernel_v));
        vx_uint32 uniS16MulS16toInt8_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8AddInt8_w8k3p1_4x8[16] = {
            0x3f3f3f3f, 0x0f3f3f3f, // TCfg
            0xc4100820, 0x30106200, 0x18a40148, 0xe601cc50, 0x00107020, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toInt8w8ker3str1pad1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16MulS16toInt8_2x8", 1, uniS16MulS16toInt8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8_w8k3p1_4x8", 1, uniInt8AddInt8_w8k3p1_4x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8_Int8_3_1_1", 1, &scaleInt8_Int8_3_1_1);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && kernel_v == 3 && kernel_size_y == 3 && stride_v == 1)
    {
        vx_float32    scaleInt8_Int8_3_1_1 = div_scale * (1 / (float)(kernel_v * kernel_v));
        vx_uint32 uniS16MulS16toInt8_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8AddInt8_4x8[16] = {
            0x3f3f3f3f, 0x3f3f3f3f, // TCfg
            0xc4100820, 0x30106200, 0x18a40148, 0xe601cc50, 0x02507020, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toInt8ker3str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16MulS16toInt8_2x8", 1, uniS16MulS16toInt8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8_4x8", 1, uniInt8AddInt8_4x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8_Int8_3_1_1", 1, &scaleInt8_Int8_3_1_1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16 && kernel_v == 13 && kernel_size_y == 13 && stride_v == 1)
    {
        vx_float32    scaleIn_kernel13 = div_scale * (1 / (float)(13 * 13));
        vx_uint32 uniInt8AddInt8_16x1[16] = {
            0x0fffffff, // TCfg
            0x00000000, // ASelt
            0x87654321, 0x00edcba9, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddInt8_4x4[16] = {
            0xe90909ad, // TCfg
            0x54040454, // ASelt
            0x00e0ed00, 0xf2100010, // ABin
            0x2a0a0aa2, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00010001, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000001 // Constant
        };
        vx_uint32 uniFp16Sum4Line_4x4[16] = {
            0x55555555, // TCfg
            0x50505050, // ASelt
            0x51514040, 0x73736262, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniFp16Sum2Line_4x4[16] = {
            0x15151515, // TCfg
            0x14141414, // ASelt
            0x05110400, 0x07330622, // ABin
            0x2a2a2a2a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000001, 0x00010001, 0x00000001, 0x00010001, 0x00000001, 0x00010001, 0x00000001 // Constant
        };
        vx_uint32 uniFp16Swap[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x07060504, 0x03020100, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };
        vx_uint32 uniFp16Sum1Line_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniDotScale_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddInt8Hi_4x4[16] = {
            0xe90909ad, // TCfg
            0x54040454, // ASelt
            0x00e4ed04, 0xf2140014, // ABin
            0x2a0a0aa2, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00010001, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000001 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toFp16ker13str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8_16x1", 1, uniInt8AddInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddInt8_4x4", 1, uniFp16AddInt8_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16Sum4Line_4x4", 1, uniFp16Sum4Line_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16Sum2Line_4x4", 1, uniFp16Sum2Line_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16Swap", 1, uniFp16Swap);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16Sum1Line_4x4", 1, uniFp16Sum1Line_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDotScale_4x4", 1, uniDotScale_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddInt8Hi_4x4", 1, uniFp16AddInt8Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleIn_kernel13", 1, &scaleIn_kernel13);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8 && kernel_v == 7 && kernel_size_y == 7 && stride_v == 1 &&  pad_v == 0 )
    {
        vx_float32    scale7x7_FP16_INT8 = div_scale * (1 / (float)(7 * 7));
        vx_uint32 uniFp16AddFp16_8x2[16] = {
            0x15551555, // TCfg
            0x00000000, // ASelt
            0x06543210, 0x07654321, // ABin
            0x2aaa2aaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00000001, 0x00010001, 0x00010001, 0x00010001, 0x00000001 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgFp16toInt8ker7str1pad0", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16_8x2", 1, uniFp16AddFp16_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale7x7_FP16_INT8", 1, &scale7x7_FP16_INT8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && kernel_v == 7 && kernel_size_y == 7 && stride_v == 1)
    {
        vx_float32    scale7x7_INT8_INT8 = div_scale * (1 / (float)(7 * 7));
        vx_uint32 uniInt8AddInt8Lo_8x4[16] = {
            0x3fff3fff, 0x3fff3fff, // TCfg
            0x8a418820, 0x520c4101, 0x906201cc, 0x83020e62, 0x02507314, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8AddInt8Hi_8x4[16] = {
            0x3fff3fff, 0x3fff3fff, // TCfg
            0x8a452507, 0x55a92801, 0x2d4901cc, 0x6a020e66, 0x025076b1, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniDotScale_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toInt8ker7str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Lo_8x4", 1, uniInt8AddInt8Lo_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Hi_8x4", 1, uniInt8AddInt8Hi_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16_2x8", 1, uniS16AddS16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDotScale_2x8", 1, uniDotScale_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8_Int8_7_1_0", 1, &scale7x7_INT8_INT8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16 && kernel_v == 6 && kernel_size_y == 6 && stride_v == 1)
    {
        vx_float32    scaleInt8_FP16_6_1_0 = div_scale * (1 / (float)(6 * 6));
        vx_uint32 uniS16AddS16Kernel6_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniInt8AddInt8Kernel6Lo_8x4[16] = {
            0x0fff0fff, 0x0fff0fff, // TCfg
            0x0a418820, 0x520c4100, 0x9062000c, 0x83000e62, 0x00107314, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8AddInt8Kernel6Hi_8x4[16] = {
            0x0fff0fff, 0x0fff0fff, // TCfg
            0x128398a4, 0x941cc500, 0xa0e60014, 0x070016a4, 0x0018b525, // BinSelect
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16DotFP16_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgInt8toFp16ker6str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16Kernel6_2x8", 1, uniS16AddS16Kernel6_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Kernel6Lo_8x4", 1, uniInt8AddInt8Kernel6Lo_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Kernel6Hi_8x4", 1, uniInt8AddInt8Kernel6Hi_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16DotFP16_2x8", 1, uniS16DotFP16_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8_FP16_6_1_0", 1, &scaleInt8_FP16_6_1_0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_v);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_y);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT8))
    {
        vx_float32    genericAvgScale     = div_scale / (float)(kernel_v * kernel_size_y);
        vx_int32 kernelsize[2]            = {kernel_v, kernel_size_y};
        vx_int32 padding[2]               = {pad_v, pad_y};
        vx_int32 stride[2]                = {stride_v, stride_v};
        vx_int32 x_len_8x                 = kernel_v / 8 * 8;
        vx_int32 x_len_remain             = kernel_v - x_len_8x;
        vx_int32 enable_int8_format       = outputFormat == VX_TYPE_INT8 ? 1 : 0;
        vx_uint32 uniAcc8BinFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniConfig[8] = {0x00000000, 0x00000001, 0x00000005 ,0x00000015, 0x00000055, 0x00000155, 0x00000555, 0x00001555};

        vx_uint32 uniAccNBinFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        uniAccNBinFp16_16x1[0] = uniConfig[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_fp16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinFp16_16x1", 1, uniAcc8BinFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinFp16_16x1", 1, uniAccNBinFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_int8_format", 1, &enable_int8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genericAvgScale", 1, &genericAvgScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT8))
    {
        vx_float32    genericAvgScale     = div_scale / (float)(kernel_v * kernel_size_y);
        vx_int32 kernelsize[2]            = {kernel_v, kernel_size_y};
        vx_int32 padding[2]               = {pad_v, pad_y};
        vx_int32 stride[2]                = {stride_v, stride_v};
        vx_int32 x_len_8x                 = kernel_v / 8 * 8;
        vx_int32 x_len_remain             = kernel_v - x_len_8x;
        vx_int32 enable_int8_format       = outputFormat == VX_TYPE_INT8 ? 1 : 0;
        vx_uint32 uniAcc8BinInt8_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniConfig[8] = {0x00000000, 0x00000001, 0x00000005 ,0x00000015, 0x00000055, 0x00000155, 0x00000555, 0x00001555};

        vx_uint32 uniAccNBinInt8_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        uniAccNBinInt8_16x1[0] = uniConfig[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_int8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinInt8_16x1", 1, uniAcc8BinInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinInt8_16x1", 1, uniAccNBinInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_int8_format", 1, &enable_int8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genericAvgScale", 1, &genericAvgScale);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (globalPooling_flag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 0;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }
    else
    {
        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = globalWorkSize1 == 1 ? 1 : (globalWorkSize1  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcAvgPooling_Int16****************************************************/
vxnne_shader_executable vxnneGetAvgPooling_Int16ShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               poolType,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pool_pad_x_left,
    vx_uint32               pool_pad_y_top,
    vx_scalar               rounding,
    vx_int32                activation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[3]      = {(vx_reference)input, VX_NULL, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch              = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    dims               = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    stride_v           = stride_s->value->u32;
    vx_uint32    kernel_size_x      = poolSizeX->value->u32;
    vx_uint32    kernel_size_y      = poolSizeY->value->u32;
    vx_uint32    pad_v              = pool_pad_x_left;
    vx_uint32    pad_y              = pool_pad_y_top;
    vx_scalar    in_heights         = NULL;
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_bool      globalPooling_flag = (vx_bool)(out_width == 1 && out_height == 1 && kernel_size_x == in_width && kernel_size_y == in_height);
    vx_float32   div_scale          = 1.0f;
    vx_uint32    height             = (out_height - 1) * stride_v + kernel_size_y - 2 * pad_y;
    vx_uint32    width              = (out_width - 1) * stride_v + kernel_size_x - 2 * pad_v;
    vx_uint32    rs_width           = 0;
    vx_uint32    pad_left           = pad_v;
    vx_uint32    pad_top            = pad_y;
    vx_float32   scale              = 1.0f;
    vx_uint16    minData            = 0;
    vx_uint16    maxData            = 0;
    vx_int32     packedMin          = 0;
    vx_int32     packedMax          = 0;
    vx_uint32    globalWorkSize1    = 1;
    vx_int32     packedMinData[4]   = {0};
    vx_int32     packedMaxData[4]   = {0};
    vx_float32   fdiv_scale         = div_scale * (1 / (float)(kernel_size_x * kernel_size_y));
    vx_bool      useImage2DFlag     = (vx_bool)(in_width * in_height < IMG_MAX_WIDTH);
    vx_uint32    maxWorkGroupSize   = 8;
    char *programSources = NULL;

    vx_uint32 uniExtact16Bit_2x8[16] = {
        0x33333333, // TCfg
        0x11110000, // ASelt
        0x03020100, 0x03020100, // ABin
        0x00000000, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00002400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 Uni2x8_Int32toInt16[16] = {
        0x33333333, // TCfg
        0x11110000, // ASelt
        0x03020100, 0x03020100, // ABin
        0x00000000, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00002400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    globalPooling_flag = (vx_bool)(globalPooling_flag & useImage2DFlag);

    if (height != in_height)
    {
        if (out_height < height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }
    else
    {
        if (out_height < in_height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &in_height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }

    parameters[1] = (vx_reference)in_heights;

    if (inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            div_scale *= (vx_float32)(1 << -srcFixPointPos);
        }
    }
    if (outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            div_scale *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    fdiv_scale = fdiv_scale*div_scale;

    calculateActivationRangeInt16(activation, dstFixPointPos, (vx_int16*)(&minData), (vx_int16*)(&maxData), VX_ROUND_POLICY_TO_NEAREST_EVEN);
    packedMin = (minData << 16) | (minData);
    packedMax = (maxData << 16) | (maxData);

    packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
    packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

    if (globalPooling_flag)
    {
        vx_int32 src_sizes[4] = {in_width * in_height, depth, 1, batch};
        vx_int32 dst_sizes[4] = {1, depth, 1, batch};
        borderMode->mode = VX_BORDER_CONSTANT;
        input_rs         = vxoTensor_ReshapeTensor(input, src_sizes, dims);
        output_rs        = vxoTensor_ReshapeTensor(output, dst_sizes, dims);
        rs_width = in_width * in_height;
        if (inputFormat == VX_TYPE_INT16)
        {
            borderMode->constant_value.S16 = 0;
        }

        parameters[0] = (vx_reference)input_rs;
        parameters[2] = (vx_reference)output_rs;
    }
    else if (pad_v != 0 || height != in_height || width != in_width)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        if (inputFormat == VX_TYPE_INT16)
        {
            borderMode->constant_value.S16 = 0;
        }
    }
    else
    {
        borderMode->mode = VX_BORDER_REPLICATE;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, AvgPooling_Int16, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/AvgPooling_Int16.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcAvgPooling", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (globalPooling_flag && outputFormat == VX_TYPE_INT16 )
    {
        vx_uint32 Uni16x1_Sum16[16] = {
            0xffffffff, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_globalstr1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "rs_width", 1, &rs_width);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni16x1_Sum16", 1, Uni16x1_Sum16);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 2 && kernel_size_y == 2 && stride_v == 2)
    {
        vx_uint32 UniS16AddDiv4toFloat_dp4x4[16] = {
            0xffffffff, // TCfg
            0x50505050, // ASelt
            0x32321010, 0x76765454, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003402, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        scale = div_scale;
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toInt16ker2str2pad0", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale", 1, &scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS16AddDiv4toFloat_dp4x4", 1, UniS16AddDiv4toFloat_dp4x4);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 5 && kernel_size_y == 5 && stride_v == 2)
    {
        vx_uint32 Uni16x2_Add_K5S2[16] = {
            0x03ff03ff, 0x03ff03ff, // TCfg
            0x00418820, 0xc5a92800, 0x90620000, 0x6a000062, 0x0000e6b1, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ker5str2", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni16x2_Add_K5S2", 1, Uni16x2_Add_K5S2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_height", 1, &out_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 13 && kernel_size_y == 13 && stride_v == 1 ) //kernel=13,7,6,3 stride=1 pad = xx
    {
        vx_uint32 Uni16x2_Add13[16] = {
            0x03ffffff, 0x03ffffff, // TCfg
            0x8a418820, 0xc5a92839, 0x0c410000, 0x4941cc52, 0x0000d62d, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ker13str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni16x2_Add13", 1, Uni16x2_Add13);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_height", 1, &out_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 7 && kernel_size_y == 7 && stride_v == 1)
    {
        vx_uint32 Uni16x2_Add14[16] = {
            0x3fff3fff, 0x3fff3fff, // TCfg
            0x8a418820, 0xc5a92801, 0x0c41039a, 0x4901cc52, 0x03dcd62d, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ker7str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni16x2_Add14", 1, Uni16x2_Add14);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_height", 1, &out_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);

        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 6 && kernel_size_y == 6 && stride_v == 1)
    {
        vx_uint32 Uni16x2_Add12[16] = {
            0x0fff0fff, 0x0fff0fff, // TCfg
            0x0a418820, 0xc5a92800, 0x0c41001a, 0x49000c52, 0x001cd62d, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ker6str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_height", 1, &out_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni16x2_Add12", 1, Uni16x2_Add12);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat== VX_TYPE_INT16 && kernel_size_x == 3 && kernel_size_y == 3 && stride_v == 1)
    {
        vx_uint32 Uni8x4_Add6[16] = {
            0x3f3f3f3f, 0x3f3f3f3f, // TCfg
            0x92800820, 0x900c4102, 0x106202d4, 0x830316a0, 0x0358b014, // BinSelect
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_ker3str1", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fdiv_scale", 1, &fdiv_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_height", 1, &out_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int32toInt16", 1, Uni2x8_Int32toInt16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni8x4_Add6", 1, Uni8x4_Add6);
        if (status != VX_SUCCESS) goto OnError;


        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;

    }
    else if (inputFormat == VX_TYPE_INT16 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT16))
    {
        vx_float32   genericAvgScale          = fdiv_scale;
        vx_int32     minData                  = 0;
        vx_int32     maxData                  = 0;
        vx_int32     kernelsize[2]            = {kernel_size_x, kernel_size_y};
        vx_int32     padding[2]               = {pad_left, pad_top};
        vx_int32     stride[2]                = {stride_v, stride_v};
        vx_int32     x_len_8x                 = kernel_size_x / 8 * 8;
        vx_int32     x_len_remain             = kernel_size_x - x_len_8x;
        vx_int32     enable_int16_format      = outputFormat == VX_TYPE_INT16 ? 1 : 0;

        vx_uint32 uniAcc8BinInt16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniConfig[8] = {0x00000000, 0x00000001, 0x00000005 ,0x00000015, 0x00000055, 0x00000155, 0x00000555, 0x00001555};

        vx_uint32 uniAccNBinInt16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x0000aaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        uniAccNBinInt16_16x1[0] = uniConfig[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_int16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinInt16_16x1", 1, uniAcc8BinInt16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinInt16_16x1", 1, uniAccNBinInt16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_int16_format", 1, &enable_int16_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genericAvgScale", 1, &genericAvgScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    if (globalPooling_flag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 0;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }
    else
    {

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = globalWorkSize1 == 1 ? 1 : (globalWorkSize1  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetAvgPooling_UInt8ShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               poolType,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pool_pad_x_left,
    vx_uint32               pool_pad_y_top,
    vx_scalar               rounding,
    vx_int32                activation,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[3]      = {(vx_reference)input, VX_NULL, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_int32     input_ZP           = TENSOR_TF_ZEROPOINT(input);
    vx_uint32    batch              = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int32     output_ZP          = TENSOR_TF_ZEROPOINT(output);
    vx_uint32    dims               = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    stride_v           = stride_s->value->u32;
    vx_uint32    kernel_size_x      = poolSizeX->value->u32;
    vx_uint32    kernel_size_y      = poolSizeY->value->u32;
    vx_uint32    pad_left           = pool_pad_x_left;
    vx_uint32    pad_top            = pool_pad_y_top;
    vx_scalar    in_heights         = NULL;
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_bool      globalPooling_flag = (vx_bool)(out_width == 1 && out_height == 1 && kernel_size_x == in_width && kernel_size_y == in_height);
    vx_float32   scaleIn            = 1.0f;
    vx_float32   scaleOut           = 1.0f;
    vx_uint32    height             = (out_height - 1) * stride_v + kernel_size_y - 2 * pad_top;
    vx_uint32    width              = (out_width - 1) * stride_v + kernel_size_x - 2 * pad_left;
    vx_uint32    globalWorkSize1    = 1;
    vx_bool      useImage2DFlag     = (vx_bool)(in_width * in_height < IMG_MAX_WIDTH);
    vx_uint32    maxWorkGroupSize   = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    globalPooling_flag = (vx_bool)(globalPooling_flag & useImage2DFlag);

    if (height != in_height)
    {
        if (out_height < height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }
    else
    {
        if (out_height < in_height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &in_height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }

    parameters[1] = (vx_reference)in_heights;

    if (inputFormat == VX_TYPE_INT8)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn *= (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn *= TENSOR_TF_SCALE(input);
    }


    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut *= TENSOR_TF_SCALE(output);
    }

    if (globalPooling_flag)
    {
        vx_int32 src_sizes[4] = {in_width * in_height, depth, 1, batch};
        vx_int32 dst_sizes[4] = {1, depth, 1, batch};
        borderMode->mode = VX_BORDER_CONSTANT;
        input_rs         = vxoTensor_ReshapeTensor(input, src_sizes, dims);
        output_rs        = vxoTensor_ReshapeTensor(output, dst_sizes, dims);

        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_UINT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }

        parameters[0] = (vx_reference)input_rs;
        parameters[2] = (vx_reference)output_rs;
    }
    else if (pad_left != 0 || pad_top != 0 || height != in_height || width != in_width)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_UINT8)
        {
            borderMode->constant_value.U8 = (vx_uint8)input_ZP;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }
    }
    else
    {
        borderMode->mode = VX_BORDER_REPLICATE;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, AvgPooling_UInt8, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        if ((inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
            || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_UINT8)
            || (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
            || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
        {
            vxmONERROR(getFilePath("nnvxc_kernels/AvgPooling_UInt8.vx", path));

            vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

            vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

            if (programSources)
            {
                vxFree(programSources);
                programSources = NULL;
            }
        }
        else
        {
            vxError("data format not support %s line %d", __FUNCTION__, __LINE__);
            goto OnError;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcPooling", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (globalPooling_flag && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint8     minData            = 0;
        vx_uint8     maxData            = 0;
        vx_int32     packedMin          = 0;
        vx_int32     packedMax          = 0;
        vx_int32     packedMinData[4]   = {0};
        vx_int32     packedMaxData[4]   = {0};
        vx_float32   uint8Scale_in      = scaleIn;
        vx_float32   uint8qScale_out    = 1 / (float)(kernel_size_x * kernel_size_y * scaleOut);
        vx_float32   uint8ZP_out        = (vx_float32)output_ZP;
        vx_float32   uint8ConstData_in  = (vx_float32)input_ZP * kernel_size_x * kernel_size_y * scaleIn;
        vx_int32     pool_size          = gcmALIGN_SAFE(kernel_size_x * kernel_size_y, 64);
        vx_uint32 uniAcc32U8_32x1[16] = {
            0xffffffff, 0xffffffff, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minData, &maxData, 0, 65536);

        packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
        packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);
        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (kernel_size_x * kernel_size_y <= 64)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvgUInt8K1_K8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_GlobalAvg_UInt8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc32U8_32x1", 1, uniAcc32U8_32x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale_in", 1, &uint8Scale_in);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8qScale_out", 1, &uint8qScale_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ConstData_in", 1, &uint8ConstData_in);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8ZP_out", 1, &uint8ZP_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pool_size", 1, &pool_size);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && kernel_size_x == 3 && kernel_size_y == 3 && stride_v == 1)
    {
        vx_uint16    M0                 = 0;
        vx_int8      postShift          = 0;
        vx_uint8     minData            = 0;
        vx_uint8     maxData            = 0;
        vx_int32     packedMin          = 0;
        vx_int32     packedMax          = 0;
        vx_int32     packedMinData[4]   = {0};
        vx_int32     packedMaxData[4]   = {0};
        vx_uint32    multAndoutZP[4]    = {0};
        vx_float32   uint8Scale         = scaleIn / (scaleOut * (float)(kernel_size_x * kernel_size_y));
        vx_float32   output_zeroPoint   = (vx_float32)output_ZP;
        vx_uint64    outputZP_scale     = 0;
        vx_uint32 uni8BAdd_SubNZP_k3s1_4x8[16] = {
            0x95959595, 0x95959595, // TCfg
            0xc4180820, 0x38106280, 0x18a48148, 0xe681cc58, 0x82507820, // BinSelect
            0x00000700, // AccumType, ConstantType, and PostShift
            0x03010101, 0x03010101, 0x03010101, 0x03010101, 0x03010101, 0x03010101, 0x03010101, 0x03010101 // Constant
        };
        vx_uint32 uniS16AddS16toF32Part0_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000600, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16toF32Part1_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000600, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniMACandShiftN_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x13121110, 0x17161514, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00005400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        getFP32M0AndN(uint8Scale, &M0, &postShift);

        multAndoutZP[0] = (vx_uint32)M0;
        multAndoutZP[1] = (vx_uint32)(output_ZP << postShift);
        outputZP_scale  = (vx_uint64)(output_ZP << postShift);

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minData, &maxData, 0, 65536);

        packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
        packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);
        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        if (postShift >= 0 && postShift < 32 && outputZP_scale < 0xFFFFFFFF)
        {
            uniMACandShiftN_2x8[7]   = uniMACandShiftN_2x8[7] | postShift;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgUInt8toUInt8K3S1_Fast", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgUInt8toUInt8K3S1", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uni8BAdd_SubNZP_k3s1_4x8", 1, uni8BAdd_SubNZP_k3s1_4x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16toF32Part0_4x4", 1, uniS16AddS16toF32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16toF32Part1_4x4", 1, uniS16AddS16toF32Part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMACandShiftN_2x8", 1, uniMACandShiftN_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && kernel_size_x == kernel_size_y && (kernel_size_x == 7 || kernel_size_x == 6) && stride_v == 1)
    {
        vx_uint8     minData            = 0;
        vx_uint8     maxData            = 0;
        vx_int32     packedMin          = 0;
        vx_int32     packedMax          = 0;
        vx_int32     packedMinData[4]   = {0};
        vx_int32     packedMaxData[4]   = {0};
        vx_float32   uint8Scale            = scaleIn / (scaleOut * (float)(kernel_size_x * kernel_size_y));
        vx_float32   output_zeroPoint    = (vx_float32)output_ZP;
        vx_uint32 uniAcc7DataSubZPLo_8x4[16] = {
            0xbfffbfff, 0xbfffbfff, // TCfg
            0x8a418820, 0x520c4181, 0x906281cc, 0x83820e62, 0x82507314, // BinSelect
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x07000000, 0x00000000, 0x07000000, 0x00000000, 0x07000000, 0x00000000, 0x07000000 // Constant
        };
        vx_uint32 uniAcc7DataSubZPHi_8x4[16] = {
            0xbfffbfff, 0xbfffbfff, // TCfg
            0x928398a4, 0x941cc582, 0xa0e682d4, 0x078316a4, 0x8358b525, // BinSelect
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x07000000, 0x00000000, 0x07000000, 0x00000000, 0x07000000, 0x00000000, 0x07000000 // Constant
        };
        vx_uint32 uniAcc6DataSubZPLo_8x4[16] = {
            0x8fff8fff, 0x8fff8fff, // TCfg
            0x0a418820, 0x520c4180, 0x9062800c, 0x83800e62, 0x80107314, // BinSelect
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x06000000, 0x00000000, 0x06000000, 0x00000000, 0x06000000, 0x00000000, 0x06000000 // Constant
        };
        vx_uint32 uniAcc6DataSubZPHi_8x4[16] = {
            0x8fff8fff, 0x8fff8fff, // TCfg
            0x128398a4, 0x941cc580, 0xa0e68014, 0x078016a4, 0x8018b525, // BinSelect
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x06000000, 0x00000000, 0x06000000, 0x00000000, 0x06000000, 0x00000000, 0x06000000 // Constant
        };
        vx_uint32 uniS16AddS16toFP32Lo_4x4[16] = {
            0x0f0f0f0f, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS16AddS16toFP32Hi_4x4[16] = {
            0x0f0f0f0f, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minData, &maxData, 0, 65536);

        packedMin = (minData << 24) | (minData << 16) | (minData << 8) | (minData);
        packedMax = (maxData << 24) | (maxData << 16) | (maxData << 8) | (maxData);
        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        if (kernel_size_x == 6)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgUInt8toUInt8K6S1", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AvgUInt8toUInt8K7S1", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc7DataSubZPLo_8x4", 1, uniAcc7DataSubZPLo_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc7DataSubZPHi_8x4", 1, uniAcc7DataSubZPHi_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc6DataSubZPLo_8x4", 1, uniAcc6DataSubZPLo_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc6DataSubZPHi_8x4", 1, uniAcc6DataSubZPHi_8x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16toFP32Lo_4x4", 1, uniS16AddS16toFP32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddS16toFP32Hi_4x4", 1, uniS16AddS16toFP32Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_left", 1, &pad_left);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad_top", 1, &pad_top);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_UINT8))
    {
        vx_uint8     minVal               = 0;
        vx_uint8     maxVal               = 0;
        vx_uint32    minData              = 0;
        vx_uint32    maxData              = 0;
        vx_float32   uint8Scale           = scaleIn / (scaleOut * (float)(kernel_size_x * kernel_size_y));
        vx_float32   output_zeroPoint     = (vx_float32)output_ZP;
        vx_int32 kernelsize[2]            = {kernel_size_x, kernel_size_y};
        vx_int32 padding[2]               = {pad_left, pad_top};
        vx_int32 stride[2]                = {stride_v, stride_v};
        vx_int32 x_len_8x                 = kernel_size_x / 8 * 8;
        vx_int32 x_len_remain             = kernel_size_x - x_len_8x;
        vx_int32 enable_uint8_format      = outputFormat == VX_TYPE_UINT8 ? 1 : 0;

        vx_uint32 uniAcc8BinUInt8_16x1[16] = {
            0xaaaa5555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x00000000, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };

        vx_uint32 uniUInt8Config[8] = {0x00000000, 0x00020001, 0x000a0005 ,0x002a0015, 0x00aa0055, 0x02aa0155, 0x0aaa0555, 0x2aaa1555};

        vx_uint32 uniAccNBinUInt8_16x1[16] = {
            0xaaaa5555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x00000000, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

        minData = (vx_uint32)minVal;
        maxData = (vx_uint32)maxVal;

        uniAccNBinUInt8_16x1[0] = uniUInt8Config[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_uint8", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinUInt8_16x1", 1, uniAcc8BinUInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinUInt8_16x1", 1, uniAccNBinUInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    if (globalPooling_flag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 0;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }
    else
    {
        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = globalWorkSize1 == 1 ? 1 : (globalWorkSize1  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcMaxPooling****************************************************/
vxnne_shader_executable vxnneGetMaxPoolingShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               poolType,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pool_pad_x_left,
    vx_uint32               pool_pad_y_top,
    vx_scalar               rounding,
    vx_int32                activation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[10] = {(vx_reference)input, VX_NULL, VX_NULL, VX_NULL, VX_NULL, VX_NULL, (vx_reference)stride_s, (vx_reference)poolSizeX, VX_NULL, (vx_reference)output};
    vx_enum   inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum   outputFormat      = TENSOR_DATA_TYPE(output);
    vx_uint32 in_width          = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32 in_height         = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32 depth             = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32 out_width         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32 out_height        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32 stride_v          = stride_s->value->u32;
    vx_uint32 kernel_v          = poolSizeX->value->u32;
    vx_uint32 kernelSizeY       = poolSizeY->value->u32;
    vx_uint32 pad_v             = pool_pad_x_left;
    vx_uint32 padY              = pool_pad_y_top;
    vx_scalar poolPadX          = vxCreateScalar(context, VX_TYPE_UINT32, &pool_pad_x_left);
    vx_scalar in_widths         = vxCreateScalar(context, VX_TYPE_UINT32, &in_width);
    vx_scalar in_heights        = vxCreateScalar(context, VX_TYPE_UINT32, &in_height);
    vx_scalar depth_s           = vxCreateScalar(context, VX_TYPE_UINT32, &depth);
    vx_scalar out_widths        = vxCreateScalar(context, VX_TYPE_UINT32, &out_width);
    vx_scalar out_heights       = vxCreateScalar(context, VX_TYPE_UINT32, &out_height);
    vx_int32 in_zeros_point     = TENSOR_TF_ZEROPOINT(input);
    vx_int32 out_zeros_point    = TENSOR_TF_ZEROPOINT(output);
    vx_bool   enable_setExecutParam = vx_false_e;

    vx_int8    input_fractionLengthValue  = TENSOR_POS(input);
    vx_int8    output_fractionLengthValue = TENSOR_POS(output);
    vx_int8    div_fractionLengthValue    = input_fractionLengthValue - output_fractionLengthValue;
    vx_float32 out_scale                  = 1.0f;
    vx_float32 div_scale                  = 1.0f;
    vx_float32 in_scale                   = TENSOR_TF_SCALE(input);
    vx_float32 uint8_zp                   = 0.0f;
    vx_float32 uint8_scale                = 0.0f;
    vx_int32   kernelSize[2]              = {kernel_v, kernelSizeY};
    vx_int32   stride[2]                  = {stride_v, stride_v};
    vx_int32   pad[2]                     = {pad_v, padY};
    vx_int32   kernelXis8x                = kernel_v / 8;
    vx_int32   kernelXremain              = kernel_v % 8;
    vx_uint32  maxWorkGroupSize           = 8;
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    parameters[1] = (vx_reference)in_widths;
    parameters[2] = (vx_reference)in_heights;
    parameters[3] = (vx_reference)depth_s;
    parameters[4] = (vx_reference)out_widths;
    parameters[5] = (vx_reference)out_heights;
    parameters[8] = (vx_reference)poolPadX;

    borderMode->mode = VX_BORDER_REPLICATE;
    if (output_fractionLengthValue >= 0)
    {
        out_scale = (vx_float32) (1 << output_fractionLengthValue);
    }
    else if (output_fractionLengthValue < 0)
    {
        out_scale = 1.0f / (vx_float32) (1 << -output_fractionLengthValue);
    }
    if (div_fractionLengthValue >= 0)
    {
        div_scale = 1.0f / (vx_float32) (1 << div_fractionLengthValue);
    }
    else if (div_fractionLengthValue < 0)
    {
        div_scale = (vx_float32) (1 << -div_fractionLengthValue);
    }

    if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        out_scale = TENSOR_TF_SCALE(output);
        uint8_scale = in_scale / out_scale;
        uint8_zp = out_zeros_point - in_zeros_point * uint8_scale;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, MaxPooling, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/MaxPooling.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status  = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "vxcPooling", program, 10, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (kernel_v == 1 && kernelSizeY == 1 && stride_v == 2 && pad_v == 0 && padY == 0)
    {
        vx_uint32 uniPackEvenData_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16) || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16))
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_max16BitsK1S2P0", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_max8BitsK1S2P0", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 2;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((in_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (in_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;

        enable_setExecutParam = vx_true_e;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackEvenData_2x8", 1, uniPackEvenData_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint8    minVal    = 0;
        vx_uint8    maxVal    = 0;
        vx_int32    packedMin = 0;
        vx_int32    packedMax = 0;
        vx_int32    packedMinData[4];
        vx_int32    packedMaxData[4];

        vx_uint32 uniConvertDirUint8Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertEndUint8Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniExtractMaxStride2Uint8ToFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniUint8ExtractN_dp2x8[16] = {
            0x33333333, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfigUint8ExtractN[8] = {0x11111111, 0x11111110, 0x11111100 ,0x11111000, 0x11110000, 0x11100000, 0x11000000, 0x10000000};
        vx_uint32 uniUint8toFp32_dp16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        uniUint8ExtractN_dp2x8[1] = uniConfigUint8ExtractN[kernelXremain];

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

        packedMin = ((minVal << 24) | (minVal << 16) | (minVal << 8) | (minVal));
        packedMax = ((maxVal << 24) | (maxVal << 16) | (maxVal << 8) | (maxVal));

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (kernel_v == 3 && stride_v == 1 && pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxUint8knl3str1pad1", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractMaxStride2Uint8ToFp32_4x4", 1, uniExtractMaxStride2Uint8ToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirUint8Fp32_4x4", 1, uniConvertDirUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndUint8Fp32_4x4", 1, uniConvertEndUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpScale", 1, &uint8_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZP", 1, &uint8_zp);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinVal", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxVal", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 2 && pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxUint8knl3str2pad1", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractMaxStride2Uint8ToFp32_4x4", 1, uniExtractMaxStride2Uint8ToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirUint8Fp32_4x4", 1, uniConvertDirUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndUint8Fp32_4x4", 1, uniConvertEndUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpScale", 1, &uint8_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZP", 1, &uint8_zp);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinVal", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxVal", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genMaxUint8toUint8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSize", 1, kernelSize);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad", 1, pad);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXis8x", 1, &kernelXis8x);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXremain", 1, &kernelXremain);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genDivScale", 1, &uint8_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genOutZP", 1, &uint8_zp);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8ExtractN_dp2x8", 1, uniUint8ExtractN_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8toFp32_dp16x1", 1, uniUint8toFp32_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGenConvertInt32toUint8_dp2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMinData", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMaxData", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
            if (status != VX_SUCCESS) goto OnError;
            execution_parameters.globalWorkScale[0]  = 1;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
            execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
            execution_parameters.globalWorkSize[2]   = depth;

            enable_setExecutParam = vx_true_e;
        }
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        vx_uint16   minData   = 0;
        vx_uint16   maxData   = 0;
        vx_int32    packedMin = 0;
        vx_int32    packedMax = 0;
        vx_int32    packedMinData[4];
        vx_int32    packedMaxData[4];

        vx_uint32 UniInt16toFloat4Lo_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniInt16toFloat4Hi_4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        calculateActivationRangeInt16(activation, output_fractionLengthValue, (vx_int16*)(&minData), (vx_int16*)(&maxData), VX_ROUND_POLICY_TO_NEAREST_EVEN);
        packedMin = (minData << 16) | (minData);
        packedMax = (maxData << 16) | (maxData);

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (kernel_v == 3 && stride_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxInt16ker3str1pad1", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            vx_uint32 uniInt16ExtractN_dp2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };
            vx_uint32 uniConfigInt16ExtractN[8] = {0x11111111, 0x11111110, 0x11111100 ,0x11111000, 0x11110000, 0x11100000, 0x11000000, 0x10000000};
            uniInt16ExtractN_dp2x8[1] = uniConfigInt16ExtractN[kernelXremain];

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genMaxInt16toInt16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSize", 1, kernelSize);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad", 1, pad);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXis8x", 1, &kernelXis8x);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXremain", 1, &kernelXremain);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16ExtractN_dp2x8", 1, uniInt16ExtractN_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMinData", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMaxData", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]  = 1;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
            if (out_width >= execution_parameters.globalWorkScale[0] * 8)
            {
                execution_parameters.localWorkSize[0]    = 8;
                execution_parameters.localWorkSize[1]    = 1;
                execution_parameters.localWorkSize[2]    = 1;
            }
            else if (out_width >= execution_parameters.globalWorkScale[0] * 4)
            {
                execution_parameters.localWorkSize[0]    = 4;
                execution_parameters.localWorkSize[1]    = 2;
                execution_parameters.localWorkSize[2]    = 1;
            }
            else
            {
                vx_uint32 factor = 1;
                execution_parameters.localWorkSize[0]    = 1;
                execution_parameters.localWorkSize[1]    = 1;
                if (depth <= maxWorkGroupSize)
                    execution_parameters.localWorkSize[2]    = depth;
                else if (checkGetDataFactor(depth, &factor, 2, maxWorkGroupSize, 8) == VX_SUCCESS)
                    execution_parameters.localWorkSize[2]    = factor;
                else
                    execution_parameters.localWorkSize[2]    = 1;
            }
            execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]);
            execution_parameters.globalWorkSize[1]   = gcmALIGN((out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
            execution_parameters.globalWorkSize[2]   = depth;

            enable_setExecutParam = vx_true_e;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Lo_4x4", 1, UniInt16toFloat4Lo_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniInt16toFloat4Hi_4x4", 1, UniInt16toFloat4Hi_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "divSrc4_scale", 1, &div_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMaxData", 1, packedMaxData);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16)
    {
        vx_int16    minData   = 0;
        vx_int16    maxData   = 0;
        vx_int32    packedMin = 0;
        vx_int32    packedMax = 0;
        vx_int32    packedMinData[4];
        vx_int32    packedMaxData[4];

        vx_uint32 UniPackMaxPool2x8_fp16[16] = {
            0x00111111, // TCfg
            0x00111000, // ASelt
            0x00040200, 0x00000402, // ABin
            0x00222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniPackFP16even_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 UniPackFP16odd_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x07050301, 0x07050301, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 UniFP16Mul_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16ExtractN_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 uniConfigFp16ExtractN[8] = {0x11111111, 0x11111110, 0x11111100 ,0x11111000, 0x11110000, 0x11100000, 0x11000000, 0x10000000};
        uniFp16ExtractN_dp2x8[1] = uniConfigFp16ExtractN[kernelXremain];

        calculateActivationRangeFloat16(activation, &minData, &maxData);
        packedMin = (minData << 16) | (minData);
        packedMax = (maxData << 16) | (maxData);

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (kernel_v == 3 && stride_v == 2 &&  pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxfp16ker3str2pad1", borderMode);
            if (!shaderExecutable) goto OnError;
            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackMaxPool2x8_fp16", 1, UniPackMaxPool2x8_fp16);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 2 && stride_v == 2 &&  pad_v == 0)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxfp16ker2str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackFP16even_2x8", 1, UniPackFP16even_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackFP16odd_2x8", 1, UniPackFP16odd_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 2 &&  pad_v == 0)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxfp16ker3str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackMaxPool2x8_fp16", 1, UniPackMaxPool2x8_fp16);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 1 &&  pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxfp16ker3str1pad1", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16MulSrc3_dp2x8", 1, UniFP16Mul_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outSrc3_scale", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat3", 1, &outputFormat);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genMaxFp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSize", 1, kernelSize);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad", 1, pad);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXis8x", 1, &kernelXis8x);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXremain", 1, &kernelXremain);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16ExtractN_dp2x8", 1, uniFp16ExtractN_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMinData", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMaxData", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]  = 1;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
            execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
            execution_parameters.globalWorkSize[2]   = depth;

            enable_setExecutParam = vx_true_e;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16Mul_dp2x8", 1, UniFP16Mul_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale", 1, &out_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat1", 1, &outputFormat);
        if (status != VX_SUCCESS) goto OnError;
    }
    else
    {
        vx_uint8    minVal    = 0;
        vx_uint8    maxVal    = 0;
        vx_int32    packedMin = 0;
        vx_int32    packedMax = 0;
        vx_int32    packedMinData[4];
        vx_int32    packedMaxData[4];

        vx_uint32 UniMaxPoolS8xFp16_dp2x8[16] = {
            0x00111111, // TCfg
            0x00000000, // ASelt
            0x06040200, 0x00000a08, // ABin
            0x00111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniS8xFp16Packeven_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x06040200, 0x0e0c0a08, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniS8xFp16Packodd_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x07050301, 0x0f0d0b09, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniS8xFp16_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS8xFp16Head8_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniS8xFp16Last8_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x0b0a0908, 0x0f0e0d0c, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniUint8ExtractN_dp2x8[16] = {
            0x33333333, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfigUint8ExtractN[8] = {0x11111111, 0x11111110, 0x11111100 ,0x11111000, 0x11110000, 0x11100000, 0x11000000, 0x10000000};
        vx_uint32 uniUint8toFp32_dp16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        uniUint8ExtractN_dp2x8[1] = uniConfigUint8ExtractN[kernelXremain];

        calculateActivationRangeInt8(activation, output_fractionLengthValue, (vx_int8*)(&minVal), (vx_int8*)(&maxVal), VX_ROUND_POLICY_TO_NEAREST_EVEN);

        packedMin = ((minVal << 24) | (minVal << 16) | (minVal << 8) | (minVal));
        packedMax = ((maxVal << 24) | (maxVal << 16) | (maxVal << 8) | (maxVal));

        packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = packedMin;
        packedMaxData[0] = packedMaxData[1] = packedMaxData[2] = packedMaxData[3] = packedMax;

        if (kernel_v == 2 && stride_v == 2 &&  pad_v == 0)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MaxInt8ker2str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16Packeven_dp2x8", 1, UniS8xFp16Packeven_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16Packodd_dp2x8", 1, UniS8xFp16Packodd_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 2 &&  pad_v == 0)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MaxInt8ker3str2pad0", borderMode);
            if (!shaderExecutable) goto OnError;
            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniMaxPoolS8xFp16_dp2x8", 1, UniMaxPoolS8xFp16_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 2 &&  pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MaxInt8ker3str2pad1", borderMode);
            if (!shaderExecutable) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniMaxPoolS8xFp16_dp2x8", 1, UniMaxPoolS8xFp16_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 3 && stride_v == 1 &&  pad_v == 1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MaxInt8ker3str1pad1", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16_dp2x8", 1, UniS8xFp16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "divSrc3_scale", 1, &div_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat3", 1, &outputFormat);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (kernel_v == 2 && stride_v == 1 &&  pad_v == 0)
        {
            if (div_fractionLengthValue == 0)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxInt8ker2str1pad0fpE", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_maxInt8ker2str1pad0fpUNE", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8xFp16Head8_dp2x8", 1, uniS8xFp16Head8_dp2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS8xFp16Last8_dp2x8", 1, uniS8xFp16Last8_dp2x8);
                if (status != VX_SUCCESS) goto OnError;
            }

            status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]  = 15;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
            execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
            execution_parameters.globalWorkSize[2]   = depth;

            enable_setExecutParam = vx_true_e;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genMaxInt8toInt8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSize", 1, kernelSize);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pad", 1, pad);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXis8x", 1, &kernelXis8x);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelXremain", 1, &kernelXremain);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8ExtractN_dp2x8", 1, uniUint8ExtractN_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8toFp32_dp16x1", 1, uniUint8toFp32_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGenConvertInt32toUint8_dp2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMinData", 1, packedMinData);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "packedGenMaxData", 1, packedMaxData);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
            if (status != VX_SUCCESS) goto OnError;
            execution_parameters.globalWorkScale[0]  = 1;
            execution_parameters.globalWorkScale[1]  = 1;
            execution_parameters.globalWorkScale[2]  = 1;
            execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
            execution_parameters.globalWorkSize[2]   = depth;

            enable_setExecutParam = vx_true_e;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "div_scale", 1, &div_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat2", 1, &outputFormat);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (enable_setExecutParam == vx_false_e)
    {
        status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = ((8 - kernel_v + stride_v) /2 ) * 2;
        execution_parameters.globalWorkScale[1]  = out_height;
        execution_parameters.globalWorkScale[2]  = 1;

        if (stride_v == 2 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            execution_parameters.globalWorkScale[0] = 4;
            execution_parameters.globalWorkScale[1] = 1;
        }
        else if (stride_v == 1 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            execution_parameters.globalWorkScale[0] = 8;
            execution_parameters.globalWorkScale[1] = 1;
        }

        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 10);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_widths) vxReleaseScalar(&in_widths);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (depth_s) vxReleaseScalar(&depth_s);
    if (out_widths) vxReleaseScalar(&out_widths);
    if (out_heights) vxReleaseScalar(&out_heights);
    if (poolPadX) vxReleaseScalar(&poolPadX);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_widths) vxReleaseScalar(&in_widths);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (depth_s) vxReleaseScalar(&depth_s);
    if (out_widths) vxReleaseScalar(&out_widths);
    if (out_heights) vxReleaseScalar(&out_heights);
    if (poolPadX) vxReleaseScalar(&poolPadX);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcLrn****************************************************/
vxnne_shader_executable vxnneGetNormalizationShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               type_s,
    vx_scalar               norm_size_s,
    vx_scalar               alpha_s,
    vx_scalar               beta_s,
    vx_float32              bias,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference    parameters[9]              = {(vx_reference)input, VX_NULL, VX_NULL, VX_NULL, (vx_reference)type_s, (vx_reference)norm_size_s, (vx_reference)alpha_s, (vx_reference)beta_s, (vx_reference)output};
    vx_enum         inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum         outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32       width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32       height                     = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32       channel                    = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_enum         norm_type                  = type_s->value->e;
    vx_int32        norm_size                  = norm_size_s->value->u32;
    vx_float32      alpha                      = alpha_s->value->f32;
    vx_float32      beta                       = beta_s->value->f32;
    vx_scalar       width_s                    = vxCreateScalar(context, VX_TYPE_UINT32, &width);
    vx_scalar       height_s                   = vxCreateScalar(context, VX_TYPE_UINT32, &height);
    vx_scalar       channel_s                  = vxCreateScalar(context, VX_TYPE_UINT32, &channel);
    vx_float32      in_scale                   = 1.0f;
    vx_float32      out_scale                  = 1.0f;
    vx_int8         input_fractionLengthValue  = TENSOR_POS(input);
    vx_int8         output_fractionLengthValue = TENSOR_POS(output);
    vx_int32        nsz_div2                   = norm_size / 2;
    vx_float32      alpha_nsz                  = 0.0f;
    vx_float32      one4[4]                    = {bias, bias, bias, bias};
    vx_float32      alpha_nsz4[4]              = {0};
    vx_int32        OUTPUT_IS_INT8             = (outputFormat == VX_TYPE_INT8 ? 1 : 0);
    vx_uint32       maxWorkGroupSize           = 8;
    char *programSources = NULL;

    vx_uint32 UniS8xFp16toFp16_dp2x8[16] = {
        0x11111111, // TCfg
        0x00000000, // ASelt
        0x03020100, 0x07060504, // ABin
        0x11111111, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 UniFp16xFp16toS8_dp2x8[16] = {
        0x11111111, // TCfg
        0x00000000, // ASelt
        0x03020100, 0x07060504, // ABin
        0x11111111, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    parameters[1] = (vx_reference)width_s;
    parameters[2] = (vx_reference)height_s;
    parameters[3] = (vx_reference)channel_s;

    if (norm_type == VX_NN_NORMALIZATION_ACROSS_MAPS)
    {
        alpha_nsz = alpha / norm_size;
    }
    else
    {
        alpha_nsz = alpha / (norm_size * norm_size);
    }
    alpha_nsz4[0] = alpha_nsz4[1] = alpha_nsz4[2] = alpha_nsz4[3] = alpha_nsz;

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_INT8)
    {
        borderMode->constant_value.U8 = 0;
    }
    else
    {
        borderMode->constant_value.S16 = 0;
    }
    if (input_fractionLengthValue >= 0)
    {
        in_scale = 1.0f / (vx_float32) (1 << input_fractionLengthValue);
    }
    else
    {
        in_scale = (vx_float32) (1 << -input_fractionLengthValue);
    }
    if (output_fractionLengthValue >= 0)
    {
        out_scale = (vx_float32) (1 << output_fractionLengthValue);
    }
    else
    {
        out_scale = 1.0f / (vx_float32) (1 << -output_fractionLengthValue);
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Normalization, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Normalization.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcNormalization", program, 9, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (norm_type == VX_NN_NORMALIZATION_SAME_MAP)
    {
        vx_uint32 dp_fp16_1[16] = {
            0x15151515, // TCfg
            0x00000000, // ASelt
            0x03210210, 0x05430432, // ABin
            0x15151515, // BSelt
            0x03210210, 0x05430432, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniFp16xFp16PackLo4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020001, 0x00040003, // ABin
            0x01010101, // BSelt
            0x00020000, 0x00060004, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_int32 x_len_8x = norm_size / 8;
        vx_int32 x_len_remain = norm_size % 8;
        vx_uint32 UniSquareSum_dp16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00000000, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfigSumN[8] = {0x00000000, 0x00000001, 0x00000005 ,0x00000015, 0x00000055, 0x00000155, 0x00000555, 0x00001555};
        vx_uint32 UniSquareSumN_dp16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00000000, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniFp16toFp32one_dp16x1[16] = {
            0x00000001, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000002, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniSquareSub_dp16x1[16] = {
            0xaaaa5555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x55550000, // BSelt
            0x76543210, 0x76543210, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfigSubN[8] = {0x00000000, 0x00020001, 0x000a0005 ,0x002a0015, 0x00aa0055, 0x02aa0155, 0x0aaa0555, 0x2aaa1555};
        vx_uint32 UniSquareSubN_dp16x1[16] = {
            0xaaaa5555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x55550000, // BSelt
            0x76543210, 0x76543210, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        UniSquareSumN_dp16x1[0] = uniConfigSumN[x_len_remain];
        UniSquareSubN_dp16x1[0] = uniConfigSubN[x_len_remain];

        if (inputFormat == VX_TYPE_FLOAT16 && norm_size == 3 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SameMapNs3Fp16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && norm_size == 3 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SameMapNs3Int8In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genSameMapFp16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        if (norm_size == 3 && beta == 0.75)
            execution_parameters.globalWorkScale[0]  = 4;
        else
            execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = height;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = channel;

        if (norm_size == 3 && beta == 0.75)
        {
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_UniS8xFp16toFp16_dp2x8", 1, UniS8xFp16toFp16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_in_scale", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_dp_fp16_1", 1, dp_fp16_1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_UniFp16xFp16PackLo4_dp4x4", 1, UniFp16xFp16PackLo4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_UniFp16xFp16toS8_dp2x8", 1, UniFp16xFp16toS8_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_out_scale", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sm_outputFormat", 1, &outputFormat);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSum_dp16x1_samgen", 1, UniSquareSum_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSumN_dp16x1_samgen", 1, UniSquareSumN_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16toFp32one_dp16x1_samgen", 1, UniFp16toFp32one_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSub_dp16x1_samgen", 1, UniSquareSub_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSubN_dp16x1_samgen", 1, UniSquareSubN_dp16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nsz_div2_samgen", 1, &nsz_div2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alpha_nsz_samgen", 1, &alpha_nsz);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else //VX_NN_NORMALIZATION_ACROSS_MAPS
    {
        vx_uint32 Uni4x4_SquareSubLo4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x04040404, // BSelt
            0x00110000, 0x00330022, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_SquareSubHi4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x04040404, // BSelt
            0x00550044, 0x00770066, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Fp16xFp16UnpackLo4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00020000, 0x00060004, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Fp16xFp16UnpackHi4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x01010101, // BSelt
            0x00020000, 0x00060004, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni2x8_CopyHalf8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        //add for r11
        vx_uint32 fp16MulFp16ToFp16_8x1[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 int8MulFp16ToFp16_8x1[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 fp16MulFp16_low[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 fp16MulFp16_high[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x01010101, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 fp16ExtractLow[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 fp16ExtractHigh[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 halfToVxcHalf_8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        //add for int16 norm size 11
        vx_float32 inputScaleSqr = in_scale * in_scale;
        vx_float32 outputScale   = in_scale * out_scale;
        vx_uint32 uniInt16SqrSumLo_dp4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x04040404, // BSelt
            0x00110000, 0x00330022, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16SqrSumHi_dp4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x04040404, // BSelt
            0x00550044, 0x00770066, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16toFloatLo_dp4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16toFloatHi_dp4x4[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt32toInt16_dp2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16SqrLo_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16SqrHi_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16SqrSubLo_dp4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x04040404, // BSelt
            0x00110000, 0x00330022, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt16SqrSubHi_dp4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x04040404, // BSelt
            0x00550044, 0x00770066, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        //add for generic
        vx_uint32 UniSquareLo4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniSquareHi4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x01010101, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniPackLow16bits2x8_P1[16] = {
            0x00001111, // TCfg
            0x00000000, // ASelt
            0x06040200, 0x00000000, // ABin
            0x00002222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = 1;

        if (inputFormat == VX_TYPE_INT8 && norm_size == 11 && beta == 0.5)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs11Int8In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && norm_size == 11 && beta == 0.5)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs11Fp16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT16 && norm_size == 11 && beta == 0.5)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs11Int16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && norm_size == 5 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs5Fp16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && norm_size == 5 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs5Int8In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && norm_size == 3 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs3Fp16In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 && norm_size == 3 && beta == 0.75)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs3Int8In", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else //generic AcrossMaps
        {
            if (inputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genAcrossMapsFp16In", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_genAcrossMapsInt8In", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }

        if (norm_size == 3 && beta == 0.75)
        {
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_SquareSubLo4", 1, Uni4x4_SquareSubLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_SquareSubHi4", 1, Uni4x4_SquareSubHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Fp16xFp16UnpackLo4", 1, Uni4x4_Fp16xFp16UnpackLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Fp16xFp16UnpackHi4", 1, Uni4x4_Fp16xFp16UnpackHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_CopyHalf8", 1, Uni2x8_CopyHalf8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16toFp16_dp2x8", 1, UniS8xFp16toFp16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16xFp16toS8_dp2x8", 1, UniFp16xFp16toS8_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat", 1, &outputFormat);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (norm_size == 5 && beta == 0.75)
        {
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_SquareSubLo4_r5", 1, Uni4x4_SquareSubLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_SquareSubHi4_r5", 1, Uni4x4_SquareSubHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Fp16xFp16UnpackLo4_r5", 1, Uni4x4_Fp16xFp16UnpackLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Fp16xFp16UnpackHi4_r5", 1, Uni4x4_Fp16xFp16UnpackHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_CopyHalf8_r5", 1, Uni2x8_CopyHalf8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16toFp16_dp2x8_r5", 1, UniS8xFp16toFp16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16xFp16toS8_dp2x8_r5", 1, UniFp16xFp16toS8_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale_r5", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale_r5", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormat_r5", 1, &outputFormat);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (norm_size == 11 && beta == 0.5)
        {
            //fp16
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16_low_fp16", 1, fp16MulFp16_low);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16_high_fp16", 1, fp16MulFp16_high);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16ToFp16_8x1_fp16", 1, fp16MulFp16ToFp16_8x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ExtractLow_fp16", 1, fp16ExtractLow);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ExtractHigh_fp16", 1, fp16ExtractHigh);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alphaCompute_fp16", 1, &alpha_nsz);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "halfToVxcHalf_8_fp16", 1, halfToVxcHalf_8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormatR11_fp16", 1, &outputFormat);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale_fp16", 1, &out_scale);
            //int8
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16_low_int8", 1, fp16MulFp16_low);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16_high_int8", 1, fp16MulFp16_high);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16MulFp16ToFp16_8x1_int8", 1, fp16MulFp16ToFp16_8x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "int8MulFp16ToFp16_8x1_int8", 1, int8MulFp16ToFp16_8x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ExtractLow_int8", 1, fp16ExtractLow);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16ExtractHigh_int8", 1, fp16ExtractHigh);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alphaCompute_int8", 1, &alpha_nsz);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "halfToVxcHalf_8_int8", 1, halfToVxcHalf_8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputFormatR11_int8", 1, &outputFormat);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale_int8", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale_int8", 1, &out_scale);
            //int16
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrSumLo_dp4x4", 1, uniInt16SqrSumLo_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrSumHi_dp4x4", 1, uniInt16SqrSumHi_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alphaDivNs11Int16", 1, &alpha_nsz);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScaleSqr", 1, &inputScaleSqr);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16toFloatLo_dp4x4", 1, uniInt16toFloatLo_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16toFloatHi_dp4x4", 1, uniInt16toFloatHi_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt32toInt16_dp2x8", 1, uniInt32toInt16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrLo_dp4x4", 1, uniInt16SqrLo_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrHi_dp4x4", 1, uniInt16SqrHi_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrSubLo_dp4x4", 1, uniInt16SqrSubLo_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt16SqrSubHi_dp4x4", 1, uniInt16SqrSubHi_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
        else //generic AcrossMaps
        {
            //fp16 input
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Lo4_dp4x4_acrgen", 1, fp16ExtractLow);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Hi4_dp4x4_acrgen", 1, fp16ExtractHigh);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareLo4_dp4x4_acrgen", 1, UniSquareLo4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareHi4_dp4x4_acrgen", 1, UniSquareHi4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackLow16bits2x8_P1_acrgen", 1, UniPackLow16bits2x8_P1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSubLo4_dp4x4_acrgen", 1, Uni4x4_SquareSubLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSubHi4_dp4x4_acrgen", 1, Uni4x4_SquareSubHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16xFp16toS8_dp2x8_acrgen", 1, UniFp16xFp16toS8_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nsz_div2_acrgen", 1, &nsz_div2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "OUTPUT_IS_INT8_acrgen", 1, &OUTPUT_IS_INT8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alpha_nsz4_acrgen", 1, alpha_nsz4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "one4_acrgen", 1, one4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale_acrgen", 1, &out_scale);
            //int8 input
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Lo4_dp4x4_acrgenInt8", 1, fp16ExtractLow);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Hi4_dp4x4_acrgenInt8", 1, fp16ExtractHigh);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareLo4_dp4x4_acrgenInt8", 1, UniSquareLo4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareHi4_dp4x4_acrgenInt8", 1, UniSquareHi4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniPackLow16bits2x8_P1_acrgenInt8", 1, UniPackLow16bits2x8_P1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSubLo4_dp4x4_acrgenInt8", 1, Uni4x4_SquareSubLo4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniSquareSubHi4_dp4x4_acrgenInt8", 1, Uni4x4_SquareSubHi4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16xFp16toS8_dp2x8_acrgenInt8", 1, UniFp16xFp16toS8_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16toFp16_dp2x8_acrgenInt8", 1, UniS8xFp16toFp16_dp2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nsz_div2_acrgenInt8", 1, &nsz_div2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "OUTPUT_IS_INT8_acrgenInt8", 1, &OUTPUT_IS_INT8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alpha_nsz4_acrgenInt8", 1, alpha_nsz4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "one4_acrgenInt8", 1, one4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale_acrgenInt8", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale_acrgenInt8", 1, &out_scale);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 9);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (width_s) vxReleaseScalar(&width_s);
    if (height_s) vxReleaseScalar(&height_s);
    if (channel_s) vxReleaseScalar(&channel_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (width_s) vxReleaseScalar(&width_s);
    if (height_s) vxReleaseScalar(&height_s);
    if (channel_s) vxReleaseScalar(&channel_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcLrn uint8****************************************************/
vxnne_shader_executable vxnneGetNormalizationUint8ShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               type_s,
    vx_scalar               norm_size_s,
    vx_scalar               alpha_s,
    vx_scalar               beta_s,
    vx_float32              bias,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference    parameters[9]              = {(vx_reference)input, VX_NULL, VX_NULL, VX_NULL, (vx_reference)type_s, (vx_reference)norm_size_s, (vx_reference)alpha_s, (vx_reference)beta_s, (vx_reference)output};
    vx_enum         inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum         outputFormat               = TENSOR_DATA_TYPE(output);
    vx_uint32       width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32       height                     = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32       channel                    = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_enum         norm_type                  = type_s->value->e;
    vx_int32        norm_size                  = norm_size_s->value->u32;
    vx_float32      alpha                      = alpha_s->value->f32;
    vx_float32      beta                       = beta_s->value->f32;
    vx_scalar       width_s                    = vxCreateScalar(context, VX_TYPE_UINT32, &width);
    vx_scalar       height_s                   = vxCreateScalar(context, VX_TYPE_UINT32, &height);
    vx_scalar       channel_s                  = vxCreateScalar(context, VX_TYPE_UINT32, &channel);
    vx_float32      in_scale                   = TENSOR_TF_SCALE(input);
    vx_float32      out_scale                  = (vx_float32)1.0f / TENSOR_TF_SCALE(output);
    vx_int32        in_zeros_point             = TENSOR_TF_ZEROPOINT(input);
    vx_float32      out_zeros_point            = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_float32      alpha_nsz                  = 0.0f;
    vx_int32        nszDiv2                    = norm_size / 2;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    parameters[1] = (vx_reference)width_s;
    parameters[2] = (vx_reference)height_s;
    parameters[3] = (vx_reference)channel_s;

    if (norm_type == VX_NN_NORMALIZATION_ACROSS_MAPS)
    {
        alpha_nsz = alpha / norm_size;
    }
    else
    {
        alpha_nsz = alpha / (norm_size * norm_size);
    }

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U8 = 0;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, NormalizationUint8, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/NormalizationUint8.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcNormalization", program, 9, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    //VX_NN_NORMALIZATION_ACROSS_MAPS
    {
        //add for uint8 norm size 11
        vx_uint32 UniformDp4x4_subZeroToFloatLower[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 Uniform_Dp2x8_int32ToUint8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        // uint8 for norm size 3 and 5
        vx_uint32 uniConvertUint8ToFp32_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvertSubZpUint8Fp32_4x4[16] = {
            0x09090905, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0xbc003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        //add for generic uint8
        vx_uint32 uniUint8SubZPtoFp32Lo_dp4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniUint8SubZPtoFp32Hi_dp4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };

        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && (norm_size == 11))
            execution_parameters.globalWorkScale[0]  = 4;
        else
            execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = 1;

        if (inputFormat == VX_TYPE_UINT8 && beta == 0.75 && (norm_size == 5 || norm_size == 3))
        {
            execution_parameters.globalWorkSize[2] = channel;
        }

        if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && norm_size == 11 && beta == 0.5)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs11Uint8toUint8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDp4x4_subZeroToFloatLower", 1, &UniformDp4x4_subZeroToFloatLower);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uniform_Dp2x8_int32ToUint8", 1, Uniform_Dp2x8_int32ToUint8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_zeros_point", 1, &in_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_zeros_point", 1, &out_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale_fl32", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "out_scale_fl32", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alphaDivNs11Uint8", 1, &alpha_nsz);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && beta == 0.75 && norm_size == 5)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs5Uint8toUint8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8ToFp32_4x4", 1, uniConvertUint8ToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSubZpUint8Fp32_4x4", 1, uniConvertSubZpUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &out_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &in_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alpha_nsz", 1, &alpha_nsz);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && beta == 0.75 && norm_size == 3)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsNs3Uint8toUint8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8ToFp32_4x4", 1, uniConvertUint8ToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSubZpUint8Fp32_4x4", 1, uniConvertSubZpUint8Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &out_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &in_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alpha_nsz", 1, &alpha_nsz);
            if (status != VX_SUCCESS) goto OnError;
        }
        else//generic
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_AcrossMapsGenUint8toUint8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8SubZPtoFp32Lo_dp4x4", 1, uniUint8SubZPtoFp32Lo_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUint8SubZPtoFp32Hi_dp4x4", 1, uniUint8SubZPtoFp32Hi_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSubZpUint8Fp32_4x4", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZPGen", 1, &out_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZPGen", 1, &in_zeros_point);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScaleGen", 1, &in_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScaleGen", 1, &out_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nsz_div2_acrgen", 1, &nszDiv2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "alphaNszGen", 1, &alpha_nsz);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bias", 1, &bias);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 9);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (width_s) vxReleaseScalar(&width_s);
    if (height_s) vxReleaseScalar(&height_s);
    if (channel_s) vxReleaseScalar(&channel_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (width_s) vxReleaseScalar(&width_s);
    if (height_s) vxReleaseScalar(&height_s);
    if (channel_s) vxReleaseScalar(&channel_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcSoftmax****************************************************/
#define IMAGE_SIZE_4K  (4096)
vxnne_shader_executable vxnneGetSoftmaxShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_uint32               dims,
    vx_tensor               input,
    vx_float32              beta,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]     = {(vx_reference)input, (vx_reference)output};
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = (dims > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32    depth             = (dims > 2) ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_uint32    batch             = (dims > 3) ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_uint32    input_dims        = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    output_dims       = TENSOR_DIM_NUM(output) == 1 ? 2 : TENSOR_DIM_NUM(output);
    vx_tensor    input_rs          = NULL;
    vx_tensor    output_rs         = NULL;
    vx_bool      useImage2DFlag    = (vx_bool)(width * height < IMG_MAX_WIDTH);
    vx_int8      srcFixPointPos    = TENSOR_POS(input);
    vx_int8      dstFixPointPos    = TENSOR_POS(output);
    vx_int32     output_ZP         = TENSOR_TF_ZEROPOINT(output);
    vx_float32   scaleOut          = 1.0f;
    vx_float32   scaleIn           = 1.0f;
    vx_uint32    inputWidth        = depth / 4 * 4;
    vx_uint32    inputWidthRemain4 = depth % 4;
    vx_uint32    itemCount         = width * height;
    vx_uint32    itemDepth         = depth;
    vx_int32     fp16_isFp16       = 0;
    vx_float32   logE              = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
    vx_int32     sizes[4]           = {itemCount, itemDepth, 1, batch};
    vx_float32   scaleLogE         = logE * beta;
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (dims == 2 && (!(width == 2 && inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)))
    {
        depth             = width;
        itemCount         = width;
        itemDepth         = height;
        sizes[0]          = itemCount;
        sizes[1]          = itemDepth;
        inputWidth        = depth / 4 * 4;
        inputWidthRemain4 = depth % 4;
    }

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16 || inputFormat == VX_TYPE_UINT8)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }

        if (inputFormat == VX_TYPE_UINT8)
        {
            scaleIn   = TENSOR_TF_SCALE(input);
        }
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16 || outputFormat == VX_TYPE_UINT8)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }

        if (outputFormat == VX_TYPE_UINT8)
        {
            scaleOut   = TENSOR_TF_SCALE(output);
        }
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    if (useImage2DFlag)
    {
        if (depth == 2 && inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            sizes[0] = itemCount;
            sizes[1] = depth;
        }
        else if (itemCount == 1 && dims != 2)
        {
            sizes[0] = depth;
            sizes[1] = 1;
        }

        input_rs = vxoTensor_ReshapeTensor(input, sizes, input_dims);
        output_rs = vxoTensor_ReshapeTensor(output, sizes, output_dims);

        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;
    }

    if (dims == 1)
    {
        if (width == 2)
        {
            inputWidth        = itemCount / 4 * 4;
            inputWidthRemain4 = itemCount % 4;
        }
        else
        {
            depth             = itemCount;
            inputWidth        = depth / 4 * 4;
            inputWidthRemain4 = depth % 4;
        }
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Softmax, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/Softmax.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        vxmONERROR(vxGetStatus((vx_reference)program));

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        vxmONERROR_NULLPTR(kernel = vxnneAddKernelShadersInProgram(context, "vxcSoftmax", program, 2, kernelEnum));

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && width == 2 && dims == 2)
    {
        vx_uint32 uniExtractABAB_2x8[16] = {
            0x11111111, // TCfg
            0x10101010, // ASelt
            0x02020000, 0x06060404, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 uniDataEvenSubOdd_4x4[16] = {
            0x09090909, // TCfg
            0x00000000, // ASelt
            0x00320010, 0x00760054, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };

        if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16_D2C2", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataEvenSubOdd_4x4", 1, uniDataEvenSubOdd_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractABAB_2x8", 1, uniExtractABAB_2x8);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &scaleLogE);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && width == 6 && dims == 2)
    {
        vx_uint32 uniSubMax2FP32_Lo[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniSubMax2FP32_Hi[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        if (outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16_D6Bn", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status   = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMax2FP32_Lo", 1, uniSubMax2FP32_Lo);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMax2FP32_Hi", 1, uniSubMax2FP32_Hi);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &scaleLogE);
        vxmONERROR_STATUS(status);


        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((itemDepth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);

    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && depth == 2)
    {
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniSubMax2FP32_Lo[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00110000, 0x00330022, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
            };
            vx_uint32 uniSubMax2FP32_Hi[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00550044, 0x00770066, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            if (outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16_channel2", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            status   = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMax2FP32_Lo", 1, uniSubMax2FP32_Lo);
            status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMax2FP32_Hi", 1, uniSubMax2FP32_Hi);
            status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &scaleLogE);
            vxmONERROR_STATUS(status);

        }
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 2;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (itemDepth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else if (itemCount == 1 || dims == 1 || dims == 2)
    {
        if (inputFormat == VX_TYPE_INT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_FLOAT32))
        {
            vx_int32     data_isFp16       = 0;
            vx_uint32 uniPackMaxData_2x8[16] = {
                0x00333333, // TCfg
                0x00000000, // ASelt
                0x09060300, 0x00000d0c, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniPackMaxAndScale_2x8[16] = {
                0x00000013, // TCfg
                0x00000010, // ASelt
                0x00000000, 0x00000000, // ABin
                0x00000020, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetSubData0to3_4x4[16] = {
                0x09090909, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x05050505, // BSelt
                0x00110011, 0x00110011, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf4_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00020000, 0x00060004, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
            };
            vx_uint32 uniExtact8Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (outputFormat == VX_TYPE_INT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toInt8", borderMode);
                vxmONERROR_NULLPTR(shaderExecutable);

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_Scale", 1, &scaleOut);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, &uniExtact8Bit_2x8);
                vxmONERROR_STATUS(status);
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8", borderMode);
                vxmONERROR_NULLPTR(shaderExecutable);

                if (outputFormat == VX_TYPE_FLOAT16)
                    data_isFp16 = 1;
                else if (outputFormat == VX_TYPE_FLOAT32)
                    data_isFp16 = 0;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "data_isFp16", 1, &data_isFp16);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
                vxmONERROR_STATUS(status);
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackMaxAndScale_2x8", 1, uniPackMaxAndScale_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubData0to3_4x4", 1, uniGetSubData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackMaxData_2x8", 1, uniPackMaxData_2x8);
            vxmONERROR_STATUS(status);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_Scale", 1, &scaleIn);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidth", 1, &inputWidth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidthRemain4", 1, &inputWidthRemain4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, &depth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &scaleLogE);
            vxmONERROR_STATUS(status);
        }
        else if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_FLOAT32 || outputFormat == VX_TYPE_UINT8))
        {
            vx_float32 scaleInLogE_UInt8   = scaleIn * logE * beta;
            vx_float32 qScaleOut_UInt8     = (vx_float32)1.0 / scaleOut;
            vx_float32 uint8_out_ZP        = (vx_float32)output_ZP;
            vx_int32 dst_format_type       = outputFormat;
            vx_int32 DATA_TYPE_UINT8       = VX_TYPE_UINT8;
            vx_int32 DATA_TYPE_FP16        = VX_TYPE_FLOAT16;
            vx_uint32 uniPackMaxData_2x8[16] = {
                0x00333333, // TCfg
                0x00000000, // ASelt
                0x09060300, 0x00000d0c, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniSubMaxtoFp32_4x4[16] = {
                0x0b0b0b0b, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x08080808, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00007400, // AccumType, ConstantType, and PostShift
                0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
            };
            vx_uint32 uniExtact8Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf4_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00020000, 0x00060004, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8_1x1xN", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackMaxData_2x8", 1, uniPackMaxData_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMaxtoFp32_4x4", 1, uniSubMaxtoFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            vxmONERROR_STATUS(status);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "qScaleOut_UInt8", 1, &qScaleOut_UInt8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8_out_ZP", 1, &uint8_out_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dst_format_type", 1, &dst_format_type);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_UINT8", 1, &DATA_TYPE_UINT8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_FP16", 1, &DATA_TYPE_FP16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidth", 1, &inputWidth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidthRemain4", 1, &inputWidthRemain4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, &depth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInLogE_UInt8", 1, &scaleInLogE_UInt8);
            vxmONERROR_STATUS(status);
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_FLOAT32))
        {
            vx_uint32 uniPackMaxData_2x8[16] = {
                0x00000111, // TCfg
                0x00000000, // ASelt
                0x00050300, 0x00000000, // ABin
                0x00000222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetSubData0to3_4x4[16] = {
                0x09090909, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf4_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00020000, 0x00060004, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16", borderMode);

            vxmONERROR_NULLPTR(shaderExecutable);
            if (outputFormat == VX_TYPE_FLOAT16)
                fp16_isFp16 = 1;
            else if (outputFormat == VX_TYPE_FLOAT32)
                fp16_isFp16 = 0;
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "fp16_isFp16", 1, &fp16_isFp16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubData0to3_4x4", 1, uniGetSubData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackMaxData_2x8", 1, uniPackMaxData_2x8);
            vxmONERROR_STATUS(status);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidth", 1, &inputWidth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidthRemain4", 1, &inputWidthRemain4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, &depth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &scaleLogE);
            vxmONERROR_STATUS(status);
        }
        else if (inputFormat == VX_TYPE_INT16 && (outputFormat == VX_TYPE_INT16 || outputFormat == VX_TYPE_FLOAT16))
        {
            float scaleInLogE_Int16 = logE * scaleIn * beta;
            vx_int32 DATA_TYPE_FP16       = VX_TYPE_FLOAT16;
            vx_int32 dst_format_type      = outputFormat;

            vx_uint32 uniPackMaxData_2x8[16] = {
                0x00000111, // TCfg
                0x00000000, // ASelt
                0x00050300, 0x00000000, // ABin
                0x00000222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00004400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetSubData0to3_4x4[16] = {
                0x09090909, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
            };
            vx_uint32 uniExtact16Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniExtractHalf4_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00020000, 0x00060004, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_1x1xN", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubData0to3_4x4", 1, uniGetSubData0to3_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackMaxData_2x8", 1, uniPackMaxData_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            vxmONERROR_STATUS(status);

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidth", 1, &inputWidth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputWidthRemain4", 1, &inputWidthRemain4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, &depth);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInLogE_Int16", 1, &scaleInLogE_Int16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleOut_Int16", 1, &scaleOut);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dst_format_type", 1, &dst_format_type);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_FP16", 1, &DATA_TYPE_FP16);
            vxmONERROR_STATUS(status);
        }
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.localWorkSize[0]    = (dims == 2) ? 8 : 1;
        execution_parameters.localWorkSize[1]    = 1;
        execution_parameters.globalWorkSize[0]   = (dims == 2) ? gcmALIGN((itemDepth + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]) : 1;
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else if ((inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT8) && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_FLOAT32))
    {
        float scaleLogE_Int8 = logE * scaleIn * beta;
        vx_uint32 uniGetSubLoData_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniGetSubHiData_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniGetSubLoInt8toFp32_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniGetSubHiInt8toFp32_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp16", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);
        }
        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT32)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toFp32", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toFp16", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT32)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toFp32", borderMode);
            vxmONERROR_NULLPTR(shaderExecutable);
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubLoData_4x4", 1, uniGetSubLoData_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubHiData_4x4", 1, uniGetSubHiData_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubLoInt8toFp32_4x4", 1, uniGetSubLoInt8toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubHiInt8toFp32_4x4", 1, uniGetSubHiInt8toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE_Int8", 1, &scaleLogE_Int8);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
    {
        float scaleLogE_Int8 = logE * scaleIn * beta;
        vx_uint32 uniGetSubLoInt8toFp32_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniGetSubHiInt8toFp32_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8toInt8_2d", borderMode);
        vxmONERROR_NULLPTR(shaderExecutable);

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubLoInt8toFp32_4x4", 1, uniGetSubLoInt8toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetSubHiInt8toFp32_4x4", 1, uniGetSubHiInt8toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_Scale", 1, &scaleOut);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleLogE_Int8", 1, &scaleLogE_Int8);
        vxmONERROR_STATUS(status);


        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_FLOAT32 || outputFormat == VX_TYPE_UINT8))
    {
        vx_float32 scaleInLogE_UInt8   = scaleIn * logE * beta;
        vx_float32 qScaleOut_UInt8     = (vx_float32)1.0 / scaleOut;
        vx_float32 uint8_out_ZP        = (vx_float32)output_ZP;
        vx_int32 dst_format_type       = outputFormat;
        vx_int32 DATA_TYPE_UINT8       = VX_TYPE_UINT8;
        vx_int32 DATA_TYPE_FP16        = VX_TYPE_FLOAT16;
        vx_uint32 uniSubMaxLo_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniSubMaxHi_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007700, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8_WxHxC", borderMode);
        vxmONERROR_NULLPTR(shaderExecutable);

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMaxLo_4x4", 1, uniSubMaxLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMaxHi_4x4", 1, uniSubMaxHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        vxmONERROR_STATUS(status);

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "qScaleOut_UInt8", 1, &qScaleOut_UInt8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8_out_ZP", 1, &uint8_out_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dst_format_type", 1, &dst_format_type);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_UINT8", 1, &DATA_TYPE_UINT8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_FP16", 1, &DATA_TYPE_FP16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInLogE_UInt8", 1, &scaleInLogE_UInt8);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else if (inputFormat == VX_TYPE_INT16 && (outputFormat == VX_TYPE_INT16 || outputFormat == VX_TYPE_FLOAT16))
    {
        float scaleInLogE_Int16       = logE * scaleIn * beta;
        vx_int32 DATA_TYPE_FP16       = VX_TYPE_FLOAT16;
        vx_int32 dst_format_type      = outputFormat;
        vx_uint32 uniSubMaxLo_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003300, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniSubMaxHi_4x4[16] = {
            0x0b0b0b0b, // TCfg
            0x04040404, // ASelt
            0x00550044, 0x00770066, // ABin
            0x08080808, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003300, // AccumType, ConstantType, and PostShift
            0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000, 0x00010000, 0x00000000 // Constant
        };
        vx_uint32 uniExtact16Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16to16Bits", borderMode);
        vxmONERROR_NULLPTR(shaderExecutable);

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMaxLo_4x4", 1, uniSubMaxLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSubMaxHi_4x4", 1, uniSubMaxHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact16Bit_2x8", 1, uniExtact16Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInLogE_Int16", 1, &scaleInLogE_Int16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleOut_Int16", 1, &scaleOut);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dst_format_type", 1, &dst_format_type);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "DATA_TYPE_FP16", 1, &DATA_TYPE_FP16);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((itemCount + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = 1;
    }

    vxmONERROR(vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2));
    vxmONERROR(vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters));
    vxmONERROR(vxnneShaderExecutable_SetParametersAttribute(shaderExecutable, 0, VXNNE_SHADER_PARAMETERS_ATTRIBUTE_INPUT_BIT));
    vxmONERROR(vxnneShaderExecutable_SetParametersAttribute(shaderExecutable, 1, VXNNE_SHADER_PARAMETERS_ATTRIBUTE_OUTPUT_BIT));

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }
    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcVertMaxPool****************************************************/
vxnne_shader_executable vxnneVertMaxPoolShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_uint32               pool_width,
    vx_uint32               pool_height,
    vx_bool                 enable_relu,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[6]     = {(vx_reference)input, NULL, NULL, NULL, NULL, (vx_reference)output};
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth             = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch0            = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    src_dims          = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_scalar    width_s           = NULL;
    vx_scalar    outWidth_s        = NULL;
    vx_scalar    height_s          = NULL;
    vx_scalar    depth_s           = NULL;
    vx_uint32    outputWidth       = width * height;
    vx_uint32    outputheight      = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32    batch1            = TENSOR_VIEW_SIZE_INDEX(output, 3);
    vx_uint32    dst_dims          = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor    input_rs          = NULL;
    vx_tensor    output_rs         = NULL;
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_int32     src_sizes[4]      = {width, height * depth, 1, batch0};
    vx_int32     dst_sizes[4]      = {outputWidth, outputheight, 1, batch1};
    vx_uint32    packedMinData[4]  = {0};
    vx_uint32    minVal            = 0;
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;
    input_rs      = vxoTensor_ReshapeTensor(input, src_sizes, src_dims);
    output_rs     = vxoTensor_ReshapeTensor(output, dst_sizes, dst_dims);
    width_s       = vxCreateScalar(context, VX_TYPE_INT32, &width);
    outWidth_s    = vxCreateScalar(context, VX_TYPE_INT32, &outputWidth);
    height_s      = vxCreateScalar(context, VX_TYPE_INT32, &height);
    depth_s       = vxCreateScalar(context, VX_TYPE_INT32, &depth);
    parameters[0] = (vx_reference)input_rs;
    parameters[1] = (vx_reference)width_s;
    parameters[2] = (vx_reference)outWidth_s;
    parameters[3] = (vx_reference)height_s;
    parameters[4] = (vx_reference)depth_s;
    parameters[5] = (vx_reference)output_rs;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, VertMaxPool, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/VertMaxPool.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "vertMaxPool", program, 6, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enable_relu)
    {
        if (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT8)
        {
            packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = 0;
        }
    }
    else
    {
        if (outputFormat == VX_TYPE_FLOAT16)
        {
            minVal = 0xFC00FC00;
            packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = minVal;
        }
        else if (outputFormat == VX_TYPE_INT8)
        {
            packedMinData[0] = packedMinData[1] = packedMinData[2] = packedMinData[3] = 0x80808080;
        }
    }

    if ((inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT8) && width == 20 && height == 16 && pool_width == 6 && pool_height == 6)
    {
        if (inputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_20x16_6x6_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_20x16_6x6_int8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        execution_parameters.globalWorkScale[0]  = 5;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && width == 51 && height == 39 && pool_width == 6 && pool_height == 6)
    {

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_51x39_6x6_fp16", borderMode);
        if (!shaderExecutable) goto OnError;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.localWorkSize[0]    = 7;
        execution_parameters.localWorkSize[1]    = 1;
        execution_parameters.globalWorkSize[0]   = 7;
        execution_parameters.globalWorkSize[1]   = gcmALIGN_NP2((depth  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    }
    else if (inputFormat == VX_TYPE_INT8 && width == 51 && height == 39 && pool_width == 6 && pool_height == 6)
    {

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_51x39_6x6_int8", borderMode);
        if (!shaderExecutable) goto OnError;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.localWorkSize[0]    = 7;
        execution_parameters.localWorkSize[1]    = 1;
        execution_parameters.globalWorkSize[0]   = 7;
        execution_parameters.globalWorkSize[1]   = gcmALIGN_NP2((depth  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    }

    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedMinData", 1, packedMinData);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 6);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs)vxoTensor_ReleaseTensor(&output_rs);
    if (width_s)vxReleaseScalar(&width_s);
    if (outWidth_s)vxReleaseScalar(&outWidth_s);
    if (height_s)vxReleaseScalar(&height_s);
    if (depth_s)vxReleaseScalar(&depth_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs)vxoTensor_ReleaseTensor(&output_rs);
    if (width_s)vxReleaseScalar(&width_s);
    if (outWidth_s)vxReleaseScalar(&outWidth_s);
    if (height_s)vxReleaseScalar(&height_s);
    if (depth_s)vxReleaseScalar(&depth_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcpreTreatedRect****************************************************/
vxnne_shader_executable vxnnePreTreatedRectShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_uint32               rois_stride,
    vx_uint32               rois_num,
    vx_uint32               imgWid,
    vx_uint32               imgHeight,
    vx_float32              spatial_scale,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[5]     = {(vx_reference)input, NULL, NULL, NULL, (vx_reference)output};
    vx_scalar    width_s           = NULL;
    vx_scalar    height_s          = NULL;
    vx_scalar    spatial_s         = NULL;
    vx_uint32    batch0            = 1;
    vx_uint32    outputWidth       = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    outputheight      = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    batch1            = TENSOR_VIEW_SIZE_INDEX(output, 3);
    vx_uint32    src_dims          = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    dst_dims          = TENSOR_DIM_NUM(output) == 1 ? 2 : TENSOR_DIM_NUM(output);
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_tensor    input_rs          = NULL;
    vx_tensor    output_rs         = NULL;
    vx_int32     src_sizes[4]      = {rois_stride, rois_num, 1, batch0};
    vx_int32     dst_sizes[4]      = {outputWidth, outputheight, 1, batch1};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;

    input_rs      = vxoTensor_ReshapeTensor(input, src_sizes, src_dims);
    output_rs     = vxoTensor_ReshapeTensor(output, dst_sizes, dst_dims);
    width_s       = vxCreateScalar(context, VX_TYPE_INT32, &imgWid);
    height_s      = vxCreateScalar(context, VX_TYPE_INT32, &imgHeight);
    spatial_s     = vxCreateScalar(context, VX_TYPE_FLOAT32, &spatial_scale);
    parameters[0] = (vx_reference)input_rs;
    parameters[1] = (vx_reference)width_s;
    parameters[2] = (vx_reference)height_s;
    parameters[3] = (vx_reference)spatial_s;
    parameters[4] = (vx_reference)output_rs;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, PreTreatedRect, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/PreTreatedRect.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "preTreatedRect", program, 5, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && imgWid == 20 && imgHeight == 16)
    {
        vx_uint32 uniGetRoiRectPos[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020001, 0x00040003, // ABin
            0x01010101, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_20x16_6x6_fp16toS16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetRoiRectPos", 1, uniGetRoiRectPos);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((rois_num  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && imgWid == 51 && imgHeight == 39)
    {
        vx_uint32 uniGetRoiRectPos[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020001, 0x00040003, // ABin
            0x01010101, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_51x39_6x6_fp16toS16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetRoiRectPos", 1, uniGetRoiRectPos);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((rois_num  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 5);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs)vxoTensor_ReleaseTensor(&output_rs);
    if (width_s)vxReleaseScalar(&width_s);
    if (height_s)vxReleaseScalar(&height_s);
    if (spatial_s)vxReleaseScalar(&spatial_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs)vxoTensor_ReleaseTensor(&output_rs);
    if (width_s)vxReleaseScalar(&width_s);
    if (height_s)vxReleaseScalar(&height_s);
    if (spatial_s)vxReleaseScalar(&spatial_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}


/********vxcHorzMaxPoolRect****************************************************/
vxnne_shader_executable vxnneHorzMaxPoolShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               rois,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[3]     = {(vx_reference)input, (vx_reference)rois, (vx_reference)output};
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth             = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch0            = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    src0_dims         = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    output_channel    = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    output_rois       = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32    rois_width        = TENSOR_VIEW_SIZE_INDEX(rois, 0);
    vx_uint32    rois_height       = TENSOR_VIEW_SIZE_INDEX(rois, 1);
    vx_uint32    batch1            = TENSOR_VIEW_SIZE_INDEX(rois, 3);
    vx_uint32    src1_dims         = TENSOR_DIM_NUM(rois) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_tensor    input_rs          = NULL;
    vx_tensor    rois_rs           = NULL;
    vx_int32     src0_sizes[4]     = {width * height, depth, 1, batch0};
    vx_int32     src1_sizes[4]     = {rois_width, rois_height, 1, batch1};
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_int8      srcFixedPoint     = TENSOR_POS(input);
    vx_int8      dstFixedPoint     = TENSOR_POS(output);
    vx_float32   outputScale       = 1.0;
    char *programSources[2] = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    input_rs         = vxoTensor_ReshapeTensor(input, src0_sizes, src0_dims);
    rois_rs          = vxoTensor_ReshapeTensor(rois, src1_sizes, src1_dims);
    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_INT8)
    {
        borderMode->constant_value.U8 = 0;
        if (srcFixedPoint > 0)
            outputScale *= 1.0f / (vx_float32) (1 << srcFixedPoint);
        else
            outputScale *= (vx_float32) (1 << -srcFixedPoint);
    }
    else if (inputFormat == VX_TYPE_FLOAT16)
    {
        borderMode->constant_value.U16 = 0;
    }

    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixedPoint > 0)
            outputScale *= (vx_float32) (1 << dstFixedPoint);
        else
            outputScale *= 1.0f / (vx_float32) (1 << -dstFixedPoint);
    }

    parameters[0] = (vx_reference)input_rs;
    parameters[1] = (vx_reference)rois_rs;
    parameters[2] = (vx_reference)output;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, HorzMaxPool, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/HorzMaxPool.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "horzMaxPool", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT8) && width == 20 && height == 16 )
    {
        vx_uint32 uniGetMaxPoolPos_FP16_4x4[16] = {
            0x0f030f03, // TCfg
            0x04000400, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 uniMaskData[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackData0[16] = {
            0x00000033, // TCfg
            0x00000000, // ASelt
            0x00000400, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackData1[16] = {
            0x00000033, // TCfg
            0x00000000, // ASelt
            0x00000501, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackData0_int8[16] = {
            0x00000033, // TCfg
            0x00000000, // ASelt
            0x00000400, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackData1_int8[16] = {
            0x00000033, // TCfg
            0x00000000, // ASelt
            0x00000501, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8Scale_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (inputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_20x16_fp16tofp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_20x16_int8toint8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaxPoolPos_FP16_4x4", 1, uniGetMaxPoolPos_FP16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackData0", 1, uniRePackData0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackData1", 1, uniRePackData1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackData0_int8", 1, uniRePackData0_int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackData1_int8", 1, uniRePackData1_int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8Scale_2x8", 1, uniInt8Scale_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMaskData", 1, uniMaskData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((output_rois + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (output_channel  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && width == 51 && height == 39 )
    {
        vx_uint32 uniUnpackU16toS32_FP16_Lo[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackU16toS32_FP16_Hi[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMaxPoolPos_FP16_4x4[16] = {
            0x0f030f03, // TCfg
            0x04000400, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackData[16] = {
            0x00000333, // TCfg
            0x00000000, // ASelt
            0x00050300, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniMaskData[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_51x39_fp16tofp16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackU16toS32_FP16_Lo", 1, uniUnpackU16toS32_FP16_Lo);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackU16toS32_FP16_Hi", 1, uniUnpackU16toS32_FP16_Hi);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaxPoolPos_FP16_4x4", 1, uniGetMaxPoolPos_FP16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackData", 1, uniRePackData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMaskData", 1, uniMaskData);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.localWorkSize[0]    = 1;
        execution_parameters.localWorkSize[1]    = 8;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((output_rois + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]);
        execution_parameters.globalWorkSize[1]   = gcmALIGN((output_channel  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    }
    else if (inputFormat == VX_TYPE_INT8 && width == 51 && height == 39 )
    {
        vx_uint32 uniUnpackU16toS32_Lo[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackU16toS32_Hi[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMaxPoolPos[16] = {
            0x0f030f03, // TCfg
            0x04000400, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit0_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit1_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000001, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit2_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000002, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit3_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000003, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit4_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000004, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniGetMask9Bit5_16x1[16] = {
            0x00000003, // TCfg
            0x00000000, // ASelt
            0x00000005, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006408, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniRePackInt8Data[16] = {
            0x00000333, // TCfg
            0x00000000, // ASelt
            0x00060300, 0x00000000, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniInt8Scale_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_51x39_int8toint8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackU16toS32_Lo", 1, uniUnpackU16toS32_Lo);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackU16toS32_Hi", 1, uniUnpackU16toS32_Hi);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaxPoolPos", 1, uniGetMaxPoolPos);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit0_16x1", 1, uniGetMask9Bit0_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit1_16x1", 1, uniGetMask9Bit1_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit2_16x1", 1, uniGetMask9Bit2_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit3_16x1", 1, uniGetMask9Bit3_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit4_16x1", 1, uniGetMask9Bit4_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMask9Bit5_16x1", 1, uniGetMask9Bit5_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRePackInt8Data", 1, uniRePackInt8Data);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8Scale_2x8", 1, uniInt8Scale_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.localWorkSize[0]    = 1;
        execution_parameters.localWorkSize[1]    = 8;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((output_rois + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]);
        execution_parameters.globalWorkSize[1]   = gcmALIGN((output_channel  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (rois_rs) vxoTensor_ReleaseTensor(&rois_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (rois_rs) vxoTensor_ReleaseTensor(&rois_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********DeConvolution****************************************************/
vxnne_shader_executable vxnneDeConvolutionShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor  inputs,
    vx_tensor  weights,
    vx_tensor  bias,
    vx_scalar  padding_x,
    vx_scalar  padding_y,
    vx_scalar  overflow_policy,
    vx_scalar  rounding_policy,
    vx_scalar  a_x,
    vx_scalar  a_y,
    vx_scalar  group,
    vx_tensor  outputs
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[4] = {(vx_reference)inputs, (vx_reference)weights,(vx_reference)bias, (vx_reference)outputs};

    vx_type_e  inputFormat          = (vx_type_e)TENSOR_DATA_TYPE(inputs);
    vx_type_e  weightFormat         = (vx_type_e)TENSOR_DATA_TYPE(weights);
    vx_type_e  outputFormat         = (vx_type_e)TENSOR_DATA_TYPE(outputs);
    vx_type_e  biasFormat           = (vx_type_e)TENSOR_DATA_TYPE(bias);
    vx_int8    srcFixPointPos       = TENSOR_POS(inputs);
    vx_int8    wgtFixPointPos       = TENSOR_POS(weights);
    vx_int8    dstFixPointPos       = TENSOR_POS(outputs);
    vx_uint32  width                = TENSOR_VIEW_SIZE_INDEX(inputs, 0);
    vx_uint32  height               = TENSOR_VIEW_SIZE_INDEX(inputs, 1);
    vx_uint32  depth                = TENSOR_VIEW_SIZE_INDEX(inputs, 2);
    vx_float32 div_scale            = 1.0f;
    vx_int32   kernel_size          = weights->dims[0];
    vx_float32 bias_scale           = 1.0f;
    vx_float32 out_scale            = 1.0f;
    vx_float32 scale_in_u8          = TENSOR_TF_SCALE(inputs);
    vx_float32 scale_wt_u8          = TENSOR_TF_SCALE(weights);
    vx_float32 scale_out_u8         = TENSOR_TF_SCALE(outputs);
    vx_float32 scale_bias_i32       = 0;
    vx_int32 zp_in                  = TENSOR_TF_ZEROPOINT(inputs);
    vx_int32 zp_wt                  = TENSOR_TF_ZEROPOINT(weights);
    vx_int32 zp_out                 = TENSOR_TF_ZEROPOINT(outputs);
    vx_int32 zp_bias                = 0;

    vx_float32 scale_reout          = 1 / scale_out_u8;
    vx_float32 scale_in_wt_reout    = scale_in_u8 * scale_wt_u8 * scale_reout;

    vx_uint32 weights_dims          = TENSOR_DIM_NUM(weights);
    vx_tensor weights_rs            = NULL;
    vx_tensor bias_rs               = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, inputs=%p, outputs=%p",
         context, kernelEnum, borderMode, inputs, outputs);

    if (bias!=NULL)
    {
        vx_uint32 bias_dims = TENSOR_DIM_NUM(bias);
        vx_uint32     bias_w            = TENSOR_VIEW_SIZE_INDEX(bias, 0);
        vx_uint32     bias_h            = (bias_dims > 1) ? TENSOR_VIEW_SIZE_INDEX(bias, 1) : 1;
        vx_uint32     bias_c            = (bias_dims > 2) ? TENSOR_VIEW_SIZE_INDEX(bias, 2) : 1;
        vx_uint32     bias_b            = (bias_dims > 3) ? TENSOR_VIEW_SIZE_INDEX(bias, 3) : 1;
        vx_int32      bias_sizes[4]     = {bias_w, bias_h, bias_c, bias_b};
        vx_int8       biasFixPointPos   = TENSOR_POS(bias);
        scale_bias_i32                  = TENSOR_TF_SCALE(bias);
        zp_bias                         = TENSOR_TF_ZEROPOINT(bias);
        bias_dims                       = (bias_dims == 1) ? 2 : bias_dims;
        bias_rs                         = vxoTensor_ReshapeTensor(bias, bias_sizes, bias_dims);
        parameters[2] = (vx_reference)bias_rs;

        if (biasFormat == VX_TYPE_INT32)
        {
            if (biasFixPointPos > 0)
            {
                bias_scale = 1.0f / ((vx_uint32) (1 << biasFixPointPos));
            }
            else
            {
                bias_scale =  (vx_float32) (1 << -biasFixPointPos);
            }
        }
    }

    if (weights_dims==4)
    {
        vx_int32 new_size[6] = {weights->dims[0]*weights->dims[1],1, weights->dims[2]*weights->dims[3],1,1,1};
        weights_rs = vxoTensor_ReshapeTensor(weights, new_size, 3);
        parameters[1] = (vx_reference)weights_rs;
    }

    if (inputFormat == VX_TYPE_INT8
        || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            div_scale *= (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (weightFormat == VX_TYPE_INT8
        || weightFormat == VX_TYPE_INT16)
    {
        if (wgtFixPointPos >= 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << wgtFixPointPos);
        }
        else if (wgtFixPointPos < 0)
        {
            div_scale *= (vx_float32)(1 << -wgtFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_INT8
        || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            out_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            out_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
        div_scale *= out_scale;
    }

    borderMode->mode = VX_BORDER_CONSTANT;

    if (inputFormat == VX_TYPE_INT8)
        borderMode->constant_value.U8 = 0;
    else  if (inputFormat == VX_TYPE_UINT8 )
        borderMode->constant_value.U8 = (vx_uint8)zp_in;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, DeConvolution, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/DeConvolution.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "DeConv", program, 4, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (kernel_size==4 && inputFormat == VX_TYPE_FLOAT16&& outputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 Uni4x4_Conv0002[16] = {
            0x05050505, // TCfg
            0x00000000, // ASelt
            0x00210010, 0x00320021, // ABin
            0x05050505, // BSelt
            0x00310020, 0x00310020, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Conv0103[16] = {
            0x05050505, // TCfg
            0x00000000, // ASelt
            0x00210010, 0x00320021, // ABin
            0x05050505, // BSelt
            0x00750064, 0x00750064, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 Uni2x8_PackHalf4[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_k4s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv0002", 1, Uni4x4_Conv0002);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv0103", 1, Uni4x4_Conv0103);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_PackHalf4", 1, Uni2x8_PackHalf4);


        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]  =  gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;

    }
    else if (kernel_size==4 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint32 Uni4x4_Conv0002[16] = {
            0x05050505, // TCfg
            0x00000000, // ASelt
            0x00210010, 0x00320021, // ABin
            0x05050505, // BSelt
            0x00310020, 0x00310020, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Conv0103[16] = {
            0x05050505, // TCfg
            0x00000000, // ASelt
            0x00210010, 0x00320021, // ABin
            0x05050505, // BSelt
            0x00750064, 0x00750064, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        vx_uint32 Uni2x8_U8SubZp_lo[16] = {
            0x99999999, // TCfg
            0x44444444, // ASelt
            0x03020100, 0x07060504, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 Uni4x4_Int4_to_Uchar8[16] = {
            0x03030303, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_k4s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv0002", 1, Uni4x4_Conv0002);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv0103", 1, Uni4x4_Conv0103);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Int4_to_Uchar8", 1, Uni4x4_Int4_to_Uchar8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_U8SubZp_lo", 1, Uni2x8_U8SubZp_lo);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_in_wt_reout", 1, &scale_in_wt_reout);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_reout", 1, &scale_reout);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_bias_i32", 1, &scale_bias_i32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_in", 1, &zp_in);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_wt", 1, &zp_wt);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_out", 1, &zp_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_bias", 1, &zp_bias);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]  =  gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;

    }
    else if (kernel_size==4 && inputFormat == VX_TYPE_INT8   && outputFormat == VX_TYPE_INT8)
    {
        vx_uint32 Uni4x4_Conv0_int8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0xa9219810, 0xba32a921, // ABin
            0x55555555, // BSelt
            0xb931a820, 0xb931a820, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_conv1_int8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0xa9219810, 0xba32a921, // ABin
            0x55555555, // BSelt
            0xfd75ec64, 0xfd75ec64, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni2x8_Int4toInt8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8_k4s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv0_int8", 1, Uni4x4_Conv0_int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_conv1_int8", 1, Uni4x4_conv1_int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_Int4toInt8", 1, Uni2x8_Int4toInt8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "div_scale", 1, &div_scale);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkScale[0]  = 2;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else if (kernel_size==2 && inputFormat == VX_TYPE_FLOAT16&& outputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 Uni4x4_Conv00[16] = {
            0x01010101, // TCfg
            0x00000100, // ASelt
            0x00010000, 0x00010001, // ABin
            0x01010001, // BSelt
            0x00000000, 0x00010000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Conv01[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00010000, 0x00010000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Conv10[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00010001, // ABin
            0x01010101, // BSelt
            0x00030002, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni4x4_Conv11[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00030002, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 Uni2x8_PackHalf4[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_k2s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv00", 1, Uni4x4_Conv00);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv01", 1, Uni4x4_Conv01);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv10", 1, Uni4x4_Conv10);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Conv11", 1, Uni4x4_Conv11);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni2x8_PackHalf4", 1, Uni2x8_PackHalf4);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else if (kernel_size==2 && inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
    {
        vx_uint32 uniDeconv1RowInt8_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00010001, // ABin
            0x01010101, // BSelt
            0x00020003, 0x00020003, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv1RowHiInt8_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00020003, 0x00020003, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv2RowLoInt8_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00010001, // ABin
            0x01010101, // BSelt
            0x00000001, 0x00000001, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv2RowHiInt8_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00000001, 0x00000001, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toInt8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8_k2s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv1RowInt8_4x4", 1, uniDeconv1RowInt8_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv1RowHiInt8_4x4", 1, uniDeconv1RowHiInt8_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv2RowLoInt8_4x4", 1, uniDeconv2RowLoInt8_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv2RowHiInt8_4x4", 1, uniDeconv2RowHiInt8_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toInt8_2x8", 1, uniConvertInt32toInt8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_in_wt_out", 1, &div_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_out", 1, &out_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_bias", 1, &bias_scale);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else if (kernel_size==2 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
    {
        vx_uint32 uniConvertUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002100, // AccumType, ConstantType, and PostShift
            0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDeconvPackInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x02030203, 0x00010001, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackHighUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x07060504, 0x07060504, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackLowUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_k2s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8SubZpToFp32_4x4", 1, uniConvertUint8SubZpToFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconvPackInt32toUint8_2x8", 1, uniDeconvPackInt32toUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackLowUint8_2x8", 1, uniPackLowUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackHighUint8_2x8", 1, uniPackHighUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_in_wt_reout", 1, &scale_in_wt_reout);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_reout", 1, &scale_reout);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_bias_i32", 1, &scale_bias_i32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_in", 1, &zp_in);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_wt", 1, &zp_wt);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_out", 1, &zp_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "zp_bias", 1, &zp_bias);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else if (kernel_size==2 && inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
    {
        vx_uint32 uniDeconv1RowLoInt16_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00010001, // ABin
            0x01010101, // BSelt
            0x00020003, 0x00020003, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv1RowHiInt16_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00020003, 0x00020003, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv2RowLoInt16_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00010001, // ABin
            0x01010101, // BSelt
            0x00000001, 0x00000001, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDeconv2RowHiInt16_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020002, 0x00030003, // ABin
            0x01010101, // BSelt
            0x00000001, 0x00000001, // BBin
            0x00003400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toInt8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int16_k2s2", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv1RowLoInt16_4x4", 1, uniDeconv1RowLoInt16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv1RowHiInt16_4x4", 1, uniDeconv1RowHiInt16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv2RowLoInt16_4x4", 1, uniDeconv2RowLoInt16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDeconv2RowHiInt16_4x4", 1, uniDeconv2RowHiInt16_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toInt8_2x8", 1, uniConvertInt32toInt8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_in_wt_out", 1, &div_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_out", 1, &out_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_bias", 1, &bias_scale);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else
    {
        vxError("not support deconv type:inputFormat=%d,outputFormat=%d\n",inputFormat,outputFormat);
        goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (weights_rs) vxoTensor_ReleaseTensor(&weights_rs);
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (weights_rs) vxoTensor_ReleaseTensor(&weights_rs);
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}


/********vxcReshuffle****************************************************/
vxnne_shader_executable vxnneReshuffleShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_uint32               stride_x,
    vx_uint32               stride_y,
    vx_enum                 padMode,
    vx_uint32               padConstValue,
    vx_uint32               padXLeft,
    vx_uint32               padXRight,
    vx_uint32               padYTop,
    vx_uint32               padYBottom,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable   = VX_NULL;
    vxnne_kernel_shaders    kernel             = VX_NULL;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[4]     = {(vx_reference)input, NULL, NULL, (vx_reference)output};
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth             = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_scalar    padXLeft_s        = VX_NULL;
    vx_scalar    padYTOP_s         = VX_NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    padXLeft_s   = vxCreateScalar(context, VX_TYPE_INT32, &padXLeft);
    padYTOP_s    = vxCreateScalar(context, VX_TYPE_INT32, &padYTop);

    borderMode->mode = VX_BORDER_REPLICATE;
    if (padMode == VX_PAD_CONSTANT)
        borderMode->mode = VX_BORDER_CONSTANT;

    parameters[1] = (vx_reference)padXLeft_s;
    parameters[2] = (vx_reference)padYTOP_s;
    if (inputFormat == VX_TYPE_INT8)
    {
        borderMode->constant_value.U8 = (vx_uint8)padConstValue;
    }
    else if (inputFormat == VX_TYPE_FLOAT16)
    {
        borderMode->constant_value.U16 = (vx_uint16)padConstValue;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Reshuffle, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Reshuffle.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcReshuffle", program, 4, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && stride_x == 2 && stride_y == 2)
    {
        vx_uint32 UniReshuffle_dual_0_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 UniReshuffle_dual_1_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x07050301, 0x07050301, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        if (padXLeft != 0)
        {
            if (width + padXLeft == 2)
            {
                UniReshuffle_dual_0_2x8[2] = 0x00000000;
                UniReshuffle_dual_1_2x8[2] = 0x00000001;
            }
            else if (width + padXLeft == 3)
            {
                UniReshuffle_dual_0_2x8[2] = 0x00000200;
                UniReshuffle_dual_1_2x8[2] = 0x00000001;
            }
            else if (width + padXLeft == 4)
            {
                UniReshuffle_dual_0_2x8[2] = 0x00000200;
                UniReshuffle_dual_1_2x8[2] = 0x00000301;
            }
            else if (width + padXLeft == 5)
            {
                UniReshuffle_dual_0_2x8[2] = 0x00040200;
                UniReshuffle_dual_1_2x8[2] = 0x00000301;
            }
            else if (width + padXLeft == 6)
            {
                UniReshuffle_dual_0_2x8[2] = 0x00040200;
                UniReshuffle_dual_1_2x8[2] = 0x00050301;
            }
            else if (width + padXLeft == 7)
            {
                UniReshuffle_dual_1_2x8[2] = 0x00050301;
            }
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16Stride2", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_dual_0_2x8", 1, UniReshuffle_dual_0_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_dual_1_2x8", 1, UniReshuffle_dual_1_2x8);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 4;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + padXLeft + padXRight + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + padYTop + padYBottom + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && stride_x == 4 && stride_y == 4)
    {
        vx_uint32 UniReshuffle_quad_0_4x4[16] = {
            0x01010101, // TCfg
            0x01010000, // ASelt
            0x00040000, 0x00040000, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 UniReshuffle_quad_1_4x4[16] = {
            0x01010101, // TCfg
            0x01010000, // ASelt
            0x00050001, 0x00050001, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 UniReshuffle_quad_2_4x4[16] = {
            0x01010101, // TCfg
            0x01010000, // ASelt
            0x00060002, 0x00060002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 UniReshuffle_quad_3_4x4[16] = {
            0x01010101, // TCfg
            0x01010000, // ASelt
            0x00070003, 0x00070003, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };


        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16Stride4", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_quad_0_4x4", 1, UniReshuffle_quad_0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_quad_1_4x4", 1, UniReshuffle_quad_1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_quad_2_4x4", 1, UniReshuffle_quad_2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniReshuffle_quad_3_4x4", 1, UniReshuffle_quad_3_4x4);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 4;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + padXLeft + padXRight + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + padYTop + padYBottom + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (padXLeft_s) vxReleaseScalar(&padXLeft_s);
    if (padYTOP_s) vxReleaseScalar(&padYTOP_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (padXLeft_s) vxReleaseScalar(&padXLeft_s);
    if (padYTOP_s) vxReleaseScalar(&padYTOP_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/************************vxcTensorTranspose************************************/
vxnne_shader_executable vxnneTensorTransposeShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_uint32               *perm,
    vx_uint32               pnum,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable   = VX_NULL;
    vxnne_kernel_shaders    kernel             = VX_NULL;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]     = {(vx_reference)input, (vx_reference)output};
    vx_uint32    dims              = TENSOR_DIM_NUM(input);
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth             = (dims > 2) ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_uint32    batch             = (dims > 3) ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_tensor    src               = NULL;
    vx_tensor    dst               = NULL;
    vx_uint32    maxWorkGroupSize  = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (perm[0] == 2 && perm[1] == 0 && perm[2] == 1 && pnum > 2 && (width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH)
    {
        vx_int32 sizes[4] = {1};

        width    = width * height;
        height   = depth;
        depth    = 1;

        sizes[0] = width;
        sizes[1] = height;
        sizes[2] = 1;
        sizes[3] = batch;
        dims     = TENSOR_DIM_NUM(input);
        src = vxoTensor_ReshapeTensor(input, sizes, dims);

        sizes[0] = height;
        sizes[1] = width;
        sizes[2] = 1;
        sizes[3] = batch;
        dims    = TENSOR_DIM_NUM(output);
        dst = vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)src;
        parameters[1] = (vx_reference)dst;
        pnum = 2;
    }
    else if (perm[0] == 1 && perm[1] == 2 && perm[2] == 0 && pnum > 2 && (height * depth < IMG_MAX_WIDTH))
    {
        vx_int32 sizes[4] = {1};

        height   = height * depth;
        depth    = 1;

        sizes[0] = width;
        sizes[1] = height;
        sizes[2] = 1;
        sizes[3] = batch;
        dims     = TENSOR_DIM_NUM(input);
        src = vxoTensor_ReshapeTensor(input, sizes, dims);

        sizes[0] = height;
        sizes[1] = width;
        sizes[2] = 1;
        sizes[3] = batch;
        dims    = TENSOR_DIM_NUM(output);
        dst = vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)src;
        parameters[1] = (vx_reference)dst;
        pnum = 2;
    }

    borderMode->mode = VX_BORDER_REPLICATE;
    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorTranspose, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorTranspose.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxTensorTranspose", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (((inputFormat == VX_TYPE_INT16 && outputFormat == inputFormat)
     || (inputFormat == VX_TYPE_FLOAT16 && outputFormat == inputFormat)
     || (inputFormat == VX_TYPE_INT8 && outputFormat == inputFormat)
     || (inputFormat == VX_TYPE_UINT8 && outputFormat == inputFormat))
     && pnum == 2)
    {
        if ((inputFormat == VX_TYPE_UINT8 && outputFormat == inputFormat)
         || (inputFormat == VX_TYPE_INT8 && outputFormat == inputFormat))
        {
            vx_uint32 uniExchangeStride1_part0_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x01010000, 0x03030202, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride1_part1_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x05050404, 0x07070606, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x09080100, 0x09080100, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0b0a0302, 0x0b0a0302, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part2_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0d0c0504, 0x0d0c0504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part3_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0f0e0706, 0x0f0e0706, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part0_2x8", 1, uniExchangeStride1_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part1_2x8", 1, uniExchangeStride1_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part0_2x8", 1, uniExchange8Bits_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part1_2x8", 1, uniExchange8Bits_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part2_2x8", 1, uniExchange8Bits_part2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part3_2x8", 1, uniExchange8Bits_part3_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            vx_uint32 uniExchangeStride1_part0_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x01010000, 0x03030202, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride1_part1_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x05050404, 0x07070606, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride2_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x01000100, 0x03020302, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride2_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x05040504, 0x07060706, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride4_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride4_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x07060504, 0x07060504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits_2D", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part0_2x8", 1, uniExchangeStride1_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part1_2x8", 1, uniExchangeStride1_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2_part0_2x8", 1, uniExchangeStride2_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2_part1_2x8", 1, uniExchangeStride2_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4_part0_2x8", 1, uniExchangeStride4_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4_part1_2x8", 1, uniExchangeStride4_part1_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }

        execution_parameters.globalWorkScale[0]    = 8;
        execution_parameters.globalWorkScale[1]    = 8;
        execution_parameters.globalWorkScale[2]    = 1;
    }
    else if ((inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)&& pnum == 3 )
    {
        vx_uint32 uniPackDataABCD_01[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x04000400, 0x05010501, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackDataABCD_23[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x06020602, 0x07030703, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00006400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]    = 8;
        execution_parameters.globalWorkScale[1]    = 1;
        execution_parameters.globalWorkScale[2]    = 4;
        if (perm[0] == 2 && perm[1] == 0 && perm[2] == 1)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2CWH", borderMode);
        else if (perm[0] == 2 && perm[1] == 1 && perm[2] == 0)
        {
            vx_uint32 uniPackedABAB_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x01010000, 0x03030202, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniPackedABCDLo_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x01000100, 0x03020302, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniPackedABCDHi_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x05040504, 0x07060706, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniPacked01234567Lo_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniPacked01234567Hi_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x07060504, 0x07060504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2CHW", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedABAB_2x8", 1, uniPackedABAB_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedABCDLo_2x8", 1, uniPackedABCDLo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedABCDHi_2x8", 1, uniPackedABCDHi_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPacked01234567Lo_2x8", 1, uniPacked01234567Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPacked01234567Hi_2x8", 1, uniPacked01234567Hi_2x8);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]    = 4;
            execution_parameters.globalWorkScale[1]    = 1;
            execution_parameters.globalWorkScale[2]    = 8;
        }
        else if (perm[0] == 0 && perm[1] == 2 && perm[2] == 1)
        {
            execution_parameters.globalWorkScale[0]    = 8;
            execution_parameters.globalWorkScale[1]    = 4;
            execution_parameters.globalWorkScale[2]    = 1;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2WCH", borderMode);
        }
        else if ((perm[0] == 1 && perm[1] == 2 && perm[2] == 0) || (perm[0] == 1 && perm[1] == 0 && perm[2] == 2))
        {
            vx_uint32 uniExchangeStride1_part0_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x01010000, 0x03030202, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride1_part1_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x05050404, 0x07070606, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride2_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x01000100, 0x03020302, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride2_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11001100, // ASelt
                0x05040504, 0x07060706, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride4_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride4_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x07060504, 0x07060504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            execution_parameters.globalWorkScale[0]    = 8;
            execution_parameters.globalWorkScale[1]    = 8;
            execution_parameters.globalWorkScale[2]    = 1;

            if (perm[0] == 1 && perm[1] == 2 && perm[2] == 0)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2HCW", borderMode);
            else
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2HWC", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part0_2x8", 1, uniExchangeStride1_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part1_2x8", 1, uniExchangeStride1_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2_part0_2x8", 1, uniExchangeStride2_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2_part1_2x8", 1, uniExchangeStride2_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4_part0_2x8", 1, uniExchangeStride4_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4_part1_2x8", 1, uniExchangeStride4_part1_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackDataABCD_01", 1, uniPackDataABCD_01);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackDataABCD_23", 1, uniPackDataABCD_23);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if ((inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_UINT8)&& pnum == 3 )
    {
        vx_uint32 uniPackDataABCD_01[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x04000400, 0x05010501, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPackDataABCD_23[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x06020602, 0x07030703, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]    = 8;
        execution_parameters.globalWorkScale[1]    = 1;
        execution_parameters.globalWorkScale[2]    = 4;

        if (perm[0] == 2 && perm[1] == 0 && perm[2] == 1)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2CWH_int8", borderMode);
        else if (perm[0] == 2 && perm[1] == 1 && perm[2] == 0)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2CHW_int8", borderMode);
        else if (perm[0] == 0 && perm[1] == 2 && perm[2] == 1)
        {
            execution_parameters.globalWorkScale[0]    = 8;
            execution_parameters.globalWorkScale[1]    = 4;
            execution_parameters.globalWorkScale[2]    = 1;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2WCH_int8", borderMode);
        }
        else if ((perm[0] == 1 && perm[1] == 2 && perm[2] == 0) || (perm[0] == 1 && perm[1] == 0 && perm[2] == 2))
        {
            vx_uint32 uniExchangeStride1_part0_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x01010000, 0x03030202, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchangeStride1_part1_2x8[16] = {
                0x11111111, // TCfg
                0x10101010, // ASelt
                0x05050404, 0x07070606, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part0_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x09080100, 0x09080100, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part1_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0b0a0302, 0x0b0a0302, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part2_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0d0c0504, 0x0d0c0504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };
            vx_uint32 uniExchange8Bits_part3_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x0f0e0706, 0x0f0e0706, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            execution_parameters.globalWorkScale[0]    = 8;
            execution_parameters.globalWorkScale[1]    = 8;
            execution_parameters.globalWorkScale[2]    = 1;

            if (perm[0] == 1 && perm[1] == 0 && perm[2] == 2)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2HWC_int8", borderMode);
            else
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_WHC2HCW_int8", borderMode);

            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part0_2x8", 1, uniExchangeStride1_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1_part1_2x8", 1, uniExchangeStride1_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part0_2x8", 1, uniExchange8Bits_part0_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part1_2x8", 1, uniExchange8Bits_part1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part2_2x8", 1, uniExchange8Bits_part2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchange8Bits_part3_2x8", 1, uniExchange8Bits_part3_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackDataABCD_01", 1, uniPackDataABCD_01);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackDataABCD_23", 1, uniPackDataABCD_23);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkSize[0]    = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]    = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]    = (depth + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********RPN SOFT MAX****************************************************/
vxnne_shader_executable vxnneRPNSoftMaxShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor  inputs,
    vx_tensor  outputs
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[2]     = {(vx_reference)inputs, (vx_reference)outputs};

    vx_enum  inputFormat = TENSOR_DATA_TYPE(inputs);
    vx_enum  outputFormat= TENSOR_DATA_TYPE(outputs);
    char *programSources[2] = {NULL, NULL};

    vx_uint32 UniformDP4x4_cvtFP16ToFP32[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
    };
    vx_uint32 Uniform2x8_SubFp16[16] = {
        0x99999999, // TCfg
        0x44444444, // ASelt
        0x33221100, 0x77665544, // ABin
        0xaaaaaaaa, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
    };
    vx_uint32 UniformDP4x4_cvtFP16ToFp32High[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00050004, 0x00070006, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
    };
    vx_uint32 UniformDP2x8_packTwoF16[16] = {
        0x11111111, // TCfg
        0x11110000, // ASelt
        0x06040200, 0x06040200, // ABin
        0x22222222, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
    };
/*    vx_uint32 Uniform2x8_SubInt8[16] = {
        0x99999999, // TCfg
        0x44444444, // ASelt
        0x33221100, 0x77665544, // ABin
        0xaaaaaaaa, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
    };
    vx_uint32 UniformDP4x4_cvtInt8toFp16_low[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x01010101, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 UniformDP4x4_cvtInt8toFp16_high[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00050004, 0x00070006, // ABin
        0x01010101, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    */
    vx_uint32 Uni4x4_Sub_low[16] = {
        0x09090909, // TCfg
        0x04040404, // ASelt
        0x00110000, 0x00330022, // ABin
        0x0a0a0a0a, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
    };
    vx_uint32 Uni4x4_Sub_high[16] = {
        0x09090909, // TCfg
        0x04040404, // ASelt
        0x00550044, 0x00770066, // ABin
        0x0a0a0a0a, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
    };

    vx_uint32 imgWid = 0, imgHei = 0, imgChe = 0;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, inputs=%p, outputs=%p",
         context, kernelEnum, borderMode, inputs, outputs);

    imgWid  = TENSOR_VIEW_SIZE_INDEX(inputs, 0);
    imgHei  = TENSOR_VIEW_SIZE_INDEX(inputs, 1);
    imgChe  = TENSOR_VIEW_SIZE_INDEX(inputs, 2) / 2;

    execution_parameters.globalWorkScale[0]  = 8;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((imgWid + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (imgHei  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = imgChe;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, RPNSoftMax, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));

        vxmONERROR(getFilePath("nnvxc_kernels/RPNSoftMax.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "vxcRPN_Softmax", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_FP16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_FLOAT16)
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT8", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UINT8", borderMode);
        if (!shaderExecutable) goto OnError;
    }

    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDP2x8_packTwoF16", 1, UniformDP2x8_packTwoF16);

    if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_FLOAT16)
    {
        vx_float32  softMaxScale = 0;
        vx_int8 fixedPointPos = TENSOR_POS(inputs);
        if ((fixedPointPos) > 0)
            softMaxScale = (1.0f / ((vx_float32) (1 << (fixedPointPos))));
        else
            softMaxScale = ((vx_float32) (1 << -(fixedPointPos)));

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_low", 1, Uni4x4_Sub_low);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_high", 1, Uni4x4_Sub_high);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "softMaxScale", 1, &softMaxScale);
    }
    else  if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
    {
        vx_float32  softMaxScale = TENSOR_TF_SCALE(inputs);
       // vx_float32  softMaxZP =  TENSOR_TF_ZEROPOINT(inputs);

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_low", 1, Uni4x4_Sub_low);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_high", 1, Uni4x4_Sub_high);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "softMaxScale", 1, &softMaxScale);
       // status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "softMaxZP", 1, &softMaxZP);
    }
    else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_FLOAT16)
    {
        vx_float32  softMaxScale = 0;
        vx_int8 fixedPointPos = TENSOR_POS(inputs);
        if ((fixedPointPos) > 0)
            softMaxScale = (1.0f / ((vx_float32) (1 << (fixedPointPos))));
        else
            softMaxScale = ((vx_float32) (1 << -(fixedPointPos)));

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_low", 1, Uni4x4_Sub_low);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Sub_high", 1, Uni4x4_Sub_high);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "softMaxScale", 1, &softMaxScale);
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
    {
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDP4x4_cvtFP16ToFP32", 1, UniformDP4x4_cvtFP16ToFP32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uniform2x8_SubFp16", 1, Uniform2x8_SubFp16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDP4x4_cvtFP16ToFp32High", 1, UniformDP4x4_cvtFP16ToFp32High);
    }
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
vxnne_shader_executable vxnneRPNRegressionShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor  scores,
    vx_tensor  bboxs,
    vx_tensor  anchors,
    vx_tensor  output,
    vx_scalar feat_stride,
    vx_scalar img_W,
    vx_scalar img_H,
    vx_scalar min_box_W,
    vx_scalar min_box_H
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_SUCCESS;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[9]     = {  (vx_reference)scores, (vx_reference)bboxs, (vx_reference)anchors, (vx_reference)output,
        (vx_reference)feat_stride, (vx_reference)img_W, (vx_reference)img_H, (vx_reference)min_box_W,
        (vx_reference)min_box_H};

    vx_enum  bboxsFormat  = TENSOR_DATA_TYPE(bboxs);
    char *programSources = NULL;

    vx_uint32 UniformDP4x4_cvtFP16ToFP32[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
    };
    vx_uint32 UniformDp2x8_packF16[16] = {
        0x00011111, // TCfg
        0x00010000, // ASelt
        0x06040200, 0x00000000, // ABin
        0x00022222, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 UniformDP4x4_cvtInt8toFp16_low[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x01010101, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 Uni4x4_Cvt2Float32_low[16] = {
        0x01010101, // TCfg
        0x00000000, // ASelt
        0x00010000, 0x00030002, // ABin
        0x02020202, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000100, // AccumType, ConstantType, and PostShift
        0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
    };
   /* vx_uint32 Uni4x4_Sub_ZP_low[16] = {
        0x09090909, // TCfg
        0x04040404, // ASelt
        0x00010000, 0x00030002, // ABin
        0x0a0a0a0a, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
    };
    */


    vx_bool is_float32_output = vx_false_e;
    vx_uint32 imgWid = 0, imgHei = 0, imgChe = 0;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, output=%p",
         context, kernelEnum, borderMode, output);

    if (scores->dims[0] * 10 == output->dims[0])
        is_float32_output = vx_true_e;

    imgWid  = TENSOR_VIEW_SIZE_INDEX(scores, 0);
    imgHei  = TENSOR_VIEW_SIZE_INDEX(scores, 1);
    imgChe  = TENSOR_VIEW_SIZE_INDEX(scores, 2) / 2;

    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((imgWid + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (imgHei  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = imgChe;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, RPNRegression, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/RPNRegression.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcRPN_Regression", program, 9, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }
    if (bboxsFormat == VX_TYPE_FLOAT16)
    {
        if (is_float32_output)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_FP16toFP32", borderMode);
        else
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_FP16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (bboxsFormat == VX_TYPE_INT16)
    {
        if (is_float32_output)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT16toFP32", borderMode);
        else
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (bboxsFormat == VX_TYPE_INT8)
    {
        if(is_float32_output)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT8toFP32", borderMode);
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_INT8", borderMode);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDP4x4_cvtInt8toFp16_low", 1, UniformDP4x4_cvtInt8toFp16_low);
        }
        if (!shaderExecutable) goto OnError;
    }
    else if (bboxsFormat == VX_TYPE_UINT8)
    {
        if(is_float32_output)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UINT8toFP32", borderMode);
        else
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UINT8", borderMode);
        if (!shaderExecutable) goto OnError;
    }

    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDP4x4_cvtFP16ToFP32", 1, UniformDP4x4_cvtFP16ToFP32);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDp2x8_packF16", 1, UniformDp2x8_packF16);
    if (bboxsFormat == VX_TYPE_INT8)
    {
        vx_float32  bboxScale;
        vx_int8 fixedPointPos = TENSOR_POS(bboxs);
        if ((fixedPointPos) > 0)
            bboxScale = (1.0f / ((vx_float32) (1 << (fixedPointPos))));
        else
            bboxScale = ((vx_float32) (1 << -(fixedPointPos)));

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bboxScale", 1, &bboxScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Cvt2Float32_low", 1, &Uni4x4_Cvt2Float32_low);
    }
    else if (bboxsFormat == VX_TYPE_INT16)
    {
        vx_float32  bboxScale;
        vx_int8 fixedPointPos = TENSOR_POS(bboxs);
        if ((fixedPointPos) > 0)
            bboxScale = (1.0f / ((vx_float32) (1 << (fixedPointPos))));
        else
            bboxScale = ((vx_float32) (1 << -(fixedPointPos)));

        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bboxScale", 1, &bboxScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Cvt2Float32_low", 1, &Uni4x4_Cvt2Float32_low);
    }
    else if(bboxsFormat == VX_TYPE_UINT8)
    {
        vx_float32  bboxScale = TENSOR_TF_SCALE(bboxs);
        vx_float32  bboxZP =  (vx_uint8)TENSOR_TF_ZEROPOINT(bboxs);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bboxScale", 1, &bboxScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "bboxZP", 1, &bboxZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Uni4x4_Cvt2Float32_low", 1, &Uni4x4_Cvt2Float32_low);
   }
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 9);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneRPNNmsShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor proposal,
    vx_tensor roi_indices,
    vx_scalar real_roi_t,
    vx_scalar pre_nms_topn,
    vx_scalar post_nms_topn,
    vx_scalar nms_thresh)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[6]     = {  (vx_reference)proposal,
                                        (vx_reference)roi_indices,
                                        (vx_reference)real_roi_t,
                                        (vx_reference)pre_nms_topn,
                                        (vx_reference)post_nms_topn,
                                        (vx_reference)nms_thresh};
    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, proposal=%p, roi_indices=%p, real_roi_t=%p, pre_nms_topn=%p, post_nms_topn=%p, nms_thresh=%p",
         context, kernelEnum, borderMode, proposal, roi_indices, real_roi_t, pre_nms_topn, post_nms_topn, nms_thresh);

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, RPNNms, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/RPNNms.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "Nms", program, 6, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }
    {
        vx_uint32 UniformDp4x4_cvtF16toF32Score[16] = {
            0x00000001, // TCfg
            0x00000000, // ASelt
            0x00000004, 0x00000000, // ABin
            0x00000002, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniformDp4x4_cvtF16toF32Info[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "VXC", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDp4x4_cvtF16toF32Score", 1, UniformDp4x4_cvtF16toF32Score);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniformDp4x4_cvtF16toF32Info", 1, UniformDp4x4_cvtF16toF32Info);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;

        execution_parameters.localWorkSize[0]    = 32;
        execution_parameters.localWorkSize[1]    = 1;

        execution_parameters.globalWorkSize[0]   = 32;
        execution_parameters.globalWorkSize[1]   = 1;
    }


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 6);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********RPN Retrieve****************************************************/
vxnne_shader_executable vxnneRPNRetrieveShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               proposal,
    vx_tensor               roi_indices,
    vx_scalar               real_roi_t,
    vx_tensor               roi_output,
    vx_tensor               score_output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[5] = {(vx_reference)proposal,
                                  (vx_reference)roi_indices,
                                  (vx_reference)real_roi_t,
                                  (vx_reference)roi_output,
                                  (vx_reference)score_output};

    vx_uint32 UniDp2x8_pack[16] = {
        0x00011111, // TCfg
        0x00000000, // ASelt
        0x02010004, 0x00000003, // ABin
        0x00022222, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000000, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 UniDp2x8_pack0[16] = {
        0x00000011, // TCfg
        0x00000010, // ASelt
        0x00000404, 0x00000000, // ABin
        0x00000022, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };
    vx_uint32 UniDp2x8_pack1[16] = {
        0x00001111, // TCfg
        0x00001100, // ASelt
        0x01000100, 0x00000000, // ABin
        0x00002222, // BSelt
        0x00000000, 0x00000000, // BBin
        0x00000400, // AccumType, ConstantType, and PostShift
        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
    };

    vx_int32  imgWid = 0, imgHei = 1;
    vx_int32 storeScore = 0;
    vx_uint32 param_num = 4;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, proposal=%p, roi_indices=%p, real_roi_t=%p, roi_output=%p, score_output=%p",
         context, kernelEnum, borderMode, proposal, roi_indices, real_roi_t, roi_output, score_output);

    imgWid = TENSOR_VIEW_SIZE_INDEX(roi_indices, 0);
    if (score_output != NULL){
        storeScore = 1;
        param_num = 5;
    }

    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((imgWid + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (imgHei  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, RPNRetrieve, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/RPNRetrieve.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcRPN_Retrieve", program, param_num, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (storeScore)
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_FP16", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else
    {
        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_noScore_FP16", borderMode);
        if (!shaderExecutable) goto OnError;
    }


    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniDp2x8_pack", 1, UniDp2x8_pack);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniDp2x8_pack0", 1, UniDp2x8_pack0);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniDp2x8_pack1", 1, UniDp2x8_pack1);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "imgWid", 1, &imgWid);
    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "storeScore", 1, &storeScore);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, param_num);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********RPN Retrieve****************************************************/
vxnne_shader_executable vxnneRPNSortShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               proposal
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[3];

    vx_int32  len = 0, flag = 0;
    vx_scalar s0 = NULL, s1 = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, proposal=%p",
         context, kernelEnum, borderMode, proposal);

    len = TENSOR_VIEW_SIZE_INDEX(proposal, 1);

    s0 = vxCreateScalar(context, VX_TYPE_INT32, &flag);
    s1 = vxCreateScalar(context, VX_TYPE_INT32, &len);

    parameters[0] = (vx_reference)proposal;
    parameters[1] = (vx_reference)s0;
    parameters[2] = (vx_reference)s1;

    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;

    execution_parameters.localWorkSize[0]    = 32;
    execution_parameters.localWorkSize[1]    = 1;

    execution_parameters.globalWorkSize[0]   = 32;
    execution_parameters.globalWorkSize[1]   = 1;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, RPNSort, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/RPNSort.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcRPN_Sort", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_FP16", borderMode);
    if (!shaderExecutable) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (s0 != NULL) vxReleaseScalar(&s0);
    if (s1 != NULL) vxReleaseScalar(&s1);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (s0 != NULL) vxReleaseScalar(&s0);
    if (s1 != NULL) vxReleaseScalar(&s1);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneTensorConvFormatShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength                           = 0;
#endif
    vx_program program                                 = VX_NULL;
    vx_status  status                                  = VX_FAILURE;
    vxnne_shader_executable shaderExecutable           = VX_NULL;
    vxnne_kernel_shaders    kernel                     = VX_NULL;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]                         = {(vx_reference)input, (vx_reference)output};
    vx_uint32    width                                 = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height                                = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth                                 = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch                                 = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    dims                                  = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_enum      inputFormat                           = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat                          = TENSOR_DATA_TYPE(output);
    vx_int8      srcFixPointPos                        = TENSOR_POS(input);
    vx_int8      dstFixPointPos                        = TENSOR_POS(output);
    vx_bool      useImage2DFlag                        = (vx_bool)(width * height < IMG_MAX_WIDTH);
    vx_float32   div_scale                             = 1.0f;
    vx_tensor    input_rs                              = NULL;
    vx_tensor    output_rs                             = NULL;
    vx_int32     sizes[4]                              = {width * height, depth, 1, batch};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;
    input_rs         = vxoTensor_ReshapeTensor(input, sizes, dims);
    output_rs        = vxoTensor_ReshapeTensor(output, sizes, dims);

    if (inputFormat == VX_TYPE_INT8)
    {
        if (srcFixPointPos >= 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            div_scale *= (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixPointPos >= 0)
        {
            div_scale *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            div_scale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    if (useImage2DFlag)
    {
        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorConvFormat, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorConvFormat.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "convFormat", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT8)
    {
        vx_float32    convFormat_FP16toINT8 = div_scale;

        vx_uint32 uniFp16MulFp16toInt8_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toInt8_2D", borderMode);
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16toInt8", borderMode);
        }
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulFp16toInt8_2x8", 1, uniFp16MulFp16toInt8_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "convFormat_FP16toINT8", 1, &convFormat_FP16toINT8);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 4;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 4;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;

}

vxnne_shader_executable vxnneTensor2RowShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_int32                kernelSize_x,
    vx_int32                kernelSize_y,
    vx_int32                dilation_x,
    vx_int32                dilation_y,
    vx_int32                stride_x,
    vx_int32                stride_y,
    vx_int32                padding_x,
    vx_int32                padding_y,
    vx_int32                outputWidth,
    vx_int32                outputHeight,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vx_uint32  width            = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32  height           = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32  channels         = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_tensor  src              = VX_NULL;
    vx_bool    enable_K1S1      = vx_false_e;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]     = {(vx_reference)input, (vx_reference)output};
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_bool      useImage2DFlag    = (vx_bool)(outputWidth * outputHeight < IMG_MAX_WIDTH);

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    useImage2DFlag = (vx_bool)((outputWidth * outputHeight < IMG_MAX_WIDTH) && dilation_x == 1 && dilation_y == 1);

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
    {
        borderMode->constant_value.S16 = 0;
    }
    else if (inputFormat == VX_TYPE_INT8)
    {
        borderMode->constant_value.U8 = 0;
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        borderMode->constant_value.U8 = (vx_uint8)TENSOR_TF_ZEROPOINT(input);
    }

    if (kernelSize_x == 1 && kernelSize_y == 1 && stride_x == 1 && stride_y == 1
     && padding_x == 0 && padding_y == 0 && dilation_x == 1 && dilation_y == 1
     && useImage2DFlag && (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_UINT8))
    {
        vx_int32 sizes[4] = {width * height, channels, 1, 1};

        src = vxoTensor_ReshapeTensor(input, sizes, 2);

        parameters[0] = (vx_reference)src;

        enable_K1S1 = vx_true_e;

        borderMode->mode = VX_BORDER_REPLICATE;
    }
    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Tensor2Row, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Tensor2Row.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "tensor2row", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enable_K1S1)
    {
        vx_uint32 uniExchangeStride1Fp_2x8[16] = {
            0x33333333, // TCfg
            0x10101010, // ASelt
            0x02020000, 0x06060404, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007300, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExchangeStride1EvenFp_2x8[16] = {
            0x33333333, // TCfg
            0x10101010, // ASelt
            0x03030101, 0x07070505, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExchangeStride2FpOdd_2x8[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x01000100, 0x05040504, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExchangeStride2FpEven_2x8[16] = {
            0x33333333, // TCfg
            0x11001100, // ASelt
            0x03020302, 0x07060706, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExchangeStride4Odd_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExchangeStride4Even_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x07060504, 0x07060504, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00007100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        execution_parameters.workDim            = 2;
        execution_parameters.globalWorkScale[0] = 8;
        execution_parameters.globalWorkScale[1] = 8;
        execution_parameters.globalWorkSize[0]  = gcmALIGN_NP2_SAFE((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]  = (channels + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_K1S1", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1Fp_2x8", 1, uniExchangeStride1Fp_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride1EvenFp_2x8", 1, uniExchangeStride1EvenFp_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2FpOdd_2x8", 1, uniExchangeStride2FpOdd_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride2FpEven_2x8", 1, uniExchangeStride2FpEven_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4Odd_2x8", 1, uniExchangeStride4Odd_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExchangeStride4Even_2x8", 1, uniExchangeStride4Even_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16 || inputFormat == VX_TYPE_UINT8 || inputFormat == VX_TYPE_INT8)
    {
        vx_uint32 kernelSizeXY = kernelSize_x * kernelSize_y;

        vx_int32 padding_xy[2] = {padding_x, padding_y};
        vx_int32 strideXY[]    = {stride_x, stride_y};

        if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
        {
            char kernelName[100];
            if (kernelSize_x < 17 && useImage2DFlag)
                sprintf(kernelName, "_Integer16_%d", kernelSize_x);
            else if (kernelSize_x > 16 && useImage2DFlag)
                sprintf(kernelName, "_Integer16_Generic");
            else if (kernelSize_x < 17 && !useImage2DFlag && dilation_x == 1 && dilation_y == 1)
                sprintf(kernelName, "_Tensor_Integer16_%d", kernelSize_x);
            else
                sprintf(kernelName, "_Tensor_Integer16_Generic");

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_UINT8)
        {
            char kernelName[100];
            if (kernelSize_x < 17 && useImage2DFlag)
                sprintf(kernelName, "_Integer8_%d", kernelSize_x);
            else if (kernelSize_x > 16 && useImage2DFlag)
                sprintf(kernelName, "_Integer8_Generic");
            else if (kernelSize_x < 17 && !useImage2DFlag && dilation_x == 1 && dilation_y == 1)
                sprintf(kernelName, "_Tensor_Integer8_%d", kernelSize_x);
            else
                sprintf(kernelName, "_Tensor_Integer8_Generic");

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "outputWidth", 1, &outputWidth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSizeXY", 1, &kernelSizeXY);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSizeX", 1, &kernelSize_x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelSizeY", 1, &kernelSize_y);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding_xy", 1, padding_xy);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "strideXY", 1, strideXY);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dilate_x", 1, &dilation_x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dilate_y", 1, &dilation_y);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.workDim             = 3;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = (outputWidth + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0];
        execution_parameters.globalWorkSize[1]   = (outputHeight + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = channels;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src) vxoTensor_ReleaseTensor(&src);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src) vxoTensor_ReleaseTensor(&src);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGemmShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               weight,
    vx_tensor               bias,
    vx_int32                fuseCode,
    vx_bool                 enable_2dTensor,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vx_uint32  inputSize        = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32  width            = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32  height           = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32  depth            = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32  dims             = TENSOR_DIM_NUM(output) == 1 ? 2 : TENSOR_DIM_NUM(output);
    vx_tensor  outputs          = NULL;
    vx_uint32  kernel_x         = TENSOR_VIEW_SIZE_INDEX(weight, 0);
    vx_uint32  kernel_y         = TENSOR_VIEW_SIZE_INDEX(weight, 1);
    vx_uint32  ifm              = TENSOR_VIEW_SIZE_INDEX(weight, 2);
    vx_uint32  ofm              = TENSOR_VIEW_SIZE_INDEX(weight, 3);
    vx_tensor  weights          = NULL;
    vx_tensor  biases           = NULL;
    vx_scalar  relu_s           = NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_uint32  input_ZP         = TENSOR_TF_ZEROPOINT(input);
    vx_uint32  weight_ZP        = TENSOR_TF_ZEROPOINT(weight);
    vx_uint32  output_ZP        = TENSOR_TF_ZEROPOINT(output);
    vx_float32 input_scale      = TENSOR_TF_SCALE(input);
    vx_float32 weight_scale     = TENSOR_TF_SCALE(weight);
    vx_float32 output_scale     = TENSOR_TF_SCALE(output);

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {1, 1, 1}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[5]     = {(vx_reference)input, NULL, NULL, NULL, (vx_reference)output};
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_int32     size[]            = {1, 1, 1, 1};
    vx_float32   in_scale          = 0;
    vx_int32     dRelu             = 0;
    vx_bool      is_static_weights_biases       = vx_false_e;
    vx_bool      enable_adjust_biases           = vx_false_e;
    char *programSources[2]        = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (fuseCode == VX_NN_ACTIVATION_RELU)
        dRelu = 1;

    is_static_weights_biases = (vx_bool)(TENSOR_DATA_LIFETIME(weight) == VX_TENSOR_LIFE_TIME_STATIC && TENSOR_DATA_LIFETIME(bias) == VX_TENSOR_LIFE_TIME_STATIC);
    enable_adjust_biases     = is_static_weights_biases && TENSOR_QUANT_TYPE(weight) == VX_QUANT_AFFINE_SCALE && TENSOR_QUANT_TYPE(bias);

    relu_s  = vxCreateScalar(context, VX_TYPE_INT32, &dRelu);

    if (enable_2dTensor)
    {
        size[0] = width * height;
        size[1] = depth;
        size[2] = 1;
        size[3] = dims > 3 ? TENSOR_VIEW_SIZE_INDEX(output, 3) : 1;
        outputs = vxoTensor_ReshapeTensor(output, size, dims);
    }

    size[0] = kernel_x * kernel_y * ifm;
    size[1] = ofm;
    size[2] = 1;
    size[3] = 1;
    dims    = TENSOR_DIM_NUM(weight) == 1 ? 2 : TENSOR_DIM_NUM(weight);
    weights = vxoTensor_ReshapeTensor(weight, size, dims);

    size[0] = ofm;
    size[1] = 1;
    dims    = TENSOR_DIM_NUM(bias) == 1 ? 2 : TENSOR_DIM_NUM(bias);
    biases  = vxoTensor_ReshapeTensor(bias, size, dims);

    parameters[1] = (vx_reference)weights;
    parameters[2] = (vx_reference)biases;
    parameters[3] = (vx_reference)relu_s;
    if (enable_2dTensor)
        parameters[4] = (vx_reference)outputs;

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
    {
        borderMode->constant_value.S16 = 0;
    }
    else if (inputFormat == VX_TYPE_UINT8 && TENSOR_QUANT_TYPE(input) == VX_QUANT_AFFINE_SCALE)
    {
        borderMode->constant_value.U8 = (vx_uint8)weight_ZP;
    }
    else
    {
        borderMode->constant_value.U8 = 0;
    }

    if (TENSOR_QUANT_TYPE(input) == VX_QUANT_DYNAMIC_FIXED_POINT
          && TENSOR_QUANT_TYPE(weights) == VX_QUANT_DYNAMIC_FIXED_POINT
          && TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8   srcFixedPointPos  = TENSOR_POS(input);
        vx_int8   weiFixedPointPos  = TENSOR_POS(weights);
        vx_int8   dstFixedPointPos  = TENSOR_POS(output);
        vx_int32  postshift         = 0;

        postshift = postshift - srcFixedPointPos;
        postshift = postshift - weiFixedPointPos;
        postshift = postshift + dstFixedPointPos;

        if (postshift < 0)
        {
            in_scale = 1.0f / (vx_float32) (1 << -postshift);
        }
        else
        {
            in_scale = (vx_float32) (1 << postshift);
        }
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Gemm, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));
        vxmONERROR(getFilePath("nnvxc_kernels/Gemm.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "gemm", program, 5, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 inputSize_aln8 = inputSize;
        vx_uint32 uniMulAcc[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32_16x1[16] = {
            0x00000001, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000002, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (inputSize % 8 == 0)
        {
            borderMode->mode = VX_BORDER_REPLICATE;
        }

        inputSize_aln8 = gcmALIGN(inputSize, 8);

        if (enable_2dTensor)
        {
            if (TENSOR_DATA_TYPE(bias) == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_bias_fp16", borderMode);
            }
            else
            {
                if (context->evisNoInst.isVX2)
                {
                    vx_uint32 uniSumF16MulF16_8x2_b[16] = {
                        0x55555555, // TCfg
                        0x55550000, // ASelt
                        0x76543210, 0x76543210, // ABin
                        0x00000000, // BSelt
                        0x76543210, 0x76543210, // BBin
                        0x00000000, // AccumType, ConstantType, and PostShift
                        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                    };

                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_2p", borderMode);
                    if (!shaderExecutable) goto OnError;

                    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumF16MulF16_8x2_b", 1, &uniSumF16MulF16_8x2_b);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
                }
            }
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 4;
        }
        else
        {
            if (TENSOR_DATA_TYPE(bias) == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_fp16_bias_fp16", borderMode);
            }
            else
            {
                if (depth % 4 == 0)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_fp16_4x", borderMode);
                    if (!shaderExecutable) goto OnError;

                    execution_parameters.globalWorkScale[2]  = 4;
                }
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_fp16", borderMode);
            }
            if (!shaderExecutable) goto OnError;

        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc", 1, uniMulAcc);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_16x1", 1, uniFp16toFp32_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize_aln8", 1, &inputSize_aln8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8)
    {
        vx_uint32 inputSize_aln16 = gcmALIGN(inputSize, 16);
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccU8MulU8_16x2_b[16] = {
            0x55555555, 0x55555555, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000000, // AccumType, ConstantType, and PostShift
            0x76543210, 0xfedcba98, 0x76543210, 0xfedcba98, // Bin1Select
            0x00000000, 0x00000000, 0x00000000, 0x00000000, // unused
        };
        vx_uint32 uniMulAcc_Int8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccU8MulU8_16x2_b", 1, uniAccU8MulU8_16x2_b);
            if (status != VX_SUCCESS) goto OnError;
            execution_parameters.globalWorkScale[0]  = 4;
        }
        else
        {
            if (depth % 4 == 0)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int8_4x", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccU8MulU8_16x2_b", 1, uniAccU8MulU8_16x2_b);
                if (status != VX_SUCCESS) goto OnError;

                execution_parameters.globalWorkScale[2]  = 4;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int8", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc_Int8", 1, uniMulAcc_Int8);
                if (status != VX_SUCCESS) goto OnError;
            }
        }

        if (inputSize % 16 == 0)
        {
            borderMode->mode = VX_BORDER_REPLICATE;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize_aln16", 1, &inputSize_aln16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16)
    {
        vx_uint32 inputSize_aln8 = gcmALIGN(inputSize, 8);
        vx_uint32 uniMulAcc_Int16[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAcc16BMul16B_8x2_b[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x00000000, // BSelt
            0x76543210, 0x76543210, // BBin
            0x00000000, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 4;
        }
        else
        {
            if (depth % 4 == 0)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int16_4x", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[2]  = 4;
            }
            else
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        if (inputSize % 8 == 0)
        {
            borderMode->mode = VX_BORDER_REPLICATE;
        }

        if (context->evisNoInst.isVX2 && enable_2dTensor)
            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc16BMul16B_8x2_b", 1, uniAcc16BMul16B_8x2_b);
        else
            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc_Int16", 1, uniMulAcc_Int16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize_aln8", 1, &inputSize_aln8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;

    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        vx_uint32  inputSize_aln16 = inputSize;
        vx_uint32  Cycles_uint8    = inputSize;
        vx_uint8   minVal          = 0;
        vx_uint8   maxVal          = 0;
        vx_uint32  minData         = 0;
        vx_uint32  maxData         = 0;
        vx_uint32  packedZ1        = (weight_ZP << 24) | (weight_ZP << 16) | (weight_ZP << 8) | (weight_ZP);
        vx_uint32  packedZ0        = (input_ZP << 24) | (input_ZP << 16) | (input_ZP << 8) | (input_ZP);
        vx_int32   nZ1Z2           = gcmALIGN(inputSize, 64) * input_ZP * weight_ZP;
        vx_float32 uint8Scale      = input_scale * weight_scale / output_scale;
        vx_float32 outputZP        = (vx_float32)output_ZP;
        vx_uint32  uniAccQ1MulQ2_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccQaMulZb_16x2[16] = {
            0xaaaaaaaa, 0xaaaaaaaa, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000700, // AccumType, ConstantType, and PostShift
            packedZ1, packedZ1, packedZ1, packedZ1, packedZ0, packedZ0, packedZ0, packedZ0 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccU8MulZp_16x2[16] = {
            0x55555555, 0x55555555, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000700, // AccumType, ConstantType, and PostShift
            0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101 // Constant
        };
        vx_uint32 uniAccU8MulU8_16x2_b[16] = {
            0x55555555, 0x55555555, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000000, // AccumType, ConstantType, and PostShift
            0x76543210, 0xfedcba98, 0x76543210, 0xfedcba98, // Bin1Select
            0x00000000, 0x00000000, 0x00000000, 0x00000000, // unused
        };
        vx_uint32 uniAccU8subZpMulU8_32x1_b[16] = {
            0x55555555, 0xaaaaaaaa, // TCfg
            0x8a418820, 0xc5a92839, 0x42107b9a, 0x10842108, 0x84210842, // BinSelect
            0x00000000, // AccumType, ConstantType, and PostShift
            0x76543210, 0xfedcba98, 0x76543210, 0xfedcba98, // Bin1Select
            0x00000000, 0x00000000, 0x00000000, 0x00000000, // unused
        };

        if (enable_adjust_biases)
        {
            vx_uint32 i = 0;
            if (inputSize % 16 == 0)
            {
                borderMode->mode = VX_BORDER_REPLICATE;
            }

            inputSize_aln16 = gcmALIGN(inputSize, 16);

            if (enable_2dTensor || (depth % 4 == 0))
            {
                if (enable_2dTensor)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8_static", borderMode);
                    if (!shaderExecutable) goto OnError;

                    execution_parameters.globalWorkScale[0]  = 4;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_uint8_static_4x", borderMode);
                    if (!shaderExecutable) goto OnError;

                    execution_parameters.globalWorkScale[2]  = 4;
                }

                for (i = 8; i < 16; i++)
                {
                    vx_uint32 packedZP = (weight_ZP << 24) | (weight_ZP << 16) | (weight_ZP << 8) | weight_ZP;
                    uniAccU8MulZp_16x2[i] = packedZP;
                }

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccU8MulZp_16x2", 1, uniAccU8MulZp_16x2);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccU8MulU8_16x2_b", 1, uniAccU8MulU8_16x2_b);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                vx_uint8  zp = (vx_uint8)weight_ZP;
                vx_uint32 packedCoefZP = (zp << 24) | (zp << 16) | (zp << 16) | zp;

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_uint8_static", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccU8subZpMulU8_32x1_b", 1, uniAccU8subZpMulU8_32x1_b);
                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "packedCoefZP", 1, &packedCoefZP);
                if (status != VX_SUCCESS) goto OnError;
            }

            calculateActivationRangeUInt8(fuseCode, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_uint32)minVal;
            maxData = (vx_uint32)maxVal;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize_aln16", 1, &inputSize_aln16);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            /*status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);*/
            /*status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);*/
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            if (inputSize % 64 == 0)
            {
                borderMode->mode = VX_BORDER_REPLICATE;
            }

            Cycles_uint8 = gcmALIGN(Cycles_uint8, 64);

            if (enable_2dTensor)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_uint8", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            calculateActivationRangeUInt8(fuseCode, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_uint32)minVal;
            maxData = (vx_uint32)maxVal;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQ1MulQ2_16x1", 1, uniAccQ1MulQ2_16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQaMulZb_16x2", 1, uniAccQaMulZb_16x2);
            if (status != VX_SUCCESS) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles_uint8", 1, &Cycles_uint8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nZ1Z2", 1, &nZ1Z2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            /*status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);*/
            /*status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);*/
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    if (enable_2dTensor)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.localWorkSize[0]    = SHADER_THREAD_COUNT;
        execution_parameters.localWorkSize[1]    = context->nnConfig.fixedFeature.shaderCoreCount;
        execution_parameters.globalWorkSize[0]   = gcmALIGN_NP2((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], execution_parameters.localWorkSize[0]);
        execution_parameters.globalWorkSize[1]   = gcmALIGN_NP2((depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], execution_parameters.localWorkSize[1]);
    }
    else
    {
        execution_parameters.workDim             = 3;
        execution_parameters.globalWorkSize[0]   = gcmALIGN_NP2_SAFE((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = (depth + execution_parameters.globalWorkScale[2] - 1) / execution_parameters.globalWorkScale[2];
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 5);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (weights) vxoTensor_ReleaseTensor(&weights);
    if (biases) vxoTensor_ReleaseTensor(&biases);
    if (outputs) vxoTensor_ReleaseTensor(&outputs);
    if (relu_s) vxReleaseScalar(&relu_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (weights) vxoTensor_ReleaseTensor(&weights);
    if (biases) vxoTensor_ReleaseTensor(&biases);
    if (outputs) vxoTensor_ReleaseTensor(&outputs);
    if (relu_s) vxReleaseScalar(&relu_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGemm_noBiasShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               weight,
    vx_int32                fuseCode,
    vx_bool                 enable_2dTensor,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vx_uint32  inputSize        = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32  width            = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32  height           = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32  depth            = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32  dims             = TENSOR_DIM_NUM(output) == 1 ? 2 : TENSOR_DIM_NUM(output);
    vx_tensor  outputs          = NULL;
    vx_uint32  kernel_x         = TENSOR_VIEW_SIZE_INDEX(weight, 0);
    vx_uint32  kernel_y         = TENSOR_VIEW_SIZE_INDEX(weight, 1);
    vx_uint32  ifm              = TENSOR_VIEW_SIZE_INDEX(weight, 2);
    vx_uint32  ofm              = TENSOR_VIEW_SIZE_INDEX(weight, 3);
    vx_tensor  weights          = NULL;
    vx_scalar  relu_s           = NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_uint32  input_ZP         = TENSOR_TF_ZEROPOINT(input);
    vx_uint32  weight_ZP        = TENSOR_TF_ZEROPOINT(weight);
    vx_uint32  output_ZP        = TENSOR_TF_ZEROPOINT(output);
    vx_float32 input_scale      = TENSOR_TF_SCALE(input);
    vx_float32 weight_scale     = TENSOR_TF_SCALE(weight);
    vx_float32 output_scale     = TENSOR_TF_SCALE(output);

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[4]     = {(vx_reference)input, NULL, NULL, (vx_reference)output};
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_int32     size[]            = {1, 1, 1, 1};
    vx_float32   in_scale          = 0;
    vx_int32     dRelu             = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (fuseCode == VX_NN_ACTIVATION_RELU)
        dRelu = 1;

    relu_s  = vxCreateScalar(context, VX_TYPE_INT32, &dRelu);

    if (enable_2dTensor)
    {
        size[0] = width * height;
        size[1] = depth;
        outputs = vxoTensor_ReshapeTensor(output, size, dims);
    }

    size[0] = kernel_x * kernel_y * ifm;
    size[1] = ofm;
    dims    = TENSOR_DIM_NUM(weight) == 1 ? 2 : TENSOR_DIM_NUM(weight);
    weights = vxoTensor_ReshapeTensor(weight, size, dims);

    parameters[1] = (vx_reference)weights;
    parameters[2] = (vx_reference)relu_s;
    if (enable_2dTensor)
        parameters[3] = (vx_reference)outputs;

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
    {
        borderMode->constant_value.S16 = 0;
    }
    else if (inputFormat == VX_TYPE_UINT8 && TENSOR_QUANT_TYPE(input) == VX_QUANT_AFFINE_SCALE)
    {
        borderMode->constant_value.U8 = (vx_uint8)input_ZP;
    }
    else
    {
        borderMode->constant_value.U8 = 0;
    }

    if (TENSOR_QUANT_TYPE(input) == VX_QUANT_DYNAMIC_FIXED_POINT
          && TENSOR_QUANT_TYPE(weights) == VX_QUANT_DYNAMIC_FIXED_POINT
          && TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8   srcFixedPointPos  = TENSOR_POS(input);
        vx_int8   weiFixedPointPos  = TENSOR_POS(weights);
        vx_int8   dstFixedPointPos  = TENSOR_POS(output);
        vx_int32  postshift         = 0;

        postshift = postshift - srcFixedPointPos;
        postshift = postshift - weiFixedPointPos;
        postshift = postshift + dstFixedPointPos;

        if (postshift < 0)
        {
            in_scale = 1.0f / (vx_float32) (1 << -postshift);
        }
        else
        {
            in_scale = (vx_float32) (1 << postshift);
        }
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Gemm_noBias, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Gemm_noBias.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "gemm_noBias", program, 4, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 Cycles = inputSize;
        vx_uint32 uniMulAcc[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        Cycles = gcmALIGN(Cycles, 32);

        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc", 1, uniMulAcc);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles", 1, &Cycles);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT8)
    {
        vx_uint32 Cycles_int8 = inputSize;
        vx_uint32 uniMulAcc_Int8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        Cycles_int8 = gcmALIGN(Cycles_int8, 64);
        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc_Int8", 1, uniMulAcc_Int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles_int8", 1, &Cycles_int8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_INT16)
    {
        vx_uint32 inputSize_algin32 = gcmALIGN(inputSize, 32);
        vx_uint32 uniMulAcc_Int16[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_int16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_int16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        if (inputSize % 32 == 0)
        {
            borderMode->mode = VX_BORDER_REPLICATE;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAcc_Int16", 1, uniMulAcc_Int16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize_algin32", 1, &inputSize_algin32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "in_scale", 1, &in_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        vx_uint32  Cycles_uint8    = inputSize;
        vx_uint8   minVal          = 0;
        vx_uint8   maxVal          = 0;
        vx_uint32  minData         = 0;
        vx_uint32  maxData         = 0;
        vx_uint32  packedZ1        = (weight_ZP << 24) | (weight_ZP << 16) | (weight_ZP << 8) | (weight_ZP);
        vx_uint32  packedZ0        = (input_ZP << 24) | (input_ZP << 16) | (input_ZP << 8) | (input_ZP);
        vx_int32   nZ1Z2           = gcmALIGN(inputSize, 64) * input_ZP * weight_ZP;
        vx_float32 uint8Scale      = input_scale * weight_scale / output_scale;
        vx_float32 outputZP        = (vx_float32)output_ZP;
        vx_uint32  uniAccQ1MulQ2_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccQaMulZb_16x2[16] = {
            0xaaaaaaaa, 0xaaaaaaaa, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000700, // AccumType, ConstantType, and PostShift
            packedZ1, packedZ1, packedZ1, packedZ1, packedZ0, packedZ0, packedZ0, packedZ0 // Constant
        };

        Cycles_uint8 = gcmALIGN(Cycles_uint8, 64);
        if (enable_2dTensor)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_uint8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Tensor_uint8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        calculateActivationRangeUInt8(fuseCode, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

        minData = (vx_uint32)minVal;
        maxData = (vx_uint32)maxVal;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQ1MulQ2_16x1", 1, uniAccQ1MulQ2_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccQaMulZb_16x2", 1, uniAccQaMulZb_16x2);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "Cycles_uint8", 1, &Cycles_uint8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "nZ1Z2", 1, &nZ1Z2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (enable_2dTensor)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.workDim             = 3;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (weights) vxoTensor_ReleaseTensor(&weights);
    if (outputs) vxoTensor_ReleaseTensor(&outputs);
    if (relu_s) vxReleaseScalar(&relu_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (weights) vxoTensor_ReleaseTensor(&weights);
    if (outputs) vxoTensor_ReleaseTensor(&outputs);
    if (relu_s) vxReleaseScalar(&relu_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********L2normalize sum sqrt****************************************************/
vxnne_shader_executable vxnneL2NormSumSqrtShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders kernel;
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]      = {NULL, NULL};
    vx_enum       srcFormat                  = TENSOR_DATA_TYPE(input);
    vx_int8       srcFixPointPos             = TENSOR_POS(input);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     height                     = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     depth                      = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     batch                      = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_tensor     inputReshaped              = NULL;
    vx_float32    inputScale                 = TENSOR_TF_SCALE(input);
    vx_int32      inputZP                    = TENSOR_TF_ZEROPOINT(input);
    vx_int32      sizes[]                    = {width * height, depth, 1, batch};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    inputReshaped = vxoTensor_ReshapeTensor(input, sizes, dims);

    parameters[0] = (vx_reference)inputReshaped;
    parameters[1] = (vx_reference)output;

    borderMode->mode = VX_BORDER_CONSTANT;

    if (srcFormat == VX_TYPE_INT8 || srcFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
            inputScale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        else
            inputScale = (vx_float32) (1 << -srcFixPointPos);
    }

    if (srcFormat == VX_TYPE_INT8)
        borderMode->constant_value.U8 = 0;
    else if (srcFormat == VX_TYPE_UINT8)
        borderMode->constant_value.U8 = (vx_uint8)TENSOR_TF_ZEROPOINT(input);
    else
        borderMode->constant_value.S16 = 0;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, L2NormSumSqrt, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/L2NormSumSqrt.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcL2NormScale", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (srcFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 UniFp16MulLo_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniFp16MulHi_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x01010101, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SumRsqrt", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16MulLo_dp4x4", 1, UniFp16MulLo_dp4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFp16MulHi_dp4x4", 1, UniFp16MulHi_dp4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_INT8)
    {
        vx_float32 r_inputScale = 1.0f / inputScale;
        vx_uint32 uniDataSquareAddU32Lo_4x4[16] = {
            0x0d0d0d0d, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x00000000, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00005400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSquareAddU32Hi_4x4[16] = {
            0x0d0d0d0d, // TCfg
            0x04040404, // ASelt
            0x00150004, 0x00370026, // ABin
            0x00000000, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00005400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SumRsqrt_int8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSquareAddU32Lo_4x4", 1, uniDataSquareAddU32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSquareAddU32Hi_4x4", 1, uniDataSquareAddU32Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "r_inputScale", 1, &r_inputScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_INT16)
    {
        vx_float32 r_inputScale = 1.0f / inputScale;
        vx_uint32 uniIntegerSquareLo_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x00000000, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniIntegerSquareHi_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x00000000, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SumRsqrt_int16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniIntegerSquareLo_4x4", 1, uniIntegerSquareLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniIntegerSquareHi_4x4", 1, uniIntegerSquareHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "r_inputScale", 1, &r_inputScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_UINT8)
    {
        vx_float32 r_inputScale = 1.0f / inputScale;
        vx_uint32 uniUInt8SquareLo_4x4[16] = {
            0x69696969, // TCfg
            0x40404040, // ASelt
            0x01110000, 0x03330222, // ABin
            0x54545454, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniUInt8SquareHi_4x4[16] = {
            0x69696969, // TCfg
            0x40404040, // ASelt
            0x05550444, 0x07770666, // ABin
            0x54545454, // BSelt
            0x00050004, 0x00070006, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_SumRsqrt_uint8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8SquareLo_4x4", 1, uniUInt8SquareLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUInt8SquareHi_4x4", 1, uniUInt8SquareHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "r_inputScale", 1, &r_inputScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0] = 8;
    execution_parameters.globalWorkScale[1] = 1;
    execution_parameters.globalWorkScale[2] = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = 1;


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (inputReshaped)  vxoTensor_ReleaseTensor(&inputReshaped);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (inputReshaped)  vxoTensor_ReleaseTensor(&inputReshaped);
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneL2NormSumScaleShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               sumTmp,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders kernel;
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]      = {NULL, NULL, NULL};
    vx_enum       srcFormat                  = TENSOR_DATA_TYPE(input);
    vx_enum       dstFormat                  = TENSOR_DATA_TYPE(output);
    vx_int8       srcFixPointPos             = TENSOR_POS(input);
    vx_int8       dstFixPointPos             = TENSOR_POS(output);
    vx_uint32     width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     height                     = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32     depth                      = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32     batch                      = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32     dims                       = TENSOR_DIM_NUM(input);
    vx_float32    inputScale                 = TENSOR_TF_SCALE(input);
    vx_float32    outputScale                = TENSOR_TF_SCALE(output);
    vx_tensor     inputReshaped              = NULL;
    vx_tensor     outputReshaped             = NULL;
    vx_int32      inputZP                    = TENSOR_TF_ZEROPOINT(input);
    vx_int32      outputZP                   = TENSOR_TF_ZEROPOINT(output);
    vx_int32      sizes[]                    = {width * height, depth, 1, batch};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    inputReshaped = vxoTensor_ReshapeTensor(input, sizes, dims);
    outputReshaped = vxoTensor_ReshapeTensor(output, sizes, dims);

    parameters[0] = (vx_reference)inputReshaped;
    parameters[1] = (vx_reference)sumTmp;
    parameters[2] = (vx_reference)outputReshaped;

    if (srcFormat == VX_TYPE_INT8 || srcFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
            inputScale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        else
            inputScale = (vx_float32) (1 << -srcFixPointPos);
    }
    else if (srcFormat == VX_TYPE_FLOAT16)
    {
        inputScale     = 1.0f;
        inputZP        = 0;
    }

    if (dstFormat == VX_TYPE_INT8 || dstFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
            outputScale = (vx_float32) (1 << dstFixPointPos);
        else
            outputScale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
    }
    else if (dstFormat == VX_TYPE_FLOAT16)
    {
        outputScale    = 1.0f;
        outputZP       = 0;
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, L2NormSumScale, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/L2NormSumScale.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcL2NormScale", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (srcFormat == VX_TYPE_FLOAT16 && dstFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniUnpackFp16toFp32Lo_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackFp16toFp32Hi_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MulScale", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackFp16toFp32Lo_4x4", 1, uniUnpackFp16toFp32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackFp16toFp32Hi_4x4", 1, uniUnpackFp16toFp32Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_INT8 && dstFormat == VX_TYPE_INT8)
    {
        vx_float32 IntergerScale = inputScale * outputScale;

        vx_uint32 uniUnpackedIntegerLo_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackedIntegerHi_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MulScale_int8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerLo_4x4", 1, uniUnpackedIntegerLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerHi_4x4", 1, uniUnpackedIntegerHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "IntergerScale", 1, &IntergerScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_INT16 && dstFormat == VX_TYPE_INT16)
    {
        vx_float32 IntergerScale = inputScale * outputScale;

        vx_uint32 uniUnpackedIntegerLo_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackedIntegerHi_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MulScale_int16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerLo_4x4", 1, uniUnpackedIntegerLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerHi_4x4", 1, uniUnpackedIntegerHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "IntergerScale", 1, &IntergerScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_UINT8 && dstFormat == VX_TYPE_UINT8)
    {
        vx_float32 IntergerScale = inputScale / outputScale;
        vx_float32 output_ZP      = (vx_float32)outputZP;

        vx_uint32 uniUnpackedIntegerLo_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackedIntegerHi_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_MulScale_uint8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerLo_4x4", 1, uniUnpackedIntegerLo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackedIntegerHi_4x4", 1, uniUnpackedIntegerHi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "IntergerScale", 1, &IntergerScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_ZP);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat != dstFormat)
    {
        vx_float32 IntergerScale = inputScale;
        vx_float32 output_ZP      = (vx_float32)outputZP;
        char kernelName[1024];
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part0_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part1_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        if (dstFormat == VX_TYPE_UINT8)
            IntergerScale = IntergerScale / outputScale;
        else
            IntergerScale = IntergerScale * outputScale;

        switch (srcFormat)
        {
        case VX_TYPE_FLOAT16:
            sprintf(kernelName, "_Fp16");
            break;
        case VX_TYPE_INT8:
            sprintf(kernelName, "_Int8");
            break;
        case VX_TYPE_UINT8:
            sprintf(kernelName, "_UInt8");
            break;
        case VX_TYPE_INT16:
            sprintf(kernelName, "_Int16");
            break;
        default:
            break;
        }

        switch (dstFormat)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "toFp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "toInt8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "toUInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "toInt16" );
            break;
        default:
            break;
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "IntergerScale", 1, &IntergerScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "L2NorS_depth", 1, &depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part0_4x4", 1, uniDataSubZPtoFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part1_4x4", 1, uniDataSubZPtoFp32Part1_4x4);
        if (dstFormat == VX_TYPE_FLOAT16)
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtractHalf8_2x8);
        else
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0] = 8;
    execution_parameters.globalWorkScale[1] = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = 1;


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (inputReshaped)  vxoTensor_ReleaseTensor(&inputReshaped);
    if (outputReshaped)  vxoTensor_ReleaseTensor(&outputReshaped);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (inputReshaped)  vxoTensor_ReleaseTensor(&inputReshaped);
    if (outputReshaped)  vxoTensor_ReleaseTensor(&outputReshaped);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;

}

vxnne_shader_executable vxnneLSTMUnitShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               w_h,
    vx_tensor               h_state_in,
    vx_tensor               c_state,
    vx_tensor               cell_clip,
    vx_bool                 enable_cifg,
    vx_bool                 enable_peephole,
    vx_bool                 enable_projection,
    vx_tensor               cell2input_weight,
    vx_tensor               cell2forget_weight,
    vx_tensor               cell2output_weight,
    vx_tensor               c_state_out,
    vx_tensor               h_state_out,
    vx_tensor               activation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[12]         = {(vx_reference)input, (vx_reference)w_h, (vx_reference)h_state_in, (vx_reference)c_state, (vx_reference)c_state_out, (vx_reference)h_state_out, (vx_reference)output, (vx_reference)activation, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL};

    vx_uint32    dims                   = TENSOR_DIM_NUM(input);
    vx_uint32    output_dims            = TENSOR_DIM_NUM(output);
    vx_uint32    batch                  = (output_dims > 1) ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32    output_num             = TENSOR_VIEW_SIZE_INDEX(h_state_in, 0);
    vx_uint32    num_units              = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_enum      inputFormat            = TENSOR_DATA_TYPE(input);
    vx_tensor    input_rs               = NULL;
    vx_tensor    cell2input_weight_rs   = NULL;
    vx_tensor    cell2forget_weight_rs  = NULL;
    vx_tensor    cell2output_weight_rs  = NULL;
    vx_tensor    activation_rs          = NULL;
    vx_int32     sizes[]                = {1,1,1,1};
    vx_uint32    inputCount             = 0;
    vx_uint32    paramt_num             = 9;
    vx_tensor    cell_clip_rs           = NULL;
    vx_uint32    disable_projection     = enable_projection ? 0 : 1;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    cell_clip_rs      = vxoTensor_ReshapeTensor(cell_clip, sizes, 2);
    parameters[8]     = (vx_reference)cell_clip_rs;

    vxoTensor_GetTensorElementCount(input, &inputCount);
    sizes[0]        = inputCount / batch;
    sizes[1]        = batch;
    dims            = 2;
    input_rs        = vxoTensor_ReshapeTensor(input, sizes, dims);

    parameters[0]   = (vx_reference)input_rs;

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.S16 = 0;

    if (TENSOR_DIM_NUM(activation) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(activation, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        activation_rs = vxoTensor_ReshapeTensor(activation, sizes, dims);
        parameters[7] = (vx_reference)activation_rs;
    }

    if (enable_peephole)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(cell2forget_weight, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};

        dims = 2;
        cell2forget_weight_rs       = vxoTensor_ReshapeTensor(cell2forget_weight, sizes, dims);
        cell2output_weight_rs       = vxoTensor_ReshapeTensor(cell2output_weight, sizes, dims);
        if (!enable_cifg)
        {
            cell2input_weight_rs    = vxoTensor_ReshapeTensor(cell2input_weight, sizes, dims);

            parameters[9]           = (vx_reference)cell2input_weight_rs;
            parameters[10]           = (vx_reference)cell2forget_weight_rs;
            parameters[11]          = (vx_reference)cell2output_weight_rs;

            paramt_num = 12;
        }
        else
        {
            parameters[9]           = (vx_reference)cell2forget_weight_rs;
            parameters[10]           = (vx_reference)cell2output_weight_rs;

            paramt_num              = 11;
        }

    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnit, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnit.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnit", program, paramt_num, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && !enable_peephole)
    {
        vx_float32     logE               = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniSumFp16MulFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toClip_4x4[16] = {
            0x00000101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x0000bc00, 0x00000000, 0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_int32 offsetX[2] = {8, 0};

        if (enable_cifg)
        {
            offsetX[1] =0 - (vx_int32)num_units * 2;

            if (TENSOR_DATA_LIFETIME(activation) == VX_TENSOR_LIFE_TIME_STATIC)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_non_peephole_Fp16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_non_peephole_Fp16_dyn", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }
        else
        {
            offsetX[1] =0 - (vx_int32)num_units * 3;

            if (TENSOR_DATA_LIFETIME(activation) == VX_TENSOR_LIFE_TIME_STATIC)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_non_peephole_non_CIFG_Fp16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_non_peephole_non_CIFG_Fp16_dyn", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumFp16MulFp16_16x1", 1, uniSumFp16MulFp16_16x1);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toClip_4x4", 1, uniFp16toClip_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offsetX", 1, offsetX);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_num", 1, &output_num);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "disable_projection", 1, &disable_projection);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && enable_peephole)
    {
        vx_float32     logE               = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniSumFp16MulFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16MulFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x01010101, // BSelt
            0x00010000, 0x00030002, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toClip_4x4[16] = {
            0x00000101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x0000bc00, 0x00000000, 0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_int32 offsetX[2] = {8, 0};

        if (enable_cifg)
        {
            offsetX[1] =0 - (vx_int32)num_units * 2;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_peephole_Fp16_dyn", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            offsetX[1] =0 - (vx_int32)num_units * 3;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_non_CIFG_peephole_Fp16_dyn", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumFp16MulFp16_16x1", 1, uniSumFp16MulFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulFp16toFp32_4x4", 1, uniFp16MulFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toClip_4x4", 1, uniFp16toClip_4x4);
        status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offsetX", 1, offsetX);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_num", 1, &output_num);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "disable_projection", 1, &disable_projection);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.workDim             = 2;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramt_num);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (activation_rs) vxoTensor_ReleaseTensor(&activation_rs);
    if (cell2input_weight_rs) vxoTensor_ReleaseTensor(&cell2input_weight_rs);
    if (cell2forget_weight_rs) vxoTensor_ReleaseTensor(&cell2forget_weight_rs);
    if (cell2output_weight_rs) vxoTensor_ReleaseTensor(&cell2output_weight_rs);
    if (cell_clip_rs) vxoTensor_ReleaseTensor(&cell_clip_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (activation_rs) vxoTensor_ReleaseTensor(&activation_rs);
    if (cell2input_weight_rs) vxoTensor_ReleaseTensor(&cell2input_weight_rs);
    if (cell2forget_weight_rs) vxoTensor_ReleaseTensor(&cell2forget_weight_rs);
    if (cell2output_weight_rs) vxoTensor_ReleaseTensor(&cell2output_weight_rs);
    if (cell_clip_rs) vxoTensor_ReleaseTensor(&cell_clip_rs);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneLSTMLayerShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_float32              forget_bias,
    vx_tensor               w_h,
    vx_int32                time_step,
    vx_tensor               output,
    vx_uint32               maxComputeUnits)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[5]     = {(vx_reference)input, (vx_reference)w_h, (vx_reference)output};
    vx_uint32    dims              = TENSOR_DIM_NUM(input);
    vx_uint32    input_width       = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    batch             = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    output_num        = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_int32     sizes[]           = {1,1,1,1};
    vx_tensor    input_rs          = NULL;
    vx_tensor    output_rs         = NULL;
    vx_int8       input_fl         = TENSOR_POS(input);
    vx_float32   hidden_fcScale    = 1.0f;
    vx_float32   outputScale       = 1.0f;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (TENSOR_QUANT_TYPE(w_h) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8   srcFixedPointPos    = TENSOR_POS(output);
        vx_int8   weiFixedPointPos    = TENSOR_POS(w_h);
        vx_int32  multiplicator       = 0;

        multiplicator                 = multiplicator - srcFixedPointPos;
        multiplicator                 = multiplicator - weiFixedPointPos;

        if (multiplicator < 0)
            hidden_fcScale = 1.0f / (vx_float32) (1 << -multiplicator);
        else
            hidden_fcScale = (vx_float32) (1 << multiplicator);
    }

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8 fixPointPos = TENSOR_POS(output);

        if (fixPointPos >= 0)
            outputScale = (vx_float32) (1 << fixPointPos);
        else if (fixPointPos < 0)
            outputScale = 1.0f / (vx_float32) (1 << -fixPointPos);
    }

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.S16 = 0;

    sizes[0]        = input_width;
    sizes[1]        = time_step;
    dims            = 2;
    input_rs        = vxoTensor_ReshapeTensor(input, sizes, dims);

    sizes[0]        = output_num;
    sizes[1]        = time_step;
    dims            = 2;
    output_rs        = vxoTensor_ReshapeTensor(output, sizes, dims);

    parameters[0]    = (vx_reference)input_rs;
    parameters[2]    = (vx_reference)output_rs;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMLayer, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMLayer.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMLayer", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16 && batch == 1)
    {
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniSumFp16MulFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 uniUnpackFp16toFp32Lo_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniUnpackFp16toFp32Hi_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_int32 offsetX[2] = {8, 0};

        offsetX[1] = 0 - (vx_int32)output_num * 3;

        if (maxComputeUnits == 1)
        {
            if (output_num <= 128)
            {
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (output_num <= 1024)
            {
                execution_parameters.globalWorkScale[0]  = 64;
                execution_parameters.globalWorkScale[1]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Fp16toFp16_1024", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }
        else
        {
            if (output_num <= 128)
            {
                execution_parameters.globalWorkScale[0]  = 4;
                execution_parameters.globalWorkScale[1]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Fp16toFp16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (output_num <= 1024)
            {
                execution_parameters.globalWorkScale[0]  = 32;
                execution_parameters.globalWorkScale[1]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Fp16toFp16_1024", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumFp16MulFp16_16x1", 1, uniSumFp16MulFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackFp16toFp32Lo_4x4", 1, uniUnpackFp16toFp32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniUnpackFp16toFp32Hi_4x4", 1, uniUnpackFp16toFp32Hi_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offsetX", 1, offsetX);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_num", 1, &output_num);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "time_step", 1, &time_step);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (TENSOR_QUANT_TYPE(input ) == VX_QUANT_DYNAMIC_FIXED_POINT && batch == 1)
    {
        vx_float32     logE                 = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE              = 2 * logE;
        vx_uint32 uniExtractDft16_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDft16toFp32_input_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniMulAccInt16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniMulAccInt8_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_int32 offsetX[2] = {8, 0};

        uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

        offsetX[1] = 0 - (vx_int32)output_num * 3;

        if (inputFormat == VX_TYPE_INT8)
            offsetX[0] = 16;
        if (maxComputeUnits == 1)
        {
            if (output_num <= 128)
            {
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 1;

                if (inputFormat == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Int16toInt16", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (output_num <= 1024)
            {
                execution_parameters.globalWorkScale[0]  = 64;
                execution_parameters.globalWorkScale[1]  = 1;

                if (inputFormat == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Int16toInt16_1024", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16x1_Int8toInt8_1024", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }
        else
        {
            if (output_num <= 128)
            {
                execution_parameters.globalWorkScale[0]  = 4;
                execution_parameters.globalWorkScale[1]  = 1;

                if (inputFormat == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Int16toInt16", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Int8toInt8", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (output_num <= 1024)
            {
                execution_parameters.globalWorkScale[0]  = 32;
                execution_parameters.globalWorkScale[1]  = 1;

                if (inputFormat == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Int16toInt16_1024", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_32x1_Int8toInt8_1024", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractDft16_2x8", 1, uniExtractDft16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft16toFp32_input_4x4", 1, uniDft16toFp32_input_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAccInt16_16x1", 1, uniMulAccInt16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMulAccInt8_16x1", 1, uniMulAccInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offsetX", 1, offsetX);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "output_num", 1, &output_num);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "time_step", 1, &time_step);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "hidden_fcScale", 1, &hidden_fcScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (maxComputeUnits == 1)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.localWorkSize[0]    = 16;
        execution_parameters.localWorkSize[1]    = 1;
        execution_parameters.globalWorkSize[0]   = 16;
        execution_parameters.globalWorkSize[1]   = 1;
    }
    else
    {
        execution_parameters.workDim             = 2;
        execution_parameters.localWorkSize[0]    = 32;
        execution_parameters.localWorkSize[1]    = 1;
        execution_parameters.globalWorkSize[0]   = 32;
        execution_parameters.globalWorkSize[1]   = 1;
    }

    if (!shaderExecutable) goto OnError;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneTensorCopyShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]     = {(vx_reference)input, (vx_reference)output};
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_uint32    dimCount          = TENSOR_VIEW_DIM_NUM(input);
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = (dimCount > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32    depth             = (dimCount > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_uint32    batch             = (dimCount > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_uint32    input_dims        = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor    input_rs          = NULL;
    vx_tensor    output_rs         = NULL;
    vx_bool      useImage2DFlag    = vx_false_e;
    vx_int8      srcFixPointPos    = TENSOR_POS(input);
    vx_int8      dstFixPointPos    = TENSOR_POS(output);
    vx_float32   scaleOut          = 1.0f;
    vx_float32   scaleIn           = 1.0f;
    vx_int32     inputZP           = 0;
    vx_int32     outputZP          = 0;
    vx_int32     sizes[4]          = {1, 1, 1, batch};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if ((width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH && inputFormat != VX_TYPE_FLOAT32 && outputFormat != VX_TYPE_FLOAT32)
    {
        width  = width * height;
        height = depth;
        depth  = 1;

        useImage2DFlag = vx_true_e;
    }
    else if (depth == 1)
    {
        useImage2DFlag = vx_true_e;
    }

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn = TENSOR_TF_SCALE(input);
        inputZP = TENSOR_TF_ZEROPOINT(input);
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut = TENSOR_TF_SCALE(output);
        outputZP = TENSOR_TF_ZEROPOINT(output);
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    sizes[0]  = width;
    sizes[1]  = height;
    sizes[2]  = depth;
    input_rs  = vxoTensor_ReshapeTensor(input, sizes, input_dims);
    output_rs = vxoTensor_ReshapeTensor(output, sizes, input_dims);

    parameters[0] = (vx_reference)input_rs;
    parameters[1] = (vx_reference)output_rs;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorCopy, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorCopy.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "tensorCopy", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && srcFixPointPos == dstFixPointPos) ||
        (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && TENSOR_TF_SCALE(input) == TENSOR_TF_SCALE(output) && TENSOR_TF_ZEROPOINT(input) == TENSOR_TF_ZEROPOINT(output)))
    {
        if (useImage2DFlag)
        {
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits", borderMode);
            if (!shaderExecutable) goto OnError;
        }
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT32)
    {
        vx_uint32 uniConvertF16toF32Lo_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertF16toF32Hi_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF32_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toFp32", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertF16toF32Lo_4x4", 1, uniConvertF16toF32Lo_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertF16toF32Hi_4x4", 1, uniConvertF16toF32Hi_4x4);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT32 && outputFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniPackedEvenData_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F32toF16_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F32toF16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedEvenData_2x8", 1, uniPackedEvenData_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT32 && outputFormat == VX_TYPE_FLOAT32)
    {
        execution_parameters.globalWorkScale[0]  = 4;
        execution_parameters.globalWorkScale[1]  = 4;
        execution_parameters.globalWorkScale[2]  = 1;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp32toFp32", borderMode);
        if (!shaderExecutable) goto OnError;
    }
    else if (inputFormat != VX_TYPE_UINT8)
    {
        vx_float32     scaleInt16         = scaleIn * scaleOut;
        vx_float32     scaleInt8          = scaleIn * scaleOut;
        vx_uint32 UniScaletoInt16_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniScaletoInt8Lo_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniScaletoInt8Hi_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x0b0a0908, 0x0f0e0d0c, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (useImage2DFlag)
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16) || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16 && srcFixPointPos == dstFixPointPos))
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits_2D", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_2D", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
            {
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_2D", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
            if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16) || (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16 && srcFixPointPos == dstFixPointPos))
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
            {
                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniScaletoInt16_2x8", 1, UniScaletoInt16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniScaletoInt8Lo_2x8", 1, UniScaletoInt8Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniScaletoInt8Hi_2x8", 1, UniScaletoInt8Hi_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16", 1, &scaleInt16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt8", 1, &scaleInt8);
        if (status != VX_SUCCESS) goto OnError;
    }
    else
    {
        vx_float32 uint8Scale = scaleIn / scaleOut;
        vx_uint16  M0                   = 0;
        vx_int8    postShift            = 0;
        vx_uint32    multAndoutZP[2]    = {0};
        vx_uint32 uniU8MulAndPostShift_Lo_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x13121110, 0x17161514, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002600, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniU8MulAndPostShift_Hi_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x1b1a1918, 0x1f1e1d1c, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002600, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        getFP32M0AndN(uint8Scale, &M0, &postShift);
        multAndoutZP[0] = (vx_uint32)(M0);
        multAndoutZP[1] = (vx_uint32)((outputZP << postShift) - inputZP * M0);

        uniU8MulAndPostShift_Lo_2x8[7] |= (postShift & 0x1F);
        uniU8MulAndPostShift_Hi_2x8[7] |= (postShift & 0x1F);

        if (useImage2DFlag)
        {
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
            if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8_2D", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
            {
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8toFp16_2D", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }
        else
        {
            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
            execution_parameters.globalWorkScale[2]  = 1;
            if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_FLOAT16)
            {
                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 4;
                execution_parameters.globalWorkScale[2]  = 1;
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_UInt8toFp16", borderMode);
                if (!shaderExecutable) goto OnError;
            }
        }


        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_Lo_2x8", 1, uniU8MulAndPostShift_Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAndPostShift_Hi_2x8", 1, uniU8MulAndPostShift_Hi_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}


/********Generic ROIPool****************************************************/
vxnne_shader_executable vxnneROIPoolShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               input_rois,
    vx_uint32               pool_width,
    vx_uint32               pool_height,
    vx_float32              spatial_scale,
    vx_bool                 enable_relu,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[6]     = {(vx_reference)input, (vx_reference)input_rois, NULL, NULL, NULL, (vx_reference)output};
    vx_uint32    width             = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    height            = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    rois_depth        = TENSOR_VIEW_SIZE_INDEX(input_rois, 2);
    vx_uint32    rois_batch        = TENSOR_VIEW_SIZE_INDEX(input_rois, 3);
    vx_uint32    rois_dims         = TENSOR_DIM_NUM(input_rois) == 1 ? 2 : TENSOR_DIM_NUM(input_rois);
    vx_scalar    pool_width_s      = NULL;
    vx_scalar    pool_height_s     = NULL;
    vx_scalar    spatial_scale_s   = NULL;
    vx_uint32    output_width      = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    output_height     = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    output_depth      = TENSOR_VIEW_SIZE_INDEX(output, 2);
    vx_uint32    output_batch      = TENSOR_VIEW_SIZE_INDEX(output, 3);
    vx_uint32    dst_dims          = TENSOR_DIM_NUM(output) == 1 ? 2 : TENSOR_DIM_NUM(output);
    vx_int8      srcFixPointPos    = TENSOR_POS(input);
    vx_int8      dstFixPointPos    = TENSOR_POS(output);
    vx_tensor    input_rois_rs     = NULL;
    vx_tensor    output_rs         = NULL;
    vx_float32   scaleIn           = 1.0;
    vx_float32   scaleOut          = 1.0;
    vx_int32     inputZP           = 0;
    vx_int32     outputZP          = 0;
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_enum      roisFormat        = TENSOR_DATA_TYPE(input_rois);
    vx_enum      outputFormat      = TENSOR_DATA_TYPE(output);
    vx_int32     rois_sizes[4]     = {rois_depth, rois_batch, 1, 1};
    vx_int32     dst_sizes[4]      = {output_width * output_height, output_depth, output_batch, 1};
    vx_uint32    minVal            = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn    = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn    = (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn = TENSOR_TF_SCALE(input);
        inputZP = TENSOR_TF_ZEROPOINT(input);
    }

    if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut = TENSOR_TF_SCALE(output);
        outputZP = TENSOR_TF_ZEROPOINT(output);
    }

    borderMode->mode   = VX_BORDER_CONSTANT;
    input_rois_rs      = vxoTensor_ReshapeTensor(input_rois, rois_sizes, rois_dims);
    output_rs          = vxoTensor_ReshapeTensor(output, dst_sizes, dst_dims);
    pool_width_s       = vxCreateScalar(context, VX_TYPE_INT32, &pool_width);
    pool_height_s      = vxCreateScalar(context, VX_TYPE_INT32, &pool_height);
    spatial_scale_s    = vxCreateScalar(context, VX_TYPE_FLOAT32, &spatial_scale);
    parameters[1]      = (vx_reference)input_rois_rs;
    parameters[2]      = (vx_reference)pool_width_s;
    parameters[3]      = (vx_reference)pool_height_s;
    parameters[4]      = (vx_reference)spatial_scale_s;
    parameters[5]      = (vx_reference)output_rs;

    if (inputFormat == VX_TYPE_FLOAT16)
    {
        borderMode->constant_value.U16 = 0;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, ROIPool, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/ROIPool.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "roiPooling", program, 6, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enable_relu)
    {
        if (outputFormat == VX_TYPE_UINT8 && TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
        {
            minVal = TENSOR_TF_ZEROPOINT(output);
        }
        else
        {
            minVal = 0;
        }
    }
    else
    {
        if (inputFormat == VX_TYPE_FLOAT16)
        {
            minVal = 0xFC00;
        }
        else if (inputFormat == VX_TYPE_INT8)
        {
            minVal = 0x80;
        }
        else if (inputFormat == VX_TYPE_UINT8)
        {
            minVal = 0;
        }
        else if (inputFormat == VX_TYPE_INT16)
        {
            minVal = 0x8000;
        }
    }

    if ((inputFormat == VX_TYPE_FLOAT16 && roisFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16) ||
        (inputFormat == VX_TYPE_INT16 && roisFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_INT16))
    {
        vx_float32 q_PoolWH[2] = {1 / (vx_float32)pool_width, 1 / (vx_float32)pool_height};
        vx_int32   inputSize[2] = {width, height};
        vx_int32   offset = rois_depth == 5? 1 : 0;
        vx_float32 scaleInt16toInt16   = scaleIn * scaleOut;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        if (inputFormat == VX_TYPE_FLOAT16 && roisFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_int16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, inputSize);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "q_PoolWH", 1, q_PoolWH);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offset", 1, &offset);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scaleInt16toInt16", 1, &scaleInt16toInt16);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minVal", 1, &minVal);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && roisFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_UINT8)
    {
        vx_float32 q_PoolWH[2] = {1 / (vx_float32)pool_width, 1 / (vx_float32)pool_height};
        vx_int32   inputSize[2] = {width, height};
        vx_int32   offset = rois_depth == 5? 1 : 0;
        vx_float32 uint8Scale   = scaleIn / scaleOut;
        vx_float32 input_ZP     = (vx_float32)inputZP;
        vx_float32 output_ZP    = (vx_float32)outputZP;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_uint8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputSize", 1, inputSize);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "q_PoolWH", 1, q_PoolWH);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offset", 1, &offset);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minVal", 1, &minVal);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.workDim             = 2;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = (output_batch + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0];
    execution_parameters.globalWorkSize[1]   = gcmALIGN((output_depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 6);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rois_rs) vxoTensor_ReleaseTensor(&input_rois_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (pool_width_s) vxReleaseScalar(&pool_width_s);
    if (pool_height_s) vxReleaseScalar(&pool_height_s);
    if (spatial_scale_s) vxReleaseScalar(&spatial_scale_s);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rois_rs) vxoTensor_ReleaseTensor(&input_rois_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (pool_width_s) vxReleaseScalar(&pool_width_s);
    if (pool_height_s) vxReleaseScalar(&pool_height_s);
    if (spatial_scale_s) vxReleaseScalar(&spatial_scale_s);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetL2PoolingShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_scalar               poolType,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pad_left,
    vx_uint32               pad_top,
    vx_scalar               rounding,
    vx_int32                activation,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[3]      = {(vx_reference)input, VX_NULL, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_int32     input_ZP           = TENSOR_TF_ZEROPOINT(input);
    vx_uint32    batch              = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int32     output_ZP          = TENSOR_TF_ZEROPOINT(output);
    vx_uint32    dims               = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32    stride_v           = stride_s->value->u32;
    vx_uint32    kernel_size_x      = poolSizeX->value->u32;
    vx_uint32    kernel_size_y      = poolSizeY->value->u32;
    vx_scalar    in_heights         = NULL;
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_bool      globalPooling_flag = (vx_bool)(out_width == 1 && out_height == 1 && kernel_size_x == in_width && kernel_size_y == in_height);
    vx_float32   scaleIn            = 1.0f;
    vx_float32   scaleOut           = 1.0f;
    vx_uint32    height             = (out_height - 1) * stride_v + kernel_size_y - 2 * pad_top;
    vx_uint32    width              = (out_width - 1) * stride_v + kernel_size_x - 2 * pad_left;
    vx_uint32    globalWorkSize1    = 1;
    vx_bool      useImage2DFlag     = (vx_bool)(in_width * in_height < IMG_MAX_WIDTH);
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    globalPooling_flag = (vx_bool)(globalPooling_flag & useImage2DFlag);

    if (height != in_height)
    {
        if (out_height < height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }
    else
    {
        if (out_height < in_height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &in_height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }

    parameters[1] = (vx_reference)in_heights;

    if (inputFormat == VX_TYPE_INT8)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn *= (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn *= TENSOR_TF_SCALE(input);
    }


    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut *= TENSOR_TF_SCALE(output);
    }

    if (globalPooling_flag)
    {
        vx_int32 src_sizes[4] = {in_width * in_height, depth, 1, batch};
        vx_int32 dst_sizes[4] = {1, depth, 1, batch};
        borderMode->mode = VX_BORDER_CONSTANT;
        input_rs         = vxoTensor_ReshapeTensor(input, src_sizes, dims);
        output_rs        = vxoTensor_ReshapeTensor(output, dst_sizes, dims);

        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_UINT8)
        {
            borderMode->constant_value.U8 = (vx_uint8)input_ZP;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }

        parameters[0] = (vx_reference)input_rs;
        parameters[2] = (vx_reference)output_rs;
    }
    else if (pad_left != 0 || pad_top != 0 || height != in_height || width != in_width)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        if (inputFormat == VX_TYPE_INT8)
        {
            borderMode->constant_value.U8 = 0;
        }
        else if (inputFormat == VX_TYPE_UINT8)
        {
            borderMode->constant_value.U8 = (vx_uint8)input_ZP;
        }
        else if (inputFormat == VX_TYPE_FLOAT16)
        {
            borderMode->constant_value.S16 = 0;
        }
    }
    else
    {
        borderMode->mode = VX_BORDER_REPLICATE;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, L2Pooling, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/L2Pooling.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcL2Pooling", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (globalPooling_flag && inputFormat == VX_TYPE_UINT8)
    {
        vx_int32     minData                = 0;
        vx_int32     maxData                = 0;
        vx_int32     enable_uint8_format    = outputFormat == VX_TYPE_UINT8 ? 1 : 0;
        vx_uint32    input_2ZP              = input_ZP * 2;
        vx_float32   uint8Scale             = scaleIn * scaleIn/ (float)(kernel_size_x * kernel_size_y * scaleOut);
        vx_float32   uint8ZP_out            = (vx_float32)output_ZP;
        vx_int32     pool_size              = gcmALIGN_SAFE(kernel_size_x * kernel_size_y, 32);
        vx_float32   NInputZPSquare         = (vx_float32)input_ZP * input_ZP * pool_size;
        vx_uint32 uniAcc8BinSquareUInt8_16x1[16] = {
            0x99999999, // TCfg
            0x00000000, // ASelt
            0x33221100, 0x77665544, // ABin
            0x44444444, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (outputFormat == VX_TYPE_UINT8)
        {
            vx_uint8     minVal    = 0;
            vx_uint8     maxVal    = 0;
            calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }
        else
        {
            vx_int16     minVal                = 0;
            vx_int16     maxVal                = 0;
            calculateActivationRangeFloat16(activation, &minVal, &maxVal);
            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_global_uint8", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinSquareUInt8_16x1", 1, uniAcc8BinSquareUInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_2ZP", 1, &input_2ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &uint8ZP_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "NInputZPSquare", 1, &NInputZPSquare);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pool_size", 1, &pool_size);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (globalPooling_flag && inputFormat == VX_TYPE_FLOAT16)
    {
        vx_int32     minData                = 0;
        vx_int32     maxData                = 0;
        vx_int32     enable_uint8_format    = outputFormat == VX_TYPE_UINT8 ? 1 : 0;
        vx_float32   uint8ZP_out            = (vx_float32)output_ZP;
        vx_int32     pool_size              = gcmALIGN_SAFE(kernel_size_x * kernel_size_y, 32);
        vx_float32   genericL2Scale         = (vx_float32)1.0 / (vx_float32)(kernel_size_x * kernel_size_y * scaleOut);
        vx_uint32 uniAcc8BinSquareFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00000000, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (outputFormat == VX_TYPE_UINT8)
        {
            vx_uint8     minVal    = 0;
            vx_uint8     maxVal    = 0;
            calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }
        else
        {
            vx_int16     minVal                = 0;
            vx_int16     maxVal                = 0;
            calculateActivationRangeFloat16(activation, &minVal, &maxVal);
            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_global_fp16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinSquareFp16_16x1", 1, uniAcc8BinSquareFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "genericL2Scale", 1, &genericL2Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &uint8ZP_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "pool_size", 1, &pool_size);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_UINT8))
    {
        vx_int32     minData              = 0;
        vx_int32     maxData              = 0;
        vx_float32   uint8Scale           = scaleIn * scaleIn/ (float)(kernel_size_x * kernel_size_y * scaleOut);
        vx_float32   output_zeroPoint     = (vx_float32)output_ZP;
        vx_int32     kernelsize[2]        = {kernel_size_x, kernel_size_y};
        vx_int32     padding[2]           = {pad_left, pad_top};
        vx_int32     stride[2]            = {stride_v, stride_v};
        vx_int32     x_len_8x             = kernel_size_x / 8 * 8;
        vx_int32     x_len_remain         = kernel_size_x - x_len_8x;
        vx_uint32    input_2ZP            = input_ZP * 2;
        vx_float32   NInputZPSquare       = (vx_float32)input_ZP * input_ZP * kernel_size_x * kernel_size_y;
        vx_int32     enable_uint8_format  = outputFormat == VX_TYPE_UINT8 ? 1 : 0;

        vx_uint32 uniAcc8BinSquareUInt8_16x1[16] = {
            0x99999999, // TCfg
            0x00000000, // ASelt
            0x33221100, 0x77665544, // ABin
            0x44444444, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccNBinSquareUInt8_16x1[16] = {
            0x99999999, // TCfg
            0x00000000, // ASelt
            0x33221100, 0x77665544, // ABin
            0x44444444, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfig_uint8[8] = {0x00000000, 0x00000009, 0x00000099 ,0x00000999, 0x00009999, 0x00099999, 0x00999999, 0x09999999};
        uniAccNBinSquareUInt8_16x1[0] = uniConfig_uint8[x_len_remain];

        if (outputFormat == VX_TYPE_UINT8)
        {
            vx_uint8     minVal    = 0;
            vx_uint8     maxVal    = 0;
            calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }
        else
        {
            vx_int16     minVal                = 0;
            vx_int16     maxVal                = 0;
            calculateActivationRangeFloat16(activation, &minVal, &maxVal);
            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_uint8", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinSquareUInt8_16x1", 1, uniAcc8BinSquareUInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinSquareUInt8_16x1", 1, uniAccNBinSquareUInt8_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_2ZP", 1, &input_2ZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "NInputZPSquare", 1, &NInputZPSquare);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_UINT8))
    {
        vx_int32     minData              = 0;
        vx_int32     maxData              = 0;
        vx_float32   genericL2Scale       = 1.0f / (float)(kernel_size_x * kernel_size_y * scaleOut);
        vx_float32   output_zeroPoint     = (vx_float32)output_ZP;
        vx_int32     kernelsize[2]        = {kernel_size_x, kernel_size_y};
        vx_int32     padding[2]           = {pad_left, pad_top};
        vx_int32     stride[2]            = {stride_v, stride_v};
        vx_int32     x_len_8x             = kernel_size_x / 8 * 8;
        vx_int32     x_len_remain         = kernel_size_x - x_len_8x;
        vx_int32     enable_uint8_format  = outputFormat == VX_TYPE_UINT8 ? 1 : 0;

        vx_uint32 uniAcc8BinSquareFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00000000, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniAccNBinSquareFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00000000, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfig[8] = {0x00000000, 0x00000001, 0x00000005 ,0x00000015, 0x00000055, 0x00000155, 0x00000555, 0x00001555};
        uniAccNBinSquareFp16_16x1[0] = uniConfig[x_len_remain];

        if (outputFormat == VX_TYPE_UINT8)
        {
            vx_uint8     minVal    = 0;
            vx_uint8     maxVal    = 0;
            calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }
        else
        {
            vx_int16     minVal                = 0;
            vx_int16     maxVal                = 0;
            calculateActivationRangeFloat16(activation, &minVal, &maxVal);
            minData = (vx_int32)minVal;
            maxData = (vx_int32)maxVal;
        }

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_fp16", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8BinSquareFp16_16x1", 1, uniAcc8BinSquareFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNBinSquareFp16_16x1", 1, uniAccNBinSquareFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genericL2Scale", 1, &genericL2Scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (globalPooling_flag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 0;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }
    else
    {
        execution_parameters.workDim = 3;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = globalWorkSize1 == 1 ? 1 : (globalWorkSize1  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetTensorScaleShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_enum                 type,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[2]      = {(vx_reference)input, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_int32     input_ZP           = 0;
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int32     output_ZP          = 0;
    vx_float32   scaleIn            = 1.0f;
    vx_float32   scaleOut           = 1.0f;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_float32   scale_factor[2]    = {in_width / (vx_float32)out_width, in_height / (vx_float32)out_height};
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_UINT8 && TENSOR_QUANT_TYPE(input) == VX_QUANT_AFFINE_SCALE)
    {
        scaleIn *= TENSOR_TF_SCALE(input);
        input_ZP = TENSOR_TF_ZEROPOINT(input);
    }
    else if (TENSOR_QUANT_TYPE(input) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn *= (vx_float32)(1 << -srcFixPointPos);
        }
    }

    if (outputFormat == VX_TYPE_UINT8 && TENSOR_QUANT_TYPE(input) == VX_QUANT_AFFINE_SCALE)
    {
        scaleOut *= TENSOR_TF_SCALE(output);
        output_ZP = TENSOR_TF_ZEROPOINT(output);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    borderMode->mode = VX_BORDER_REPLICATE;


    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorScale, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorScale.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorScale", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    execution_parameters.globalWorkScale[0] = 4;
    execution_parameters.globalWorkScale[1] = 1;
    execution_parameters.globalWorkScale[2] = 1;

    if (TENSOR_QUANT_TYPE(input) == VX_QUANT_DYNAMIC_FIXED_POINT && type == VX_INTERPOLATION_BILINEAR)
    {
        vx_float32 dfpScale = scaleIn * scaleOut;
        vx_uint32 uniConvertDFP2FP32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniExtact8Bit_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && out_width > in_width)
        {
            vx_uint32 uniConvertI32toI16_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetMaskShift_2x8[16] = {
                0x99999999, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x55555555, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniConvertDFP2FP32_part1_4x4[16] = {
                0x09090909, // TCfg
                0x00000000, // ASelt
                0x00150004, 0x00370026, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000300, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_dfp8_upsample", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertI32toI16_2x8", 1, uniConvertI32toI16_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaskShift_2x8", 1, uniGetMaskShift_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDFP2FP32_part1_4x4", 1, uniConvertDFP2FP32_part1_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[2] = depth;
        }
        else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16 && out_width > in_width)
        {
            vx_uint32 uniConvertI32toI16_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetMaskShift_2x8[16] = {
                0x99999999, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x55555555, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniConvertDFP2FP32_part1_4x4[16] = {
                0x09090909, // TCfg
                0x00000000, // ASelt
                0x00150004, 0x00370026, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000300, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_dfp16_upsample", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertI32toI16_2x8", 1, uniConvertI32toI16_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaskShift_2x8", 1, uniGetMaskShift_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDFP2FP32_part1_4x4", 1, uniConvertDFP2FP32_part1_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[2] = depth;
        }
        else if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_dfp8", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_dfp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDFP2FP32_4x4", 1, uniConvertDFP2FP32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dfpScale", 1, &dfpScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_UINT8 || outputFormat == VX_TYPE_FLOAT16) && type == VX_INTERPOLATION_BILINEAR)
    {
        if (scale_factor[0] == 0.5f && scale_factor[1] == 0.5f )
        {
            vx_float32   uint8Scale         = scaleIn / scaleOut;
            vx_uint16    M0                 = 0;
            vx_int8      postShift          = 0;
            vx_uint32    multAndoutZP[2]    = {0};
            vx_uint32 uniU8SubZP2XtoFp16Hi_4x4[16] = {
                0x25092509, // TCfg
                0x10041004, // ASelt
                0x00320002, 0x00430003, // ABin
                0x2a0a2a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x00000000, 0x38003800, 0x00003c00, 0x3c003c00, 0x00000000, 0x38003800, 0x00003c00 // Constant
            };
            vx_uint32 uniU8SubZP2XtoFp16Lo_4x4[16] = {
                0x25092509, // TCfg
                0x10041004, // ASelt
                0x00100000, 0x00210001, // ABin
                0x2a0a2a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x00000000, 0x38003800, 0x00003c00, 0x3c003c00, 0x00000000, 0x38003800, 0x00003c00 // Constant
            };
            vx_uint32 uniF16AddFp16Shift1_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000101, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
            };
            vx_uint32 uniMultiplyAndPostShift_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            getFP32M0AndN(uint8Scale, &M0, &postShift);

            multAndoutZP[0] = (vx_uint32)M0;
            multAndoutZP[1] = (vx_uint32)(output_ZP << postShift);
            uniMultiplyAndPostShift_2x8[7] |= (postShift & 0x1F);

            if (outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8tofp16_2x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8_2x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            execution_parameters.globalWorkScale[0] = 8;
            execution_parameters.globalWorkScale[1] = 2;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP2XtoFp16Hi_4x4", 1, uniU8SubZP2XtoFp16Hi_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP2XtoFp16Lo_4x4", 1, uniU8SubZP2XtoFp16Lo_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16AddFp16Shift1_2x8", 1, uniF16AddFp16Shift1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x8", 1, uniMultiplyAndPostShift_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.25f && scale_factor[1] == 0.25f )
        {
            vx_float32   uint8Scale         = scaleIn / scaleOut;
            vx_uint16    M0                 = 0;
            vx_int8      postShift          = 0;
            vx_uint32    multAndoutZP[2]    = {0};
            vx_uint32 uniF16AddFp16Shift1_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000101, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
            };
            vx_uint32 uniMultiplyAndPostShift_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniF16Mul3AddFp16Mul1Shift2_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000102, // AccumType, ConstantType, and PostShift
                0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200 // Constant
            };
            vx_uint32 uniF16Mul1AddFp16Mul3Shift2_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000102, // AccumType, ConstantType, and PostShift
                0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00 // Constant
            };
            vx_uint32 uniU8SubZP4XtoFp16Lo_4x4[16] = {
                0x25252509, // TCfg
                0x10101004, // ASelt
                0x00100000, 0x00100010, // ABin
                0x2a2a2a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x00000000, 0x34003a00, 0x00003c00, 0x38003800, 0x00003c00, 0x3a003400, 0x00003c00 // Constant
            };
            vx_uint32 uniU8SubZP4XtoFp16Hi_4x4[16] = {
                0x25252509, // TCfg
                0x10101004, // ASelt
                0x00210001, 0x00210021, // ABin
                0x2a2a2a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x00000000, 0x34003a00, 0x00003c00, 0x38003800, 0x00003c00, 0x3a003400, 0x00003c00 // Constant
            };

            getFP32M0AndN(uint8Scale, &M0, &postShift);

            multAndoutZP[0] = (vx_uint32)M0;
            multAndoutZP[1] = (vx_uint32)(output_ZP << postShift);
            uniMultiplyAndPostShift_2x8[7] |= (postShift & 0x1F);

            if (outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8tofp16_4x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8_4x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            execution_parameters.globalWorkScale[0] = 8;
            execution_parameters.globalWorkScale[1] = 4;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP4XtoFp16Hi_4x4", 1, uniU8SubZP4XtoFp16Hi_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP4XtoFp16Lo_4x4", 1, uniU8SubZP4XtoFp16Lo_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16AddFp16Shift1_2x8", 1, uniF16AddFp16Shift1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16Mul3AddFp16Mul1Shift2_2x8", 1, uniF16Mul3AddFp16Mul1Shift2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16Mul1AddFp16Mul3Shift2_2x8", 1, uniF16Mul1AddFp16Mul3Shift2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x8", 1, uniMultiplyAndPostShift_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            vx_float32   uint8Scale             = scaleIn / scaleOut;
            vx_float32   uint8ZP_out            = (vx_float32)output_ZP;
            vx_uint32 uniExtact8Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniU8SubZPtoFp32_4x4[16] = {
                0x09090909, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
            };

            if (outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8tofp16", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &scaleIn);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                if (out_width > in_width)
                {
                    vx_uint32 uniConvertI32toI16_2x8[16] = {
                        0x33333333, // TCfg
                        0x11110000, // ASelt
                        0x03020100, 0x03020100, // ABin
                        0x00000000, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00002400, // AccumType, ConstantType, and PostShift
                        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                    };
                    vx_uint32 uniGetMaskShift_2x8[16] = {
                        0x99999999, // TCfg
                        0x00000000, // ASelt
                        0x03020100, 0x07060504, // ABin
                        0x55555555, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000400, // AccumType, ConstantType, and PostShift
                        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                    };
                    vx_uint32 uniU8SubZPtoFp32_part1_4x4[16] = {
                        0x09090909, // TCfg
                        0x00000000, // ASelt
                        0x00150004, 0x00370026, // ABin
                        0x0a0a0a0a, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000400, // AccumType, ConstantType, and PostShift
                        0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000, 0x00010001, 0x00000000 // Constant
                    };

                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_u8_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;

                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertI32toI16_2x8", 1, uniConvertI32toI16_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaskShift_2x8", 1, uniGetMaskShift_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZPtoFp32_part1_4x4", 1, uniU8SubZPtoFp32_part1_4x4);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
                    if (status != VX_SUCCESS) goto OnError;

                    execution_parameters.globalWorkScale[2] = depth;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_uint8", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &uint8ZP_out);
                if (status != VX_SUCCESS) goto OnError;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZPtoFp32_4x4", 1, uniU8SubZPtoFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
            if (status != VX_SUCCESS) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_ZP);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_UINT8 || outputFormat == VX_TYPE_FLOAT16) && type == VX_INTERPOLATION_BILINEAR)
    {
        if (scale_factor[0] == 0.5f && scale_factor[1] == 0.5f && outputFormat == VX_TYPE_FLOAT16 )
        {
            vx_uint32 uniHorz16BitsLo_2x_2x8[16] = {
                0x51515151, // TCfg
                0x00000000, // ASelt
                0x21011000, 0x43033202, // ABin
                0xa2a2a2a2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x38003800, 0x00003c00, 0x38003800, 0x00003c00, 0x38003800, 0x00003c00, 0x38003800 // Constant
            };
            vx_uint32 uniHorz16BitsHi_2x_2x8[16] = {
                0x01515151, // TCfg
                0x00000000, // ASelt
                0x65055404, 0x00077606, // ABin
                0x02a2a2a2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x38003800, 0x00003c00, 0x38003800, 0x00003c00, 0x38003800, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniVert16BitsPart0_2x_4x4[16] = {
                0x55055505, // TCfg
                0x50045004, // ASelt
                0x10100000, 0x21210011, // ABin
                0xaa0aaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x34003400, 0x34003400, 0x38003800, 0x00000000, 0x34003400, 0x34003400 // Constant
            };
            vx_uint32 uniVert16BitsPart1_2x_4x4[16] = {
                0x55055505, // TCfg
                0x50045004, // ASelt
                0x32320022, 0x43430033, // ABin
                0xaa0aaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x34003400, 0x34003400, 0x38003800, 0x00000000, 0x34003400, 0x34003400 // Constant
            };
            vx_uint32 uniVert16BitsPart2_2x_4x4[16] = {
                0x55055505, // TCfg
                0x50045004, // ASelt
                0x54540044, 0x65650055, // ABin
                0xaa0aaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x34003400, 0x34003400, 0x38003800, 0x00000000, 0x34003400, 0x34003400 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_2x_Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0] = 12;
            execution_parameters.globalWorkScale[1] = 2;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniHorz16BitsLo_2x_2x8", 1, uniHorz16BitsLo_2x_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniHorz16BitsHi_2x_2x8", 1, uniHorz16BitsHi_2x_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsPart0_2x_4x4", 1, uniVert16BitsPart0_2x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsPart1_2x_4x4", 1, uniVert16BitsPart1_2x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsPart2_2x_4x4", 1, uniVert16BitsPart2_2x_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.25f && scale_factor[1] == 0.25f && outputFormat == VX_TYPE_UINT8)
        {
            vx_float32   uint8Scale         = scaleIn / scaleOut;
            vx_uint16    M0                 = 0;
            vx_int8      postShift          = 0;
            vx_uint32    multAndoutZP[2]    = {0};
            vx_uint32 uniF16AddFp16Shift1_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000101, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
            };
            vx_uint32 uniMultiplyAndPostShift_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniF16Mul3AddFp16Mul1Shift2_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000102, // AccumType, ConstantType, and PostShift
                0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200, 0x3c004200 // Constant
            };
            vx_uint32 uniF16Mul1AddFp16Mul3Shift2_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x33221100, 0x77665544, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000102, // AccumType, ConstantType, and PostShift
                0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00, 0x42003c00 // Constant
            };
            vx_uint32 uniFp16_4xResizeBilinear_2x8[16] = {
                0x55515551, // TCfg
                0x00000000, // ASelt
                0x10101000, 0x21212101, // ABin
                0xaaa2aaa2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x34003a00, 0x38003800, 0x3a003400, 0x00003c00, 0x34003a00, 0x38003800, 0x3a003400 // Constant
            };

            getFP32M0AndN(uint8Scale, &M0, &postShift);

            multAndoutZP[0] = (vx_uint32)M0;
            multAndoutZP[1] = (vx_uint32)(output_ZP << postShift);
            uniMultiplyAndPostShift_2x8[7] |= (postShift & 0x1F);

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_fp16touint8_4x_upsample", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0] = 8;
            execution_parameters.globalWorkScale[1] = 4;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16_4xResizeBilinear_2x8", 1, uniFp16_4xResizeBilinear_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16AddFp16Shift1_2x8", 1, uniF16AddFp16Shift1_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16Mul3AddFp16Mul1Shift2_2x8", 1, uniF16Mul3AddFp16Mul1Shift2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16Mul1AddFp16Mul3Shift2_2x8", 1, uniF16Mul1AddFp16Mul3Shift2_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x8", 1, uniMultiplyAndPostShift_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.25f && scale_factor[1] == 0.25f && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniHorz16BitsPart0_4x_2x8[16] = {
                0x55515551, // TCfg
                0x00000000, // ASelt
                0x10101000, 0x21212101, // ABin
                0xaaa2aaa2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x34003a00, 0x38003800, 0x3a003400, 0x00003c00, 0x34003a00, 0x38003800, 0x3a003400 // Constant
            };
            vx_uint32 uniHorz16BitsPart1_4x_2x8[16] = {
                0x55515551, // TCfg
                0x00000000, // ASelt
                0x32323202, 0x43434303, // ABin
                0xaaa2aaa2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x34003a00, 0x38003800, 0x3a003400, 0x00003c00, 0x34003a00, 0x38003800, 0x3a003400 // Constant
            };
            vx_uint32 uniVert16BitsSec1Part0_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x34003a00, 0x00000000, 0x32003880, 0x2c003200, 0x36003600, 0x30003000, 0x38803200, 0x32002c00 // Constant
            };
            vx_uint32 uniVert16BitsSec1Part1_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x21210011, 0x21212121, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x34003a00, 0x00000000, 0x32003880, 0x2c003200, 0x36003600, 0x30003000, 0x38803200, 0x32002c00 // Constant
            };
            vx_uint32 uniVert16BitsSec1Part2_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x32320022, 0x32323232, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x34003a00, 0x00000000, 0x32003880, 0x2c003200, 0x36003600, 0x30003000, 0x38803200, 0x32002c00 // Constant
            };
            vx_uint32 uniVert16BitsSec1Part3_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x43430033, 0x43434343, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x34003a00, 0x00000000, 0x32003880, 0x2c003200, 0x36003600, 0x30003000, 0x38803200, 0x32002c00 // Constant
            };
            vx_uint32 uniVert16BitsSec2Part0_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x30003600, 0x30003600, 0x34003400, 0x34003400, 0x36003000, 0x36003000 // Constant
            };
            vx_uint32 uniVert16BitsSec2Part1_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x21210011, 0x21212121, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x30003600, 0x30003600, 0x34003400, 0x34003400, 0x36003000, 0x36003000 // Constant
            };
            vx_uint32 uniVert16BitsSec2Part2_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x32320022, 0x32323232, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x30003600, 0x30003600, 0x34003400, 0x34003400, 0x36003000, 0x36003000 // Constant
            };
            vx_uint32 uniVert16BitsSec2Part3_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x43430033, 0x43434343, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x38003800, 0x00000000, 0x30003600, 0x30003600, 0x34003400, 0x34003400, 0x36003000, 0x36003000 // Constant
            };
            vx_uint32 uniVert16BitsSec3Part0_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3a003400, 0x00000000, 0x2c003200, 0x32003880, 0x30003000, 0x36003600, 0x32002c00, 0x38803200 // Constant
            };
            vx_uint32 uniVert16BitsSec3Part1_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x21210011, 0x21212121, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3a003400, 0x00000000, 0x2c003200, 0x32003880, 0x30003000, 0x36003600, 0x32002c00, 0x38803200 // Constant
            };
            vx_uint32 uniVert16BitsSec3Part2_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x32320022, 0x32323232, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3a003400, 0x00000000, 0x2c003200, 0x32003880, 0x30003000, 0x36003600, 0x32002c00, 0x38803200 // Constant
            };
            vx_uint32 uniVert16BitsSec3Part3_4x_4x4[16] = {
                0x55555505, // TCfg
                0x50505004, // ASelt
                0x43430033, 0x43434343, // ABin
                0xaaaaaa0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3a003400, 0x00000000, 0x2c003200, 0x32003880, 0x30003000, 0x36003600, 0x32002c00, 0x38803200 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_4x_Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0] = 16;
            execution_parameters.globalWorkScale[1] = 4;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniHorz16BitsPart0_4x_2x8", 1, uniHorz16BitsPart0_4x_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniHorz16BitsPart1_4x_2x8", 1, uniHorz16BitsPart1_4x_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec1Part0_4x_4x4", 1, uniVert16BitsSec1Part0_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec1Part1_4x_4x4", 1, uniVert16BitsSec1Part1_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec1Part2_4x_4x4", 1, uniVert16BitsSec1Part2_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec1Part3_4x_4x4", 1, uniVert16BitsSec1Part3_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec2Part0_4x_4x4", 1, uniVert16BitsSec2Part0_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec2Part1_4x_4x4", 1, uniVert16BitsSec2Part1_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec2Part2_4x_4x4", 1, uniVert16BitsSec2Part2_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec2Part3_4x_4x4", 1, uniVert16BitsSec2Part3_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec3Part0_4x_4x4", 1, uniVert16BitsSec3Part0_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec3Part1_4x_4x4", 1, uniVert16BitsSec3Part1_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec3Part2_4x_4x4", 1, uniVert16BitsSec3Part2_4x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVert16BitsSec3Part3_4x_4x4", 1, uniVert16BitsSec3Part3_4x_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.125f && scale_factor[1] == 0.125f && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniHorzPart0_8x_2x8[16] = {
                0x55555551, // TCfg
                0x00000000, // ASelt
                0x10101000, 0x10101010, // ABin
                0xaaaaaaa2, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x30003b00, 0x34003a00, 0x36003900, 0x38003800, 0x39003600, 0x3a003400, 0x3b003000 // Constant
            };
            vx_uint32 uniVertSec1Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003b00, 0x00003000, 0x2f003a20, 0x24002f00, 0x33003940, 0x28002e00, 0x35403860, 0x2a002d00 // Constant
            };
            vx_uint32 uniVertSec1Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x37003700, 0x2c002c00, 0x38603540, 0x2d002a00, 0x39403300, 0x2e002800, 0x3a202f00, 0x2f002400 // Constant
            };
            vx_uint32 uniVertSec2Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003a00, 0x00003400, 0x2e003940, 0x28003300, 0x32003880, 0x2c003200, 0x34803780, 0x2e003100 // Constant
            };
            vx_uint32 uniVertSec2Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x36003600, 0x30003000, 0x37803480, 0x31002e00, 0x38803200, 0x32002c00, 0x39402e00, 0x33002800 // Constant
            };
            vx_uint32 uniVertSec3Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003900, 0x00003600, 0x2d003860, 0x2a003540, 0x31003780, 0x2e003480, 0x33803640, 0x30803380 // Constant
            };
            vx_uint32 uniVertSec3Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x35003500, 0x32003200, 0x36403380, 0x33803080, 0x37803100, 0x34802e00, 0x38602d00, 0x35402a00 // Constant
            };
            vx_uint32 uniVertSec4Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003800, 0x00003800, 0x2c003700, 0x2c003700, 0x30003600, 0x30003600, 0x32003500, 0x32003500 // Constant
            };
            vx_uint32 uniVertSec4Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x34003400, 0x34003400, 0x35003200, 0x35003200, 0x36003000, 0x36003000, 0x37002c00, 0x37002c00 // Constant
            };
            vx_uint32 uniVertSec5Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003600, 0x00003900, 0x2a003540, 0x2d003860, 0x2e003480, 0x31003780, 0x30803380, 0x33803640 // Constant
            };
            vx_uint32 uniVertSec5Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x32003200, 0x35003500, 0x33803080, 0x36403380, 0x34802e00, 0x37803100, 0x35402a00, 0x38602d00 // Constant
            };
            vx_uint32 uniVertSec6Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003400, 0x00003a00, 0x28003300, 0x2e003940, 0x2c003200, 0x32003880, 0x2e003100, 0x34803780 // Constant
            };
            vx_uint32 uniVertSec6Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x30003000, 0x36003600, 0x31002e00, 0x37803480, 0x32002c00, 0x38803200, 0x33002800, 0x39402e00 // Constant
            };
            vx_uint32 uniVertSec7Part0_8x_4x4[16] = {
                0x55555511, // TCfg
                0x50505010, // ASelt
                0x10100000, 0x10101010, // ABin
                0xaaaaaa22, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003000, 0x00003b00, 0x24002f00, 0x2f003a20, 0x28002e00, 0x33003940, 0x2a002d00, 0x35403860 // Constant
            };
            vx_uint32 uniVertSec7Part1_8x_4x4[16] = {
                0x55555555, // TCfg
                0x50505050, // ASelt
                0x10101010, 0x10101010, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x2c002c00, 0x37003700, 0x2d002a00, 0x38603540, 0x2e002800, 0x39403300, 0x2f002400, 0x3a202f00 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_8x_Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0] = 8;
            execution_parameters.globalWorkScale[1] = 8;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniHorzPart0_8x_2x8", 1, uniHorzPart0_8x_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec1Part0_8x_4x4", 1, uniVertSec1Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec1Part1_8x_4x4", 1, uniVertSec1Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec2Part0_8x_4x4", 1, uniVertSec2Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec2Part1_8x_4x4", 1, uniVertSec2Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec3Part0_8x_4x4", 1, uniVertSec3Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec3Part1_8x_4x4", 1, uniVertSec3Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec4Part0_8x_4x4", 1, uniVertSec4Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec4Part1_8x_4x4", 1, uniVertSec4Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec5Part0_8x_4x4", 1, uniVertSec5Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec5Part1_8x_4x4", 1, uniVertSec5Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec6Part0_8x_4x4", 1, uniVertSec6Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec6Part1_8x_4x4", 1, uniVertSec6Part1_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec7Part0_8x_4x4", 1, uniVertSec7Part0_8x_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniVertSec7Part1_8x_4x4", 1, uniVertSec7Part1_8x_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.0625f && scale_factor[1] == 0.0625f && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniTop2andBottom2toFp32_4x4[16] = {
                0x01010101, // TCfg
                0x01010000, // ASelt
                0x00010000, 0x00010000, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_16x_Fp16toFp16", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0] = 16;
            execution_parameters.globalWorkScale[1] = 16;
            execution_parameters.globalWorkScale[2] = 1;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniTop2andBottom2toFp32_4x4", 1, uniTop2andBottom2toFp32_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            vx_float32   uint8Scale             = 1.0f / scaleOut;
            vx_float32   uint8ZP_out            = (vx_float32)output_ZP;
            vx_uint32 uniExtact8Bit_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniFp16toFp32_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniRightSubLeft_4x4[16] = {
                0x09090909, // TCfg
                0x04040404, // ASelt
                0x00110000, 0x00330022, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
            };
            vx_uint32 uniExtactHalf8_2x8[16] = {
                0x11111111, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
            };

            if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16 && out_width > in_width)
            {
                vx_uint32 uniConvertI32toI16_2x8[16] = {
                    0x33333333, // TCfg
                    0x11110000, // ASelt
                    0x03020100, 0x03020100, // ABin
                    0x00000000, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniGetMaskShift_2x8[16] = {
                    0x99999999, // TCfg
                    0x00000000, // ASelt
                    0x03020100, 0x07060504, // ABin
                    0x55555555, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00000400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniFp16toFp32_part1_4x4[16] = {
                    0x09090909, // TCfg
                    0x00000000, // ASelt
                    0x00150004, 0x00370026, // ABin
                    0x0a0a0a0a, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00000100, // AccumType, ConstantType, and PostShift
                    0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
                };

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_fp16_upsample", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertI32toI16_2x8", 1, uniConvertI32toI16_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetMaskShift_2x8", 1, uniGetMaskShift_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_part1_4x4", 1, uniFp16toFp32_part1_4x4);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtactHalf8_2x8", 1, uniExtactHalf8_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "depth", 1, &depth);
                if (status != VX_SUCCESS) goto OnError;

                execution_parameters.globalWorkScale[2] = depth;
            }
            else if (outputFormat == VX_TYPE_FLOAT16)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_fp16", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtactHalf8_2x8", 1, uniExtactHalf8_2x8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Bilinear_fp16tou8", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bit_2x8", 1, uniExtact8Bit_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8Scale", 1, &uint8Scale);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &uint8ZP_out);
                if (status != VX_SUCCESS) goto OnError;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniRightSubLeft_4x4", 1, uniRightSubLeft_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    if (type == VX_INTERPOLATION_BILINEAR)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth / execution_parameters.globalWorkScale[2];
    }
    else
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((in_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (in_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetResizeNearestNeighborShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_enum                 type,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    char *programSources = NULL;

    vx_reference parameters[2]      = {(vx_reference)input, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_width           = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_uint32    batch              = TENSOR_VIEW_SIZE_INDEX(input, 3);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32    dims               = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_float32   scaleIn            = 1.0f;
    vx_float32   scaleOut           = 1.0f;
    vx_int32     input_ZP           = 0;
    vx_int32     output_ZP          = 0;
    vx_int8      srcFixPointPos     = 0;
    vx_int8      dstFixPointPos     = 0;
    vx_float32   scale_factor[2]    = {in_width / (vx_float32)out_width, in_height / (vx_float32)out_height};
    vx_bool      enable_config_out  = vx_false_e;
    vx_bool      useImage2DFlag     = (vx_bool)((in_width * in_height < IMG_MAX_WIDTH) && (out_width * out_height < IMG_MAX_WIDTH));

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn *= TENSOR_TF_SCALE(input);
        input_ZP = TENSOR_TF_ZEROPOINT(input);
    }
    else if (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16)
    {
        srcFixPointPos = TENSOR_POS(input);
    }

    if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut *= TENSOR_TF_SCALE(output);
        output_ZP = TENSOR_TF_ZEROPOINT(output);
    }
    else if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
    {
        dstFixPointPos = TENSOR_POS(output);
    }

    borderMode->mode = VX_BORDER_REPLICATE;

    if (type == VX_INTERPOLATION_NEAREST_NEIGHBOR && useImage2DFlag && scale_factor[0] == 2.0f && scale_factor[1] == 2.0f)
    {
        vx_int32        sizes[4]                   = {1, 1, 1, 1};

        sizes[0] = in_width;
        sizes[1] = depth* in_height;
        sizes[2] = 1;
        sizes[3] = batch;

        input_rs  = vxoTensor_ReshapeTensor(input, sizes, dims);

        sizes[0] = out_width;
        sizes[1] = depth * out_height;
        sizes[2] = 1;
        sizes[3] = batch;
        output_rs = vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)input_rs;
        parameters[1] = (vx_reference)output_rs;

        useImage2DFlag = vx_true_e;
    }
    else
        useImage2DFlag = vx_false_e;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, ResizeNearestNeighbor, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/ResizeNearestNeighbor.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources != NULL)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorScale", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (type == VX_INTERPOLATION_NEAREST_NEIGHBOR)
    {
        vx_float32   uint8Scale         = scaleIn / scaleOut;
        vx_uint16    M0                 = 0;
        vx_int8      postShift          = 0;
        vx_uint32    multAndoutZP[2]    = {0};
        vx_uint32 uniMultiplyAndPostShiftLo_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x11111010, 0x13131212, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniMultiplyAndPostShiftHi_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x15151414, 0x17171616, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniMultiplyAndPostShift_2x8[16] = {
            0xdddddddd, // TCfg
            0x44444444, // ASelt
            0x13121110, 0x17161514, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (outputFormat == VX_TYPE_UINT8)
        {
            getFP32M0AndN(uint8Scale, &M0, &postShift);
        }
        else if (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_INT16)
        {
            M0          = 1;
            postShift   = 0;
            if (dstFixPointPos > 0)
                M0 = 1 << dstFixPointPos;
            else
                postShift = dstFixPointPos;
        }

        multAndoutZP[0] = (vx_uint32)M0;
        multAndoutZP[1] = (vx_uint32)(output_ZP << postShift);
        uniMultiplyAndPostShiftLo_2x8[7] |= (postShift & 0x1F);
        uniMultiplyAndPostShiftHi_2x8[7] |= (postShift & 0x1F);
        uniMultiplyAndPostShift_2x8[7]   |= (postShift & 0x1F);

        if (scale_factor[0] == 2.0f && scale_factor[1] == 2.0f)
        {
            vx_uint32 uniPackEvenData_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x06040200, 0x06040200, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00003400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16bits_2x_downsample", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && (scaleIn != scaleOut || input_ZP != output_ZP))
            {
                vx_uint16  M0                   = 0;
                vx_int8    postShift            = 0;
                vx_uint32    multAndoutZP[2]    = {0};
                vx_uint32 uniMultiplyAndPostShift_2x_down_2x8[16] = {
                    0xdddddddd, // TCfg
                    0x44444444, // ASelt
                    0x16141210, 0x1e1c1a18, // ABin
                    0x11111511, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };

                getFP32M0AndN(scaleIn / scaleOut, &M0, &postShift);

                multAndoutZP[0] = (vx_uint32)(M0);
                multAndoutZP[1] = (vx_uint32)((output_ZP << postShift) - input_ZP * M0);

                uniMultiplyAndPostShift_2x_down_2x8[7] |= (postShift & 0x1F);

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8_2x_downsample", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x_down_2x8", 1, uniMultiplyAndPostShift_2x_down_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_UINT8))
            {
                if (outputFormat == VX_TYPE_INT8)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16toint8_2x_downsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16touint8_2x_downsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x8", 1, uniMultiplyAndPostShift_2x8);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
            {
                vx_uint32 uniI16toI16_2xDown_2x8[16] = {
                    0x11111111, // TCfg
                    0x11110000, // ASelt
                    0x06040200, 0x06040200, // ABin
                    0x22222222, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00000600, // AccumType, ConstantType, and PostShift
                    0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                };

                if (srcFixPointPos > dstFixPointPos)
                {
                    vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                    uniI16toI16_2xDown_2x8[7] |= (postshift & 0x1F);
                }
                else
                {
                    vx_uint32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);
                    vx_uint32 i          = 0;

                    for (i = 0; i < 8; i++)
                    {
                        uniI16toI16_2xDown_2x8[i + 8] = multiplier;
                    }
                }

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_2x_downsample", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI16toI16_2xDown_2x8", 1, uniI16toI16_2xDown_2x8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && srcFixPointPos != dstFixPointPos)
                {
                    vx_uint32 uniI8toI8_2xDown_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x06040200, 0x0e0c0a08, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };

                    if (srcFixPointPos > dstFixPointPos)
                    {
                        vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                        uniI8toI8_2xDown_2x8[7] |= (postshift & 0x1F);
                    }
                    else
                    {
                        vx_uint32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);
                        vx_uint32 i          = 0;

                        for (i = 0; i < 8; i++)
                        {
                            uniI8toI8_2xDown_2x8[i + 8] = multiplier;
                        }
                    }

                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_2x_downsample", borderMode);
                    if (!shaderExecutable) goto OnError;

                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2xDown_2x8", 1, uniI8toI8_2xDown_2x8);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8bits_2x_downsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
            }

            execution_parameters.globalWorkScale[0] = 16;
            execution_parameters.globalWorkScale[1] = 2;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackEvenData_2x8", 1, uniPackEvenData_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (scale_factor[0] == 0.5f)
        {
            if ((inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16))
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16bits_2x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0] = 8;
                execution_parameters.globalWorkScale[1] = 1;
                execution_parameters.globalWorkScale[2] = 1;
            }
            else if (inputFormat == VX_TYPE_INT16 && outputFormat == VX_TYPE_INT16)
            {
                if (srcFixPointPos != dstFixPointPos)
                {
                   vx_uint32 uniI8toI8_2x_part0_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x01010000, 0x03030202, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };
                    vx_uint32 uniI8toI8_2x_part1_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x05050404, 0x07070606, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };

                    if (srcFixPointPos > dstFixPointPos)
                    {
                        vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                        uniI8toI8_2x_part0_2x8[7] |= (postshift & 0x1F);
                        uniI8toI8_2x_part1_2x8[7] |= (postshift & 0x1F);
                    }
                    else
                    {
                        vx_uint32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);
                        vx_uint32 i          = 0;

                        for (i = 0; i < 8; i++)
                        {
                            uniI8toI8_2x_part0_2x8[i + 8] = multiplier;
                            uniI8toI8_2x_part1_2x8[i + 8] = multiplier;
                        }
                    }

                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;

                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part0_2x8", 1, uniI8toI8_2x_part0_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part1_2x8", 1, uniI8toI8_2x_part1_2x8);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16bits_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                execution_parameters.globalWorkScale[0] = 8;
                execution_parameters.globalWorkScale[1] = 1;
                execution_parameters.globalWorkScale[2] = 1;
            }
            else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8 && (scaleIn != scaleOut || input_ZP != output_ZP))
            {
                vx_uint16  M0                   = 0;
                vx_int8    postShift            = 0;
                vx_uint32    multAndoutZP[2]    = {0};
                vx_uint32 uniMultiplyAndPostShift_2x_up0_2x8[16] = {
                    0xdddddddd, // TCfg
                    0x44444444, // ASelt
                    0x11111010, 0x13131212, // ABin
                    0x11111511, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniMultiplyAndPostShift_2x_up1_2x8[16] = {
                    0xdddddddd, // TCfg
                    0x44444444, // ASelt
                    0x15151414, 0x17171616, // ABin
                    0x11111511, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniMultiplyAndPostShift_2x_up2_2x8[16] = {
                    0xdddddddd, // TCfg
                    0x44444444, // ASelt
                    0x19191818, 0x1b1b1a1a, // ABin
                    0x11111511, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniMultiplyAndPostShift_2x_up3_2x8[16] = {
                    0xdddddddd, // TCfg
                    0x44444444, // ASelt
                    0x1d1d1c1c, 0x1f1f1e1e, // ABin
                    0x11111511, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00002400, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                getFP32M0AndN(scaleIn / scaleOut, &M0, &postShift);

                multAndoutZP[0] = (vx_uint32)(M0);
                multAndoutZP[1] = (vx_uint32)((output_ZP << postShift) - input_ZP * M0);

                uniMultiplyAndPostShift_2x_up0_2x8[7] |= (postShift & 0x1F);
                uniMultiplyAndPostShift_2x_up1_2x8[7] |= (postShift & 0x1F);
                uniMultiplyAndPostShift_2x_up2_2x8[7] |= (postShift & 0x1F);
                uniMultiplyAndPostShift_2x_up3_2x8[7] |= (postShift & 0x1F);

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8_2x_upsample", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0] = 16;
                execution_parameters.globalWorkScale[1] = 1;
                execution_parameters.globalWorkScale[2] = 1;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x_up0_2x8", 1, uniMultiplyAndPostShift_2x_up0_2x8);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x_up1_2x8", 1, uniMultiplyAndPostShift_2x_up1_2x8);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x_up2_2x8", 1, uniMultiplyAndPostShift_2x_up2_2x8);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x_up3_2x8", 1, uniMultiplyAndPostShift_2x_up3_2x8);
                status  |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
                if (status != VX_SUCCESS) goto OnError;
            }
            else if ((inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8) || (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8))
            {
                if (inputFormat == VX_TYPE_INT8 && outputFormat == VX_TYPE_INT8 && srcFixPointPos != dstFixPointPos)
                {
                    vx_uint32 uniI8toI8_2x_part0_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x01010000, 0x03030202, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };
                    vx_uint32 uniI8toI8_2x_part1_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x05050404, 0x07070606, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };
                    vx_uint32 uniI8toI8_2x_part2_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x09090808, 0x0b0b0a0a, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };
                    vx_uint32 uniI8toI8_2x_part3_2x8[16] = {
                        0x11111111, // TCfg
                        0x00000000, // ASelt
                        0x0d0d0c0c, 0x0f0f0e0e, // ABin
                        0x22222222, // BSelt
                        0x00000000, 0x00000000, // BBin
                        0x00000600, // AccumType, ConstantType, and PostShift
                        0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                    };

                    if (srcFixPointPos > dstFixPointPos)
                    {
                        vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                        uniI8toI8_2x_part0_2x8[7] |= (postshift & 0x1F);
                        uniI8toI8_2x_part1_2x8[7] |= (postshift & 0x1F);
                        uniI8toI8_2x_part2_2x8[7] |= (postshift & 0x1F);
                        uniI8toI8_2x_part3_2x8[7] |= (postshift & 0x1F);
                    }
                    else
                    {
                        vx_uint32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);
                        vx_uint32 i          = 0;

                        for (i = 0; i < 8; i++)
                        {
                            uniI8toI8_2x_part0_2x8[i + 8] = multiplier;
                            uniI8toI8_2x_part1_2x8[i + 8] = multiplier;
                            uniI8toI8_2x_part2_2x8[i + 8] = multiplier;
                            uniI8toI8_2x_part3_2x8[i + 8] = multiplier;
                        }
                    }

                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;

                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part0_2x8", 1, uniI8toI8_2x_part0_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part1_2x8", 1, uniI8toI8_2x_part1_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part2_2x8", 1, uniI8toI8_2x_part2_2x8);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8toI8_2x_part3_2x8", 1, uniI8toI8_2x_part3_2x8);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8bits_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                execution_parameters.globalWorkScale[0] = 16;
                execution_parameters.globalWorkScale[1] = 1;
                execution_parameters.globalWorkScale[2] = 1;
            }
            else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_INT8 || outputFormat == VX_TYPE_UINT8))
            {
                if (outputFormat == VX_TYPE_INT8)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16toint8_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16touint8_2x_upsample", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                execution_parameters.globalWorkScale[0] = 8;
                execution_parameters.globalWorkScale[1] = 2;
                execution_parameters.globalWorkScale[2] = 1;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShiftLo_2x8", 1, uniMultiplyAndPostShiftLo_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShiftHi_2x8", 1, uniMultiplyAndPostShiftHi_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
                if (status != VX_SUCCESS) goto OnError;
            }
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            vx_uint32 uniGetExtractData_2x8[16] = {
                0x00009999, // TCfg
                0x00000000, // ASelt
                0x06040200, 0x00000000, // ABin
                0x0000aaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000300, // AccumType, ConstantType, and PostShift
                0x00100010, 0x00100010, 0x00100010, 0x00100010, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            if (scale_factor[0] < 4.0f)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_OP", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetExtractData_2x8", 1, uniGetExtractData_2x8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            execution_parameters.globalWorkScale[0] = 4;
            execution_parameters.globalWorkScale[1] = 1;
            execution_parameters.globalWorkScale[2] = 1;

            enable_config_out                       = vx_true_e;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == outputFormat && (inputFormat == VX_TYPE_INT8 || inputFormat == VX_TYPE_INT16))
        {
            vx_uint32 uniGetExtractData_2x8[16] = {
                0x00009999, // TCfg
                0x00000000, // ASelt
                0x06040200, 0x00000000, // ABin
                0x0000aaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000300, // AccumType, ConstantType, and PostShift
                0x00080008, 0x00080008, 0x00080008, 0x00080008, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniConvertI8toI8_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x22222222, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
            };

            if (inputFormat == VX_TYPE_INT16)
            {
                uniGetExtractData_2x8[8]  = 0x00100010;
                uniGetExtractData_2x8[9]  = 0x00100010;
                uniGetExtractData_2x8[10] = 0x00100010;
                uniGetExtractData_2x8[11] = 0x00100010;
                uniGetExtractData_2x8[12] = 0x00100010;
                uniGetExtractData_2x8[13] = 0x00100010;
                uniGetExtractData_2x8[14] = 0x00100010;
                uniGetExtractData_2x8[15] = 0x00100010;
            }

            if (srcFixPointPos > dstFixPointPos)
            {
                vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                uniConvertI8toI8_2x8[7] |= (postshift & 0x1F);
            }
            else
            {
                vx_uint32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);
                vx_uint32 i          = 0;

                for (i = 0; i < 8; i++)
                {
                    uniConvertI8toI8_2x8[i + 8] = multiplier;
                }
            }

            if (scale_factor[0] < 4.0f)
            {
                if (inputFormat == VX_TYPE_INT8)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_OP", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_OP", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetExtractData_2x8", 1, uniGetExtractData_2x8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                if (inputFormat == VX_TYPE_INT8)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
            }

            execution_parameters.globalWorkScale[0] = 4;
            execution_parameters.globalWorkScale[1] = 1;
            execution_parameters.globalWorkScale[2] = 1;

            enable_config_out                       = vx_true_e;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertI8toI8_2x8", 1, uniConvertI8toI8_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            vx_uint16  M0                   = 0;
            vx_int8    postShift            = 0;
            vx_uint32    multAndoutZP[2]    = {0};
            vx_uint32 uniMultiplyAndPostShift_2x8[16] = {
                0xdddddddd, // TCfg
                0x44444444, // ASelt
                0x13121110, 0x17161514, // ABin
                0x11111111, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniGetExtractData_2x8[16] = {
                0x00009999, // TCfg
                0x00000000, // ASelt
                0x06040200, 0x00000000, // ABin
                0x0000aaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000300, // AccumType, ConstantType, and PostShift
                0x00080008, 0x00080008, 0x00080008, 0x00080008, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            getFP32M0AndN(scaleIn / scaleOut, &M0, &postShift);

            multAndoutZP[0] = (vx_uint32)(M0);
            multAndoutZP[1] = (vx_uint32)((output_ZP << postShift) - input_ZP * M0);

            uniMultiplyAndPostShift_2x8[7] |= (postShift & 0x1F);

            if (scale_factor[0] < 4.0f)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8_OP", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniGetExtractData_2x8", 1, uniGetExtractData_2x8);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            execution_parameters.globalWorkScale[0] = 4;
            execution_parameters.globalWorkScale[1] = 1;
            execution_parameters.globalWorkScale[2] = 1;

            enable_config_out                       = vx_true_e;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_xy", 1, scale_factor);
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "multAndoutZP", 1, multAndoutZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMultiplyAndPostShift_2x8", 1, uniMultiplyAndPostShift_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    if (enable_config_out)
    {
        execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (out_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }
    else
    {
        if (type == VX_INTERPOLATION_NEAREST_NEIGHBOR && useImage2DFlag)
        {
            execution_parameters.workDim = 2;

            execution_parameters.globalWorkSize[0]   = gcmALIGN((in_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (depth * in_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        }
        else
        {
            execution_parameters.globalWorkSize[0]   = gcmALIGN((in_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
            execution_parameters.globalWorkSize[1]   = (in_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
            execution_parameters.globalWorkSize[2]   = depth;
        }
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs)  vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs)  vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}


/********************************vxnneROIRect2ROIListShaderExecutable****************************/
vxnne_shader_executable vxnneROIRect2ROIListShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_uint32               rois_stride,
    vx_uint32               rois_num,
    vx_uint32               poolWidth,
    vx_uint32               poolHeight,
    vx_float32              spatial_scale,
    vx_uint32               tpCoreCount,
    vx_tensor               roiList)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    char *programSources = NULL;

    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference parameters[2]     = {(vx_reference)input, (vx_reference)roiList};
    vx_uint32    batch0            = 1;
    vx_uint32    src_dims          = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_enum      inputFormat       = TENSOR_DATA_TYPE(input);
    vx_tensor    input_rs          = NULL;
    vx_tensor    roiList_rs        = NULL;
    vx_int32     src_sizes[4]      = {rois_stride, rois_num, 1, batch0};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p",
         context, kernelEnum, borderMode, input);

    borderMode->mode = VX_BORDER_REPLICATE;

    input_rs      = vxoTensor_ReshapeTensor(input, src_sizes, src_dims);
    parameters[0] = (vx_reference)input_rs;

    if (TENSOR_DIM_NUM(roiList) == 1)
    {
        vx_uint32 w             = TENSOR_VIEW_SIZE_INDEX(roiList, 0);
        vx_int32  sizes[4]      = {w, 1, 1, 1};
        vx_uint32 dims = 2;

        roiList_rs = vxoTensor_ReshapeTensor(roiList, sizes, dims);
        parameters[1] = (vx_reference)roiList_rs;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, ROIRect2ROIList, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/ROIRect2ROIList.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "roipooling", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_FLOAT16)
    {
        vx_float32  poolingHVInc_coef[2]    = {(vx_float32)256.0f / poolWidth, (vx_float32)256.0f / poolHeight};
        vx_int32    offset                  = rois_stride == 5 ? 1 : 0;
        vx_int32    rois_num_sub1           = rois_num - 1;
        vx_uint32   eachTPSize              = tpCoreCount >= rois_num ? 1 : (vx_uint32)((vx_float32)rois_num / tpCoreCount + 0.5f);
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniPackedShort4Data_4x4[16] = {
            0x03030307, // TCfg
            0x00000100, // ASelt
            0x00000020, 0x00060004, // ABin
            0x00000008, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003600, // AccumType, ConstantType, and PostShift
            0x01000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };


        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_rect2roilist_fp16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedShort4Data_4x4", 1, uniPackedShort4Data_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "poolingHVInc_coef", 1, poolingHVInc_coef);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "spatial_scale", 1, &spatial_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offset", 1, &offset);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "rois_num_sub1", 1, &rois_num_sub1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "eachTPSize", 1, &eachTPSize);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN((rois_num  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1], SHADER_THREAD_COUNT);
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (roiList_rs) vxoTensor_ReleaseTensor(&roiList_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (roiList_rs) vxoTensor_ReleaseTensor(&roiList_rs);

    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcDepthwiseConvolution****************************************/
vxnne_shader_executable vxnneGetDepthwiseConvShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               inputs,
    vx_tensor               weights,
    vx_tensor               biases,
    vx_scalar               padXLeft,
    vx_scalar               padXRight,
    vx_scalar               padYTop,
    vx_scalar               padYBottom,
    vx_enum                 padMode,
    vx_scalar               padConstant,
    vx_scalar               dilationX,
    vx_scalar               dilationY,
    vx_scalar               channel_multiplier,
    vx_scalar               relu_s,
    vx_scalar               pooling_s,
    vx_scalar               poolingX,
    vx_scalar               poolingY,
    vx_scalar               downScaleSizeRounding,
    vx_tensor               outputs)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program                       program              = VX_NULL;
    vx_status                        status               = VX_FAILURE;
    vxnne_shader_executable          shaderExecutable     = VX_NULL;
    vxnne_kernel_shaders             kernel               = NULL;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference  parameters[10]             = {(vx_reference)inputs, (vx_reference)weights, (vx_reference)biases, (vx_reference)channel_multiplier,
                                                VX_NULL, VX_NULL, VX_NULL, (vx_reference)padXLeft, (vx_reference)padYTop, (vx_reference)outputs};
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(inputs, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(inputs, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(inputs, 2);
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(outputs, 0);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(outputs, 1);
    vx_uint32     output_depth               = TENSOR_VIEW_SIZE_INDEX(outputs, 2);
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(inputs);
    vx_enum       outputFormat               = TENSOR_DATA_TYPE(outputs);
    vx_int32      kernel_width               = TENSOR_VIEW_SIZE_INDEX(weights, 0);
    vx_int32      kernel_height              = TENSOR_VIEW_SIZE_INDEX(weights, 1);
    vx_int32      padLeftv                   = padXLeft->value->n32;
    vx_int32      padRightv                  = padXRight->value->n32;
    vx_uint32     inputZP                    = TENSOR_TF_ZEROPOINT(inputs);
    vx_float32    inputScale                 = TENSOR_TF_SCALE(inputs);
    vx_uint32     weightZP                   = TENSOR_TF_ZEROPOINT(weights);
    vx_float32    weightScale                = TENSOR_TF_SCALE(weights);
    vx_uint32     biasZP                     = TENSOR_TF_ZEROPOINT(biases);
    vx_float32    biasScale                  = TENSOR_TF_SCALE(biases);
    vx_uint32     outputZP                   = TENSOR_TF_ZEROPOINT(outputs);
    vx_float32    outputScale                = TENSOR_TF_SCALE(outputs);

    vx_scalar     kernel_widths              = vxCreateScalar(context, VX_TYPE_INT32, &kernel_width);
    vx_scalar     kernel_heights             = vxCreateScalar(context, VX_TYPE_INT32, &kernel_height);
    vx_scalar     strides                    = VX_NULL;
    vx_int32      stride                     = 0;
    vx_tensor     reBiases                   = VX_NULL;
    vx_tensor     reWeights                  = VX_NULL;
    vx_int32      sizes[4]                   = {1, 1, 1, 1};
    vx_uint32     maxWorkGroupSize           = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, inputs=%p, outputs=%p",
         context, kernelEnum, borderMode, inputs, outputs);

    if (fabs(inputScale*weightScale - biasScale) > 0.000001f || biasZP !=0)
    {
        vxError("biase's scale must equal to input's scale multiply weight's scale, and biase's zero point must equal to 0! failed at function %s line %d", __FUNCTION__, __LINE__);
        goto OnError;
    }

    if ((input_width == 1 && input_height ==1) || (output_width == 1 && input_width == (vx_uint32)kernel_width && padLeftv == 0))
        stride = 1;
    else
        stride = vxoNNExternsionConvlutionRound((vx_float32)(input_width + padLeftv + padRightv - kernel_width) / (output_width - 1), downScaleSizeRounding->value->e);
    strides = vxCreateScalar(context, VX_TYPE_INT32, &stride);

    if (biases != VX_NULL)
    {
        vx_uint32 bias_dims = TENSOR_DIM_NUM(biases);
        vx_uint32 bias_w    = TENSOR_VIEW_SIZE_INDEX(biases, 0);
        vx_int32  reSize[4] = {bias_w, 1, 1, 1};

        bias_dims = (bias_dims == 1) ? 2 : bias_dims;
        reBiases  = vxoTensor_ReshapeTensor(biases, reSize, bias_dims);
    }

    sizes[0] = kernel_width * kernel_height;
    sizes[1] = TENSOR_VIEW_SIZE_INDEX(weights, 2);

    reWeights = vxoTensor_ReshapeTensor(weights, sizes, 2);

    parameters[1] = (vx_reference)reWeights;
    parameters[2] = (vx_reference)reBiases;
    parameters[4] = (vx_reference)kernel_widths;
    parameters[5] = (vx_reference)kernel_heights;
    parameters[6] = (vx_reference)strides;

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_FLOAT16)
        borderMode->constant_value.S16 = 0;
    else if (inputFormat == VX_TYPE_UINT8)
        borderMode->constant_value.U8 = (vx_uint8)inputZP;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, DepthwiseConv, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/DepthwiseConv.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcDepthwiseConv", program, 10, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        vx_int32 x_len_4x       = kernel_width / 4;
        vx_int32 x_len_remain   = kernel_width % 4;
        vx_int32 x_len_5x       = kernel_width / 5;
        vx_int32 x_len5x_remain = kernel_width % 5;
        vx_uint32 packZPin      = (inputZP << 16) | inputZP;
        vx_uint32 packZPwe      = (weightZP << 16) | weightZP;
        vx_int32 ksZPinZPwe     = kernel_width * kernel_height * inputZP * weightZP;
        vx_float32 outScale     = biasScale / outputScale;
        vx_float32 outZP        = (vx_float32)outputZP;
        vx_uint32 uniFp16MulAccumtoF32_dp4x4[16] = {
            0x00000055, // TCfg
            0x00000000, // ASelt
            0x00003210, 0x00000000, // ABin
            0x00000055, // BSelt
            0x00003210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16MulAccumNtoF32_dp4x4[16] = {
            0x00000055, // TCfg
            0x00000000, // ASelt
            0x00003210, 0x00000000, // ABin
            0x00000055, // BSelt
            0x00003210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConfigMulAccumN[4] = {0x00000055, 0x00000001, 0x00000005, 0x00000015};
        vx_uint32 uniU8MulAccumtoF32_dp16x1[16] = {
            0x29a69a69, // TCfg
            0x00004514, // ASelt
            0x44322100, 0x04332110, // ABin
            0x29a69a69, // BSelt
            0x04002000, 0x00030010, // BBin
            0x00000700, // AccumType, ConstantType, and PostShift
            packZPin, packZPin, packZPin, packZPin, packZPwe, packZPwe, packZPwe, packZPwe // Constant
        };
        vx_uint32 uniU8MulAccumNtoF32_dp16x1[16] = {
            0x29a69a69, // TCfg
            0x00004514, // ASelt
            0x44322100, 0x04332110, // ABin
            0x29a69a69, // BSelt
            0x04002000, 0x00030010, // BBin
            0x00000700, // AccumType, ConstantType, and PostShift
            packZPin, packZPin, packZPin, packZPin, packZPwe, packZPwe, packZPwe, packZPwe // Constant
        };
        vx_uint32 uniConfigU8MulAccumN[5] = {0x29a69a69, 0x00020009, 0x00260029, 0x00a60269, 0x09a60a69};
        uniFp16MulAccumNtoF32_dp4x4[0] = uniConfigMulAccumN[x_len_remain];
        uniU8MulAccumNtoF32_dp16x1[0] = uniConfigU8MulAccumN[x_len5x_remain];

        if (kernel_width <= 4 && inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16kernelWidthLE4", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16kernelWidthGT4", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (kernel_width <= 5 && inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8kernelWidthLE5", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8kernelWidthGT5", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulAccumNtoF32_dp4x4", 1, uniFp16MulAccumNtoF32_dp4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16MulAccumtoF32_dp4x4", 1, uniFp16MulAccumtoF32_dp4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_height", 1, &input_height);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_depth", 1, &input_depth);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_4x", 1, &x_len_4x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAccumNtoF32_dp16x1", 1, uniU8MulAccumNtoF32_dp16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8MulAccumtoF32_dp16x1", 1, uniU8MulAccumtoF32_dp16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_5x", 1, &x_len_5x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len5x_remain", 1, &x_len5x_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "ksZPinZPwe", 1, &ksZPinZPwe);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outScale", 1, &outScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outZP", 1, &outZP);

        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;

    execution_parameters.globalWorkSize[0]   = gcmALIGN((output_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (output_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = output_depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 10);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (reWeights) vxoTensor_ReleaseTensor(&reWeights);
    if (reBiases) vxoTensor_ReleaseTensor(&reBiases);
    if (kernel_widths) vxReleaseScalar(&kernel_widths);
    if (kernel_heights) vxReleaseScalar(&kernel_heights);
    if (strides) vxReleaseScalar(&strides);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (reWeights) vxoTensor_ReleaseTensor(&reWeights);
    if (reBiases) vxoTensor_ReleaseTensor(&reBiases);
    if (kernel_widths) vxReleaseScalar(&kernel_widths);
    if (kernel_heights) vxReleaseScalar(&kernel_heights);
    if (strides) vxReleaseScalar(&strides);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitProjectionShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               weights,
    vx_tensor               bias,
    vx_tensor               proj_clip,
    vx_tensor               output_state_out,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[6]   = {(vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL};
    vx_bool       enable_bias    = (bias == NULL) ? vx_false_e : vx_true_e;
    vx_enum       output_format  = TENSOR_DATA_TYPE(output);
    vx_enum       input_format   = TENSOR_DATA_TYPE(input);
    vx_enum       weights_format = TENSOR_DATA_TYPE(weights);
    vx_enum       bias_format    = enable_bias ? TENSOR_DATA_TYPE(bias) : VX_TYPE_INVALID;
    vx_uint32     input_num      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     bias_dims      = enable_bias ? (TENSOR_DIM_NUM(bias) == 1 ? 2 : TENSOR_DIM_NUM(bias)) : 0;
    vx_uint32     output_dims    = TENSOR_DIM_NUM(output);
    vx_uint32     num_units      = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size     = (output_dims > 1) ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_tensor     bias_rs        = NULL;
    vx_tensor     proj_clip_rs   = NULL;
    vx_int32      bias_sizes[4]  = {num_units, 1, 1, 1};
    vx_int32      sizes[4]       = {1, 1, 1, 1};
    vx_uint32     paramNum       = enable_bias ? 6 : 5;
    vx_uint32     paramIdx       = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    proj_clip_rs      = vxoTensor_ReshapeTensor(proj_clip, sizes, 2);

    if (enable_bias)
        bias_rs       = vxoTensor_ReshapeTensor(bias, bias_sizes, bias_dims);

    parameters[paramIdx ++] = (vx_reference)input;
    parameters[paramIdx ++] = (vx_reference)weights;
    if (enable_bias)
        parameters[paramIdx ++] = (vx_reference)bias_rs;
    parameters[paramIdx ++] = (vx_reference)proj_clip_rs;
    parameters[paramIdx ++] = (vx_reference)output_state_out;
    parameters[paramIdx ++] = (vx_reference)output;

    if (input_format == VX_TYPE_FLOAT16)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        borderMode->constant_value.S16 = 0;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitProjection, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitProjection.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnitProjection", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16 && weights_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_FLOAT16)
    {
        vx_int32 input_size_align32 = 0;
        vx_uint32 uniAccF16MulFp16_16x1[16] = {
            0x00005555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x00000000, // ABin
            0x00005555, // BSelt
            0x76543210, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32_16x1[16] = {
            0x00000001, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000002, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toClip_4x4[16] = {
            0x00000101, // TCfg
            0x00000000, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x0000bc00, 0x00000000, 0x00003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_bias && bias_format == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (enable_bias && bias_format == VX_TYPE_FLOAT32)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp32", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16_noBias", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccF16MulFp16_16x1", 1, uniAccF16MulFp16_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_16x1", 1, uniFp16toFp32_16x1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toClip_4x4", 1, uniFp16toClip_4x4);
        if (status != VX_SUCCESS) goto OnError;

        input_size_align32   = gcmALIGN(input_num, 32);
        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_size_align32", 1, &input_size_align32);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 1;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (proj_clip_rs) vxoTensor_ReleaseTensor(&proj_clip_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (bias_rs) vxoTensor_ReleaseTensor(&bias_rs);
    if (proj_clip_rs) vxoTensor_ReleaseTensor(&proj_clip_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitHiddenOutShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_bool                 enable_cell_in,
    vx_tensor               input_conv,
    vx_float32              forget_bias,
    vx_tensor               cell_state_in,
    vx_tensor               output,
    vx_tensor               cell_state_out,
    vx_tensor               hidden_state_out,
    vx_tensor               hidden_conv)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_reference  parameters[6]   = {(vx_reference)input_conv, (vx_reference)cell_state_in, (vx_reference)output, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL};
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vxnne_kernel_shaders    kernel           = VX_NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vx_program    program           = VX_NULL;
    vx_status     status            = VX_FAILURE;
    vx_enum       input_format      = TENSOR_DATA_TYPE(input_conv);
    vx_enum       output_format     = TENSOR_DATA_TYPE(output);
    vx_uint32     num_units         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32     paramNum          = 3;
    vx_int8       input_fl          = TENSOR_POS(input_conv);
    vx_int8       hidden_in_fl      = hidden_conv ? TENSOR_POS(hidden_conv) : 1;
    vx_float32    outputZP          = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_float32    hidden_outScale   = 1.0f;
    vx_float32    outputScale       = 1.0f;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input_conv=%p, output=%p",
         context, kernelEnum, borderMode, input_conv, output);

    if (hidden_state_out &&  TENSOR_QUANT_TYPE(hidden_state_out) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8 fixPointPos = TENSOR_POS(hidden_state_out);

        if (fixPointPos >= 0)
            hidden_outScale *= (vx_float32)(1 << fixPointPos);
        else if (fixPointPos < 0)
            hidden_outScale *= 1.0f / (vx_float32) (1 << -fixPointPos);
    }

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8 fixPointPos = TENSOR_POS(output);

        if (fixPointPos >= 0)
            outputScale *= (vx_float32)(1 << fixPointPos);
        else if (fixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -fixPointPos);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        outputScale = 1.0f / TENSOR_TF_SCALE(output);
    }

    if (cell_state_out)
        parameters[paramNum ++] = (vx_reference)cell_state_out;

    if (hidden_state_out)
        parameters[paramNum ++] = (vx_reference)hidden_state_out;

    if (hidden_conv)
        parameters[paramNum ++] = (vx_reference)hidden_conv;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitHiddenOut, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitHiddenOut.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/

        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnitHiddenOut", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_INT8)
    {
        vx_float32     logE                 = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE              = 2 * logE;
        vx_uint32 uniExtractDft16_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddFp16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };

        if (paramNum == 6 && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_P6_NP", borderMode);
        }
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractDft16_2x8", 1, uniExtractDft16_2x8);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (input_format == VX_TYPE_FLOAT16)
    {
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddFp16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };

        if (paramNum == 5 && cell_state_in && cell_state_out && hidden_conv)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P5_Projection", borderMode);
        }
        else if (paramNum == 4 && cell_state_in && cell_state_out)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_projection", borderMode);
        else if (paramNum == 3 && !enable_cell_in)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P3", borderMode);
        else if (paramNum == 3 && enable_cell_in)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P3_cell", borderMode);
        else if (paramNum == 4 && hidden_conv)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P4_I", borderMode);
        else if (paramNum == 4 && hidden_state_out)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P4_O", borderMode);

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        if (status != VX_SUCCESS) goto OnError;
    }
    else  if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_float32     logE                 = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE              = 2 * logE;
        vx_uint32 uniExtractDft16_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDft16toFp32_input_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDft16AddDft16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        if (paramNum == 3 && !enable_cell_in)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P3", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P3", borderMode);
        }
        else if (paramNum == 3 && enable_cell_in)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P3_cell", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P3_cell", borderMode);
        }
        else if (paramNum == 4 && hidden_conv)
        {
            vx_uint16 mulVal = 1 << abs(hidden_in_fl - input_fl);
            if (hidden_in_fl > input_fl)
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (hidden_in_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (1 << 16) | mulVal;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (1 << 16) | mulVal;
            }
            else
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (input_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (mulVal << 16) | 1;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (mulVal << 16) | 1;
            }

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P4_I", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P4_I", borderMode);
        }
        else if (paramNum == 4 && hidden_state_out)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P4_O", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P4_O", borderMode);
        }

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractDft16_2x8", 1, uniExtractDft16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft16toFp32_input_4x4", 1, uniDft16toFp32_input_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft16AddDft16toFp32_4x4", 1, uniDft16AddDft16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "hidden_outScale", 1, &hidden_outScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else  if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        vx_float32     logE                 = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE              = 2 * logE;
        vx_uint32 uniExtractDft16_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDft16toFp32_input_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDft16AddDft16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };

        if (paramNum == 3 && !enable_cell_in)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toU8_P3", borderMode);
        }
        else if (paramNum == 3 && enable_cell_in)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toU8_P3_cell", borderMode);
        }
        else if (paramNum == 4 && hidden_conv)
        {
            vx_uint16 mulVal = 1 << abs(hidden_in_fl - input_fl);
            if (hidden_in_fl > input_fl)
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (hidden_in_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (1 << 16) | mulVal;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (1 << 16) | mulVal;
            }
            else
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (input_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (mulVal << 16) | 1;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (mulVal << 16) | 1;
            }

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toU8_P4_I", borderMode);
        }
        else if (paramNum == 4 && hidden_state_out)
        {
            uniDft16toFp32_input_4x4[7] = uniDft16toFp32_input_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toU8_P4_O", borderMode);
        }
        else if (paramNum == 5 && !hidden_state_out)
        {
            vx_uint16 mulVal = 1 << abs(hidden_in_fl - input_fl);
            if (hidden_in_fl > input_fl)
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (hidden_in_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (1 << 16) | mulVal;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (1 << 16) | mulVal;
            }
            else
            {
                uniDft16AddDft16toFp32_4x4[7] = uniDft16AddDft16toFp32_4x4[7] | (input_fl & 0x1F);

                uniDft16AddDft16toFp32_4x4[8]  = uniDft16AddDft16toFp32_4x4[10] = (mulVal << 16) | 1;
                uniDft16AddDft16toFp32_4x4[12] = uniDft16AddDft16toFp32_4x4[14] = (mulVal << 16) | 1;
            }

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16toU8_P5_Projection", borderMode);
        }

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractDft16_2x8", 1, uniExtractDft16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft16toFp32_input_4x4", 1, uniDft16toFp32_input_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft16AddDft16toFp32_4x4", 1, uniDft16AddDft16toFp32_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "hidden_outScale", 1, &hidden_outScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitHiddenOutExtShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_bool                 enable_cell_in,
    vx_tensor               input_conv,
    vx_float32              forget_bias,
    vx_tensor               cell_state_in,
    vx_tensor               output,
    vx_tensor               cell_state_out,
    vx_tensor               hidden_state_out,
    vx_tensor               hidden_conv)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_reference  parameters[6]   = {(vx_reference)input_conv, (vx_reference)cell_state_in, (vx_reference)output, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL};
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vxnne_kernel_shaders    kernel           = VX_NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vx_program    program           = VX_NULL;
    vx_status     status            = VX_FAILURE;
    vx_enum       input_format      = TENSOR_DATA_TYPE(input_conv);
    vx_enum       output_format     = TENSOR_DATA_TYPE(output);
    vx_uint32     num_units         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int8       dstFixPointPos    = TENSOR_POS(output);
    vx_uint32     paramNum          = 3;
    vx_float32    outputZP          = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_float32    outputScale       = 1.0f;
    char *programSources = NULL;

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (dstFixPointPos >= 0)
            outputScale *= (vx_float32)(1 << dstFixPointPos);
        else if (dstFixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        outputScale = 1.0f / TENSOR_TF_SCALE(output);
    }

    if (cell_state_out)
        parameters[paramNum ++] = (vx_reference)cell_state_out;

    if (hidden_state_out)
        parameters[paramNum ++] = (vx_reference)hidden_state_out;

    if (hidden_conv)
        parameters[paramNum ++] = (vx_reference)hidden_conv;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitHiddenOutExt, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitHiddenOutExt.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/

        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnitHiddenOutExt", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16)
    {
        vx_float32  logE      = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32  twoLogE   = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddFp16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
        {
            if (paramNum == 3 && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
            {
                if (output_format == VX_TYPE_INT8)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_P3", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_P3", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                if (paramNum == 4 && hidden_conv && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
                {
                    if (output_format == VX_TYPE_INT8)
                    {
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_P4", borderMode);
                        if (!shaderExecutable) goto OnError;
                    }
                    else
                    {
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_P4", borderMode);
                        if (!shaderExecutable) goto OnError;
                    }
                }
                else if (paramNum == 6 && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
                {
                    if (output_format == VX_TYPE_INT8)
                    {
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_P6_NP", borderMode);
                        if (!shaderExecutable) goto OnError;
                    }
                    else
                    {
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_P6_NP", borderMode);
                        if (!shaderExecutable) goto OnError;
                    }
                }

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
                if (status != VX_SUCCESS) goto OnError;
            }

            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE && output_format == VX_TYPE_UINT8)
        {
            if (paramNum == 3 && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
            {

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_P3", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
                if (status != VX_SUCCESS) goto OnError;
            }
            else
            {
                if (paramNum == 4 && hidden_conv && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_P4", borderMode);
                    if (!shaderExecutable) goto OnError;
                }
                else if (paramNum == 6 && TENSOR_DATA_TYPE(cell_state_in) == VX_TYPE_FLOAT32)
                {
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_P6_NP", borderMode);
                    if (!shaderExecutable) goto OnError;
                }

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
                if (status != VX_SUCCESS) goto OnError;
            }

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            if (paramNum == 5 && cell_state_in && cell_state_out && hidden_conv)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_P5_Projection", borderMode);
            }
            else if (paramNum == 4 && cell_state_in && cell_state_out)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_projection", borderMode);
            else if (paramNum == 3 && !enable_cell_in)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_P3", borderMode);
            else if (paramNum == 3 && enable_cell_in)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_P3_cell", borderMode);
            else if (paramNum == 4 && hidden_conv)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_P4_I", borderMode);
            else if (paramNum == 4 && hidden_state_out)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_P4_O", borderMode);

            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitStateOutExtShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               inputs_conv,
    vx_float32              forget_bias,
    vx_tensor               cell_state_in,
    vx_tensor               biases,
    vx_tensor               output,
    vx_tensor               cell_state_out,
    vx_tensor               hidden_conv,
    vx_tensor               hidden_state_out
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_reference  parameters[7]   = {(vx_reference)inputs_conv, (vx_reference)cell_state_in, (vx_reference)biases, (vx_reference)output, (vx_reference)cell_state_out, (vx_reference)hidden_conv, (vx_reference)NULL};
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vxnne_kernel_shaders    kernel           = VX_NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vx_program    program           = VX_NULL;
    vx_status     status            = VX_FAILURE;
    vx_enum       input_format      = TENSOR_DATA_TYPE(inputs_conv);
    vx_enum       cell_format       = TENSOR_DATA_TYPE(cell_state_in);
    vx_enum       output_format     = TENSOR_DATA_TYPE(output);
    vx_uint32     num_units         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int8       dstFixPointPos    = TENSOR_POS(output);
    vx_uint32     paramNum          = 6;
    vx_float32    outputZP          = 0;
    vx_float32    outputScale       = 1.0f;
    vx_tensor     biases_rs         = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input_conv=%p, output=%p",
        context, kernelEnum, borderMode, inputs_conv, output);

    if (TENSOR_DIM_NUM(biases) == 1)
    {
        vx_int32 sizes[4] = {1};

        sizes[0]      = TENSOR_VIEW_SIZE_INDEX(biases, 0);
        sizes[1]      = 1;

        biases_rs     = vxoTensor_ReshapeTensor(biases, sizes, 2);

        parameters[2] = (vx_reference)biases_rs;
    }

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        outputScale = 1.0f / TENSOR_TF_SCALE(output);
        outputZP    = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (dstFixPointPos >= 0)
            outputScale *= (vx_float32)(1 << dstFixPointPos);
        else if (dstFixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
    }

    if (hidden_state_out)
        parameters[paramNum ++] = (vx_reference)hidden_state_out;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitStateOutExt, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitStateOutExt.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/

        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnitExt", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16)
    {
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };
        vx_uint32 uniFp16AddFp16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };

        if (cell_format == VX_TYPE_FLOAT16)
        {
            if (output_format == VX_TYPE_FLOAT16)
            {
                if (hidden_state_out)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16", borderMode);
                else
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16_Projection", borderMode);
            }
            else if (output_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F16", borderMode);
            else if (output_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F16", borderMode);
            else if (output_format == VX_TYPE_UINT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F16", borderMode);

            if (!shaderExecutable) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (cell_format == VX_TYPE_FLOAT32)
        {
            if (output_format == VX_TYPE_FLOAT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F32_Projection", borderMode);
            else if (output_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F32_Projection", borderMode);
            else if (output_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F32_Projection", borderMode);
            else if (output_format == VX_TYPE_UINT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F32_Projection", borderMode);

            if (!shaderExecutable) goto OnError;
        }

        if (output_format == VX_TYPE_FLOAT16)
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtract8Data_2x8", 1, uniExtractHalf8_2x8);
        else
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtract8Data_2x8", 1, uniExtractInteger_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (biases_rs) vxoTensor_ReleaseTensor(&biases_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (biases_rs) vxoTensor_ReleaseTensor(&biases_rs);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/************************vxcTensorPad*****************************************************************/
vxnne_shader_executable vxnneGetTensorPadShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               inputs,
    vx_scalar               padLeft,
    vx_scalar               padRight,
    vx_scalar               padTop,
    vx_scalar               padBottom,
    vx_scalar               padMode,
    vx_scalar               padConst,
    vx_tensor               outputs)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program                       program              = VX_NULL;
    vx_status                        status               = VX_FAILURE;
    vxnne_shader_executable          shaderExecutable     = VX_NULL;
    vxnne_kernel_shaders             kernel               = NULL;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference  parameters[6]             = {(vx_reference)inputs, (vx_reference)padLeft, (vx_reference)padRight,
                                               (vx_reference)padTop, (vx_reference)padBottom, (vx_reference)outputs};
    vx_uint32     input_width                = TENSOR_VIEW_SIZE_INDEX(inputs, 0);
    vx_uint32     input_height               = TENSOR_VIEW_SIZE_INDEX(inputs, 1);
    vx_uint32     input_depth                = TENSOR_VIEW_SIZE_INDEX(inputs, 2);
    vx_uint32     output_width               = TENSOR_VIEW_SIZE_INDEX(outputs, 0);
    vx_uint32     output_height              = TENSOR_VIEW_SIZE_INDEX(outputs, 1);
    vx_uint32     output_depth               = TENSOR_VIEW_SIZE_INDEX(outputs, 2);
    vx_enum       inputFormat                = TENSOR_DATA_TYPE(inputs);
    vx_uint32     inputElementSize           = TENSOR_DATA_SIZE(inputs);
    vx_enum       padModev                   = padMode->value->e;
    vx_int32      padConstv                  = padConst->value->n32;
    vx_uint32     padLeftv                   = padLeft->value->u32;
    vx_uint32     padRightv                  = padRight->value->u32;
    vx_uint32     padTopv                    = padTop->value->u32;
    vx_uint32     padBottomv                 = padBottom->value->u32;
    vx_uint32     maxWorkGroupSize           = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, inputs=%p, outputs=%p",
         context, kernelEnum, borderMode, inputs, outputs);

    if (input_width + padLeftv + padRightv != output_width ||
        input_height + padTopv + padBottomv != output_height || input_depth != output_depth)
    {
        vxError("The input size not match with the output size! failed at function %s line %d", __FUNCTION__, __LINE__);
        goto OnError;
    }

    if (padModev == VX_PAD_CONSTANT)
    {
        borderMode->mode = VX_BORDER_CONSTANT;
        if (inputFormat == VX_TYPE_FLOAT16 || inputFormat == VX_TYPE_INT16)
            borderMode->constant_value.S16 = (vx_int16)padConstv;
        else if (inputFormat == VX_TYPE_UINT8 || inputFormat == VX_TYPE_INT8)
            borderMode->constant_value.U8 = (vx_uint8)padConstv;
    }
    else if (padModev == VX_PAD_REPLICATE)
    {
        borderMode->mode = VX_BORDER_REPLICATE;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorPad, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorPad.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorPad", program, 6, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (padModev == VX_PAD_CONSTANT || padModev == VX_PAD_REPLICATE)
    {
        if (inputElementSize ==1)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Const8Bits", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (inputElementSize ==2)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Const16Bits", borderMode);
            if (!shaderExecutable) goto OnError;
        }
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    if (inputElementSize == 1)//UINT8,INT8
    {
        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 4;
    }
    else if (inputElementSize == 2)//FLOAT16,INT16
    {
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 4;
    }
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((output_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (output_height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = output_depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 6);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetTFAvgPoolingShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               mask,
    vx_scalar               stride_s,
    vx_scalar               poolSizeX,
    vx_scalar               poolSizeY,
    vx_uint32               pad_x_left,
    vx_uint32               pad_y_top,
    vx_int32                activation,
    vx_tensor               output
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program          = VX_NULL;
    vx_status  status           = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;
    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};

    vx_reference parameters[4]      = {(vx_reference)input, (vx_reference)mask, VX_NULL, (vx_reference)output};
    vx_enum      inputFormat        = TENSOR_DATA_TYPE(input);
    vx_enum      outputFormat       = TENSOR_DATA_TYPE(output);
    vx_uint32    in_height          = TENSOR_VIEW_SIZE_INDEX(input, 1);
    vx_uint32    depth              = TENSOR_VIEW_SIZE_INDEX(input, 2);
    vx_int32     input_ZP           = TENSOR_TF_ZEROPOINT(input);
    vx_uint32    out_width          = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32    out_height         = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int32     output_ZP          = TENSOR_TF_ZEROPOINT(output);
    vx_uint32    stride_v           = stride_s->value->u32;
    vx_uint32    kernel_size_x      = poolSizeX->value->u32;
    vx_uint32    kernel_size_y      = poolSizeY->value->u32;
    vx_uint32    pad_left           = pad_x_left;
    vx_uint32    pad_top            = pad_y_top;
    vx_scalar    in_heights         = NULL;
    vx_tensor    input_rs           = NULL;
    vx_tensor    output_rs          = NULL;
    vx_int8      srcFixPointPos     = TENSOR_POS(input);
    vx_int8      dstFixPointPos     = TENSOR_POS(output);
    vx_float32   scaleIn            = 1.0f;
    vx_float32   scaleOut           = 1.0f;
    vx_uint32    height             = (out_height - 1) * stride_v + kernel_size_y - 2 * pad_top;
    vx_uint32    globalWorkSize1    = 1;
    vx_uint32    maxWorkGroupSize   = 8;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    if (height != in_height)
    {
        if (out_height < height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }
    else
    {
        if (out_height < in_height)
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &in_height);
        else
            in_heights = vxCreateScalar(context, VX_TYPE_INT32, &out_height);
    }

    parameters[2] = (vx_reference)in_heights;

    if (inputFormat == VX_TYPE_INT8)
    {
        if (srcFixPointPos >= 0)
        {
            scaleIn *= 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            scaleIn *= (vx_float32)(1 << -srcFixPointPos);
        }
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        scaleIn *= TENSOR_TF_SCALE(input);
    }

    if (outputFormat == VX_TYPE_INT8)
    {
        if (dstFixPointPos >= 0)
        {
            scaleOut *= (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            scaleOut *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }
    else if (outputFormat == VX_TYPE_UINT8)
    {
        scaleOut *= TENSOR_TF_SCALE(output);
    }

    borderMode->mode = VX_BORDER_CONSTANT;
    if (inputFormat == VX_TYPE_INT8)
    {
        borderMode->constant_value.U8 = 0;
    }
    else if (inputFormat == VX_TYPE_UINT8)
    {
        borderMode->constant_value.U8 = 0;
    }
    else if (inputFormat == VX_TYPE_FLOAT16)
    {
        borderMode->constant_value.S16 = 0;
        borderMode->constant_value.U8 = 0;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TFAvgPooling, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TFAvgPooling.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTFPooling", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (inputFormat == VX_TYPE_UINT8 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_UINT8))
    {
        vx_uint8     minVal               = 0;
        vx_uint8     maxVal               = 0;
        vx_uint32    minData              = 0;
        vx_uint32    maxData              = 0;
        vx_float32   uint8qScale_out      = 1.0f / scaleOut;
        vx_float32   output_zeroPoint     = (vx_float32)output_ZP;
        vx_float32   input_zeroPoint      = (vx_float32)input_ZP;
        vx_int32 kernelsize[2]            = {kernel_size_x, kernel_size_y};
        vx_int32 padding[2]               = {pad_left, pad_top};
        vx_int32 stride[2]                = {stride_v, stride_v};
        vx_int32 x_len_8x                 = kernel_size_x / 8 * 8;
        vx_int32 x_len_remain             = kernel_size_x - x_len_8x;
        vx_int32 enable_uint8_format      = outputFormat == VX_TYPE_UINT8 ? 1 : 0;

        vx_uint32 uniAcc8U8_8x2[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };

        vx_uint32 uniUInt8Config[8] = {0x00000000, 0x00010001, 0x00050005 ,0x00150015, 0x00550055, 0x01550155, 0x05550555, 0x15551555};

        vx_uint32 uniAccNU8_8x2[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };

        calculateActivationRangeUInt8(activation, TENSOR_TF_SCALE(output), TENSOR_TF_ZEROPOINT(output), &minVal, &maxVal, 0, 65536);

        minData = (vx_uint32)minVal;
        maxData = (vx_uint32)maxVal;

        uniAccNU8_8x2[0] = uniUInt8Config[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_uint8", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8U8_8x2", 1, uniAcc8U8_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNU8_8x2", 1, uniAccNU8_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_uint8_format", 1, &enable_uint8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &scaleIn);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_ZP", 1, &input_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uint8qScale_out", 1, &uint8qScale_out);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_zeroPoint);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "minData", 1, &minData);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "maxData", 1, &maxData);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (inputFormat == VX_TYPE_FLOAT16 && (outputFormat == VX_TYPE_FLOAT16 || outputFormat == VX_TYPE_INT8))
    {
        vx_float32    genericAvgScale     = scaleOut;
        vx_int32 kernelsize[2]            = {kernel_size_x, kernel_size_y};
        vx_int32 padding[2]               = {pad_left, pad_top};
        vx_int32 stride[2]                = {stride_v, stride_v};
        vx_int32 x_len_8x                 = kernel_size_x / 8 * 8;
        vx_int32 x_len_remain             = kernel_size_x - x_len_8x;
        vx_int32 enable_int8_format       = outputFormat == VX_TYPE_INT8 ? 1 : 0;
        vx_uint32 uniAcc8Data_8x2[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };

        vx_uint32 uniConfig[8] = {0x00000000, 0x00010001, 0x00050005 ,0x00150015, 0x00550055, 0x01550155, 0x05550555, 0x15551555};

        vx_uint32 uniAccNData_8x2[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };
        uniAccNData_8x2[0] = uniConfig[x_len_remain];

        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        globalWorkSize1                          = out_height;

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_generic_fp16", borderMode);
        if (!shaderExecutable) goto OnError;
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAcc8Data_8x2", 1, uniAcc8Data_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniAccNData_8x2", 1, uniAccNData_8x2);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride", 1, stride);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "padding", 1, padding);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "kernelsize", 1, kernelsize);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_8x", 1, &x_len_8x);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "x_len_remain", 1, &x_len_remain);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "enable_int8_format", 1, &enable_int8_format);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "genericAvgScale", 1, &genericAvgScale);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_GetMaxWorkGroupSize(shaderExecutable, &maxWorkGroupSize);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.workDim = 3;
    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((out_width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = globalWorkSize1 == 1 ? 1 : (globalWorkSize1  + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = depth;


    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 4);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (in_heights) vxReleaseScalar(&in_heights);
    if (input_rs) vxoTensor_ReleaseTensor(&input_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitHiddenOut_PackedShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_bool                 enable_cell_in,
    vx_tensor               input_conv,
    vx_float32              forget_bias,
    vx_tensor               cell_state_in,
    vx_tensor               output,
    vx_tensor               cell_state_out,
    vx_tensor               hidden_state_out,
    vx_tensor               hidden_conv)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength      = 0;
#endif
    vx_reference  parameters[6]   = {(vx_reference)input_conv, (vx_reference)cell_state_in, (vx_reference)output, (vx_reference)NULL, (vx_reference)NULL, (vx_reference)NULL};
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vxnne_kernel_shaders    kernel           = VX_NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vx_program    program           = VX_NULL;
    vx_status     status            = VX_FAILURE;
    vx_enum       input_format      = TENSOR_DATA_TYPE(input_conv);
    vx_uint32     num_units         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_uint32     paramNum          = 3;
    vx_int8       input_fl          = TENSOR_POS(input_conv);
    vx_int8       hidden_in_fl      = hidden_conv ? TENSOR_POS(hidden_conv) : 1;
    vx_float32    hidden_outScale   = 1.0f;
    vx_float32    outputScale       = 1.0f;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input_conv=%p, output=%p",
         context, kernelEnum, borderMode, input_conv, output);

    if (hidden_state_out &&  TENSOR_QUANT_TYPE(hidden_state_out) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8 fixPointPos = TENSOR_POS(hidden_state_out);

        if (fixPointPos >= 0)
            hidden_outScale *= (vx_float32)(1 << fixPointPos);
        else if (fixPointPos < 0)
            hidden_outScale *= 1.0f / (vx_float32) (1 << -fixPointPos);
    }

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_int8 fixPointPos = TENSOR_POS(output);

        if (fixPointPos >= 0)
            outputScale *= (vx_float32)(1 << fixPointPos);
        else if (fixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -fixPointPos);
    }

    if (cell_state_out)
        parameters[paramNum ++] = (vx_reference)cell_state_out;

    if (hidden_state_out)
        parameters[paramNum ++] = (vx_reference)hidden_state_out;

    if (hidden_conv)
        parameters[paramNum ++] = (vx_reference)hidden_conv;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitHiddenOut_Packed, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitHiddenOut_Packed.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/

        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnitHiddenOut", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16)
    {
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE            = 2 * logE;
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16AddFp16toFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00110000, 0x00330022, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };

        if (paramNum == 3 && !enable_cell_in)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P3", borderMode);
        else if (paramNum == 3 && enable_cell_in)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P3_cell", borderMode);
        else if (paramNum == 4 && hidden_conv)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P4_I", borderMode);
        else if (paramNum == 4 && hidden_state_out)
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Fp16_P4_O", borderMode);

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16AddFp16toFp32_4x4", 1, uniFp16AddFp16toFp32_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        if (status != VX_SUCCESS) goto OnError;
    }
    else  if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        vx_float32     logE                 = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE              = 2 * logE;
        vx_uint32 uniExtractDft16_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDft8toFp32_part0_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00040000, 0x000c0008, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8toFp32_part1_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050001, 0x000d0009, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8toFp32_part2_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00060002, 0x000e000a, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8toFp32_part3_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00070003, 0x000f000b, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8AddDft8toFp32_part0_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00440000, 0x00cc0088, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8AddDft8toFp32_part1_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00550011, 0x00dd0099, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8AddDft8toFp32_part2_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00660022, 0x00ee00aa, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };
        vx_uint32 uniDft8AddDft8toFp32_part3_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00770033, 0x00ff00bb, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000, 0x00020001, 0x00000000 // Constant
        };


        if (paramNum == 3 && !enable_cell_in)
        {
            uniDft8toFp32_part0_4x4[7] = uniDft8toFp32_part0_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part1_4x4[7] = uniDft8toFp32_part1_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part2_4x4[7] = uniDft8toFp32_part2_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part3_4x4[7] = uniDft8toFp32_part3_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P3", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P3", borderMode);
        }
        else if (paramNum == 3 && enable_cell_in)
        {
            uniDft8toFp32_part0_4x4[7] = uniDft8toFp32_part0_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part1_4x4[7] = uniDft8toFp32_part1_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part2_4x4[7] = uniDft8toFp32_part2_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part3_4x4[7] = uniDft8toFp32_part3_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P3_cell", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P3_cell", borderMode);
        }
        else if (paramNum == 4 && hidden_conv)
        {
            vx_uint16 mulVal        = 1 << abs(hidden_in_fl - input_fl);
            vx_int8   postShift     = (hidden_in_fl > input_fl) ? hidden_in_fl : input_fl;
            vx_uint32 constants     = (hidden_in_fl > input_fl) ? ((1 << 16) | mulVal) : ((mulVal << 16) | 1);

            uniDft8AddDft8toFp32_part0_4x4[7] = uniDft8AddDft8toFp32_part0_4x4[7] | (postShift & 0x1F);
            uniDft8AddDft8toFp32_part1_4x4[7] = uniDft8AddDft8toFp32_part1_4x4[7] | (postShift & 0x1F);
            uniDft8AddDft8toFp32_part2_4x4[7] = uniDft8AddDft8toFp32_part2_4x4[7] | (postShift & 0x1F);
            uniDft8AddDft8toFp32_part3_4x4[7] = uniDft8AddDft8toFp32_part3_4x4[7] | (postShift & 0x1F);

            uniDft8AddDft8toFp32_part0_4x4[8]  = uniDft8AddDft8toFp32_part0_4x4[10] = constants;
            uniDft8AddDft8toFp32_part0_4x4[12] = uniDft8AddDft8toFp32_part0_4x4[14] = constants;
            uniDft8AddDft8toFp32_part1_4x4[8]  = uniDft8AddDft8toFp32_part1_4x4[10] = constants;
            uniDft8AddDft8toFp32_part1_4x4[12] = uniDft8AddDft8toFp32_part1_4x4[14] = constants;
            uniDft8AddDft8toFp32_part2_4x4[8]  = uniDft8AddDft8toFp32_part2_4x4[10] = constants;
            uniDft8AddDft8toFp32_part2_4x4[12] = uniDft8AddDft8toFp32_part2_4x4[14] = constants;
            uniDft8AddDft8toFp32_part3_4x4[8]  = uniDft8AddDft8toFp32_part3_4x4[10] = constants;
            uniDft8AddDft8toFp32_part3_4x4[12] = uniDft8AddDft8toFp32_part3_4x4[14] = constants;

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P4_I", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P4_I", borderMode);
        }
        else if (paramNum == 4 && hidden_state_out)
        {
            uniDft8toFp32_part0_4x4[7] = uniDft8toFp32_part0_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part1_4x4[7] = uniDft8toFp32_part1_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part2_4x4[7] = uniDft8toFp32_part2_4x4[7] | (input_fl & 0x1F);
            uniDft8toFp32_part3_4x4[7] = uniDft8toFp32_part3_4x4[7] | (input_fl & 0x1F);

            if (input_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int16_P4_O", borderMode);
            else if (input_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_Int8_P4_O", borderMode);
        }

        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractDft16_2x8", 1, uniExtractDft16_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8toFp32_part0_4x4", 1, uniDft8toFp32_part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8toFp32_part2_4x4", 1, uniDft8toFp32_part2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8toFp32_part3_4x4", 1, uniDft8toFp32_part3_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8AddDft8toFp32_part0_4x4", 1, uniDft8AddDft8toFp32_part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8AddDft8toFp32_part1_4x4", 1, uniDft8AddDft8toFp32_part1_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8AddDft8toFp32_part2_4x4", 1, uniDft8AddDft8toFp32_part2_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDft8AddDft8toFp32_part3_4x4", 1, uniDft8AddDft8toFp32_part3_4x4);
        if (status != VX_SUCCESS) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 16;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units * 4 + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcTensorAdd****************************************************/
vxnne_shader_executable vxnneGetTensorAddShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input0,
    vx_tensor               input1,
    vx_scalar               scale_s,
    vx_scalar               convertPolicy,
    vx_int32                activation,
    vx_enum                 operation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {1, 1, 1}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]         = {(vx_reference)input0, (vx_reference)input1, (vx_reference)output, (vx_reference)NULL};
    vx_enum       policyEnum            = convertPolicy->value->e;
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(output, 2) : 1;
    vx_uint32     batch                 = dims > 3 ? TENSOR_VIEW_SIZE_INDEX(output, 3) : 1;
    vx_uint32     depth0                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input0, 2) : 1;
    vx_uint32     depth1                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input1, 2) : 1;
    vx_enum       input0_format         = TENSOR_DATA_TYPE(input0);
    vx_enum       input1_format         = TENSOR_DATA_TYPE(input1);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_tensor     src0                  = NULL;
    vx_tensor     src1                  = NULL;
    vx_tensor     dst                   = NULL;
    vx_float32    input_scale0          = TENSOR_TF_SCALE(input0);
    vx_float32    input_scale1          = TENSOR_TF_SCALE(input1);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP0              = TENSOR_TF_ZEROPOINT(input0);
    vx_int32      inputZP1              = TENSOR_TF_ZEROPOINT(input1);
    vx_float32    outputZP              = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_int8       dstFixPointPos        = 0;
    vx_uint32     paramNum              = 3;
    vx_bool       enable_broadcast      = vx_false_e;
    vx_bool       enable_broadcast_Z    = vx_false_e;
    vx_bool       useImage2DFlag        = (vx_bool)((width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH);
    vx_bool       enable_2d_inst        = vx_false_e;
    vx_bool       enable_data_type      = vx_false_e;
    vx_uint32     wksizes[3]            = {width, height, depth};
    vx_tensor     input0_rs             = NULL;
    vx_tensor     input1_rs             = NULL;
    vx_tensor     output_rs             = NULL;
    vx_bool       inputSwap             = vx_false_e;
    vx_uint32     i                     = 0;

    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input0=%p, input1=%p, output=%p",
         context, kernelEnum, borderMode, input0, input1, output);

    for (i = 0; i < TENSOR_DIM_NUM(output); i++)
    {
        vx_uint32 size0 = TENSOR_DIM_NUM(input0) > i ? TENSOR_VIEW_SIZE_INDEX(input0, i) : 1;
        vx_uint32 size1 = TENSOR_DIM_NUM(input1) > i ? TENSOR_VIEW_SIZE_INDEX(input1, i) : 1;

        if (size0 != size1)
        {
            enable_broadcast = vx_true_e;
            break;
        }
    }
    enable_broadcast_Z  = (vx_bool)(enable_broadcast && (depth0 != depth1));

    enable_data_type = ((input0_format == VX_TYPE_INT8 && (input1_format == VX_TYPE_INT8 || input1_format == VX_TYPE_FLOAT16) && output_format == VX_TYPE_INT8) || (input0_format == VX_TYPE_INT16 && input1_format == VX_TYPE_INT16 && output_format == VX_TYPE_INT16));


    enable_2d_inst = (vx_bool)((useImage2DFlag || (depth == 1)) && (!enable_broadcast) && (operation == VX_TENSOR_OP_ADD) && enable_data_type && (policyEnum == VX_CONVERT_POLICY_SATURATE)) ;

    borderMode->mode = VX_BORDER_REPLICATE;

    if (input0_format == VX_TYPE_INT8 || input0_format == VX_TYPE_INT16)
    {
        vx_int8   input0_fixedPointPos    = TENSOR_POS(input0);
        if (input0_fixedPointPos >= 0)
        {
            input_scale0 = 1.0f / (vx_float32) (1 << input0_fixedPointPos);
        }
        else if (input0_fixedPointPos < 0)
        {
            input_scale0 = (vx_float32) (1 << -input0_fixedPointPos);
        }

        inputZP0 = 0;
    }
    else if (input0_format == VX_TYPE_FLOAT16)
    {
        input_scale0    = 1.0f;
        inputZP0        = 0;
    }
    else if (input0_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input0) ==VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
            vx_int8   input0_fixedPointPos    = TENSOR_POS(input0);
            if (input0_fixedPointPos >= 0)
            {
                input_scale0 = 1.0f / (vx_float32) (1 << input0_fixedPointPos);
            }
            else if (input0_fixedPointPos < 0)
            {
                input_scale0 = (vx_float32) (1 << -input0_fixedPointPos);
            }
            inputZP0 = 0;
        }
    }

    if (input1_format == VX_TYPE_INT8 || input1_format == VX_TYPE_INT16)
    {
        vx_int8   input1_fixedPointPos    = TENSOR_POS(input1);
        if (input1_fixedPointPos >= 0)
        {
            input_scale1 = 1.0f / (vx_float32) (1 << input1_fixedPointPos);
        }
        else if (input1_fixedPointPos < 0)
        {
            input_scale1 = (vx_float32) (1 << -input1_fixedPointPos);
        }

        inputZP1 = 0;
    }
    else if (input1_format == VX_TYPE_FLOAT16)
    {
        input_scale1    = 1.0f;
        inputZP1        = 0;
    }
    else if (input1_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input1) == VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
            vx_int8   input1_fixedPointPos    = TENSOR_POS(input1);
            if (input1_fixedPointPos >= 0)
            {
                input_scale1 = 1.0f / (vx_float32) (1 << input1_fixedPointPos);
            }
            else if (input1_fixedPointPos < 0)
            {
                input_scale1 = (vx_float32) (1 << -input1_fixedPointPos);
            }
            inputZP1 = 0;
        }
    }

    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        dstFixPointPos    = TENSOR_POS(output);
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }

        outputZP = 0;
    }
    else if (output_format == VX_TYPE_FLOAT16)
    {
        output_scale    = 1.0f;
        outputZP        = 0;
    }
    else if (output_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT )
        {
            outputZP = 0;
            dstFixPointPos    = TENSOR_POS(output);
            if (dstFixPointPos >= 0)
            {
                output_scale = (vx_float32) (1 << dstFixPointPos);
            }
            else if (dstFixPointPos < 0)
            {
                output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
            }
        }
        else
        {
            output_scale = 1 / output_scale;
        }
    }

    if (operation == VX_TENSOR_OP_ADD)
    {
        input_scale0 = input_scale0 * output_scale;
        input_scale1 = input_scale1 * output_scale;
    }
    else if (operation == VX_TENSOR_OP_SUB)
    {
        input_scale0 = input_scale0 * output_scale;
        input_scale1 = input_scale1 * output_scale * -1.0f;
    }

    if (TENSOR_DIM_NUM(input0) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        src0 = vxoTensor_ReshapeTensor(input0, sizes, dims);
        parameters[0] = (vx_reference)src0;
    }

    if (TENSOR_DIM_NUM(input1) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        src1 = vxoTensor_ReshapeTensor(input1, sizes, dims);
        parameters[1] = (vx_reference)src1;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(output, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        dst = vxoTensor_ReshapeTensor(output, sizes, dims);
        parameters[2] = (vx_reference)dst;
    }

    if (useImage2DFlag)
    {
        vx_int8  input0_fl  = TENSOR_POS(input0);
        vx_int8  input1_fl  = TENSOR_POS(input1);
        vx_int32 sizes[4]   = {width * height, depth, 1, batch};

        wksizes[0] = width * height;
        wksizes[1] = depth;
        wksizes[2] = 1;

        if (((input0_fl >= input1_fl) && TENSOR_QUANT_TYPE(input0) == TENSOR_QUANT_TYPE(input1)) || (input0_format != input1_format))
        {
            input0_rs = vxoTensor_ReshapeTensor(input0, sizes, dims);
            input1_rs = vxoTensor_ReshapeTensor(input1, sizes, dims);
        }
        else
        {
            input0_rs = vxoTensor_ReshapeTensor(input1, sizes, dims);
            input1_rs = vxoTensor_ReshapeTensor(input0, sizes, dims);
            inputSwap = vx_true_e;
        }

        output_rs = vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)input0_rs;
        parameters[1] = (vx_reference)input1_rs;
        parameters[2] = (vx_reference)output_rs;
    }
    else if (enable_broadcast_Z)
    {
        if (depth0 == 1)
        {
            parameters[0] = src1 ? (vx_reference)src1 : (vx_reference)input1;
            parameters[1] = src0 ? (vx_reference)src0 : (vx_reference)input0;
            inputSwap = vx_true_e;
        }
    }

    if (inputSwap)
    {
        vx_float32 tmpScale;
        vx_int32   tmpZP;

        tmpScale     = input_scale0;
        input_scale0 = input_scale1;
        input_scale1 = tmpScale;

        tmpZP        = inputZP0;
        inputZP0     = inputZP1;
        inputZP1     = tmpZP;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorAdd, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorAdd.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorEltwise", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (enable_2d_inst)
    {
        vx_int8 fla = TENSOR_POS((vx_tensor)parameters[0]);
        vx_int8 flb = TENSOR_POS((vx_tensor)parameters[1]);
        vx_int8 flc = TENSOR_POS((vx_tensor)parameters[2]);
        vx_uint32 uniInt8AddInt8Lo_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000600, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001 // Constant
        };
        vx_uint32 uniInt8AddInt8Hi_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0xbbaa9988, 0xffeeddcc, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000600, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniInt8AddFp16Lo_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001 // Constant
        };
        vx_uint32 uniInt8AddFp16Hi_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x3b2a1908, 0x7f6e5d4c, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001, 0x00020001 // Constant
        };

        if (TENSOR_QUANT_TYPE(input1) == VX_QUANT_DYNAMIC_FIXED_POINT)
        {
            if (fla >= flc)
            {
                vx_uint8  postshift      = gcmMIN(fla - flc, MAX_POST_SHIFT_BITS);
                vx_uint32 multiply       = ((1 << (fla - flb)) << 16) | 1;
                vx_uint32 i              = 0;

                uniInt8AddInt8Lo_2x8[7] = uniInt8AddInt8Lo_2x8[7] | (postshift & 0x1F);
                uniInt8AddInt8Hi_2x8[7] = uniInt8AddInt8Hi_2x8[7] | (postshift & 0x1F);

                for (i = 8; i < 16; i++)
                {
                    uniInt8AddInt8Lo_2x8[i] = multiply;
                    uniInt8AddInt8Hi_2x8[i] = multiply;
                }
            }
            else
            {
                vx_uint32 m0             = gcmMIN(1 << (flc - flb), MAX_MULTIPLIER_NUM);
                vx_uint32 m1             = gcmMIN(1 << (flc - fla), MAX_MULTIPLIER_NUM);
                vx_uint32 multiply       = ((m0 << 16) | m1);
                vx_uint32 i              = 0;

                for (i = 8; i < 16; i++)
                {
                    uniInt8AddInt8Lo_2x8[i] = multiply;
                    uniInt8AddInt8Hi_2x8[i] = multiply;
                }
            }
        }
        else if (input1_format == VX_TYPE_FLOAT16)
        {
            vx_uint32 multiply       = ((1 << flc) << 16) | (1 << (flc - fla));
            vx_uint32 i              = 0;
            vx_uint8  postshift      = 0;

            if (flc >= fla)
            {
                if (flc >= 0)
                {
                    multiply       = (((vx_uint16)Fp32toFp16((vx_float32)(1 << flc))) << 16) | ((vx_uint16)Fp32toFp16((vx_float32)(1 << (flc - fla))));
                }
                else
                {
                    multiply       = (0x3c00 << 16) | ((vx_uint16)Fp32toFp16((vx_float32)(1 << (- fla))));
                    postshift      = -flc;
                }
            }
            else
            {
                if (flc >= 0 || (flc < 0 && fla >= 0))
                {
                    multiply       = (((vx_uint16)Fp32toFp16((vx_float32)(1 << fla))) << 16) | (0x3c00);
                    postshift      = fla - flc;
                }
                else
                {
                    multiply       = (0x3c00 << 16) | ((vx_uint16)Fp32toFp16((vx_float32)(1 << (- fla))));
                    postshift      = - flc;
                }
            }

            postshift      = gcmMIN(postshift, MAX_POST_SHIFT_BITS);

            uniInt8AddFp16Lo_2x8[7] = uniInt8AddFp16Lo_2x8[7] | (postshift & 0x1F);
            uniInt8AddFp16Hi_2x8[7] = uniInt8AddFp16Hi_2x8[7] | (postshift & 0x1F);

            for (i = 8; i < 16; i++)
            {
                uniInt8AddFp16Lo_2x8[i] = multiply;
                uniInt8AddFp16Hi_2x8[i] = multiply;
            }
        }

        if (input1_format == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8AddI8ToI8_best", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else if (input1_format == VX_TYPE_INT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16AddI16ToI16_best", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8AddF16ToI8_best", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Lo_2x8", 1, uniInt8AddInt8Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddInt8Hi_2x8", 1, uniInt8AddInt8Hi_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddFp16Lo_2x8", 1, uniInt8AddFp16Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniInt8AddFp16Hi_2x8", 1, uniInt8AddFp16Hi_2x8);
        vxmONERROR_STATUS(status);

        if (input0_format == VX_TYPE_INT8)
            execution_parameters.globalWorkScale[0]  = 16;
        else
            execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }
    else
    {
        char kernelName[1024];
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part0_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part1_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        switch (input0_format)
        {
        case VX_TYPE_FLOAT16:
            sprintf(kernelName, "_Fp16");
            break;
        case VX_TYPE_INT8:
            sprintf(kernelName, "_Int8");
            break;
        case VX_TYPE_UINT8:
            sprintf(kernelName, "_UInt8");
            break;
        case VX_TYPE_INT16:
            sprintf(kernelName, "_Int16");
            break;
        default:
            break;
        }

        switch (operation)
        {
        case VX_TENSOR_OP_ADD:
        case VX_TENSOR_OP_SUB:
            strcat(kernelName, "Add" );
            break;
        case VX_TENSOR_OP_MUL:
            strcat(kernelName, "Mul" );
            break;
        case VX_TENSOR_OP_DIV:
            strcat(kernelName, "Div" );
            break;
        default:
            break;
        }

        switch (input1_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "Fp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "Int8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "UInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "Int16" );
            break;
        default:
            break;
        }

        switch (output_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "toFp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "toInt8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "toUInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "toInt16" );
            break;
        default:
            break;
        }

        if (enable_broadcast_Z)
        {
            switch (policyEnum)
            {
            case VX_CONVERT_POLICY_SATURATE:
                strcat(kernelName, "_Sat_Z_func" );
                break;
            case VX_CONVERT_POLICY_WRAP:
                strcat(kernelName, "_Warp_Z_func" );
                break;
            default:
                break;
            }
        }
        else
        {
            switch (policyEnum)
            {
            case VX_CONVERT_POLICY_SATURATE:
                strcat(kernelName, "_Sat_func" );
                break;
            case VX_CONVERT_POLICY_WRAP:
                strcat(kernelName, "_Warp_func" );
                break;
            default:
                break;
            }
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale0", 1, &input_scale0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale1", 1, &input_scale1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP0", 1, &inputZP0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP1", 1, &inputZP1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part0_4x4", 1, uniDataSubZPtoFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part1_4x4", 1, uniDataSubZPtoFp32Part1_4x4);
        if (output_format == VX_TYPE_FLOAT16)
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtractHalf8_2x8);
        else
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
    }

    execution_parameters.globalWorkSize[0]   = gcmALIGN((wksizes[0] + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (wksizes[1] + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = wksizes[2];

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (input0_rs) vxoTensor_ReleaseTensor(&input0_rs);
    if (input1_rs) vxoTensor_ReleaseTensor(&input1_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (input0_rs) vxoTensor_ReleaseTensor(&input0_rs);
    if (input1_rs) vxoTensor_ReleaseTensor(&input1_rs);
    if (output_rs) vxoTensor_ReleaseTensor(&output_rs);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}
/********vxcTensorMul****************************************************/
vxnne_shader_executable vxnneGetTensorMulShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input0,
    vx_tensor               input1,
    vx_scalar               scale_s,
    vx_scalar               convertPolicy,
    vx_scalar               round,
    vx_int32                activation,
    vx_enum                 operation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]         = {(vx_reference)input0, (vx_reference)input1, (vx_reference)output, (vx_reference)NULL};
    vx_enum       policyEnum            = convertPolicy->value->e;
    vx_enum       roundingEnum          = round->value->e;
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(output, 2) : 1;
    vx_uint32     batch                 = dims > 3 ? TENSOR_VIEW_SIZE_INDEX(output, 3) : 1;
    vx_uint32     depth0                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input0, 2) : 1;
    vx_uint32     depth1                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input1, 2) : 1;
    vx_enum       input0_format         = TENSOR_DATA_TYPE(input0);
    vx_enum       input1_format         = TENSOR_DATA_TYPE(input1);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_tensor     src0                  = NULL;
    vx_tensor     src1                  = NULL;
    vx_tensor     dst                   = NULL;
    vx_float32    input_scale           = 1.0f;
    vx_float32    input_scale0          = TENSOR_TF_SCALE(input0);
    vx_float32    input_scale1          = TENSOR_TF_SCALE(input1);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP0              = TENSOR_TF_ZEROPOINT(input0);
    vx_int32      inputZP1              = TENSOR_TF_ZEROPOINT(input1);
    vx_float32    outputZP              = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_int8       src0FixPointPos       = 0;
    vx_int8       src1FixPointPos       = 0;
    vx_int8       dstFixPointPos        = 0;
    vx_uint32     paramNum              = 3;
    vx_bool       useImage2DFlag        = vx_false_e;/* optimize dfp8 & sum(input fl) > output fl */
    vx_bool       enable_broadcast      = vx_false_e;
    vx_bool       enable_broadcast_Z    = vx_false_e;
    vx_bool       inputSwap             = vx_false_e;
    vx_uint32     i                     = 0;

    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input0=%p, input1=%p, output=%p",
         context, kernelEnum, borderMode, input0, input1, output);

    for (i = 0; i < TENSOR_DIM_NUM(output); i++)
    {
        vx_uint32 size0 = TENSOR_DIM_NUM(input0) > i ? TENSOR_VIEW_SIZE_INDEX(input0, i) : 1;
        vx_uint32 size1 = TENSOR_DIM_NUM(input1) > i ? TENSOR_VIEW_SIZE_INDEX(input1, i) : 1;

        if (size0 != size1)
        {
            enable_broadcast = vx_true_e;
            break;
        }
    }

    enable_broadcast_Z  = (vx_bool)(enable_broadcast && (depth0 != depth1));

    borderMode->mode = VX_BORDER_REPLICATE;

    if (input0_format == VX_TYPE_INT8 || input0_format == VX_TYPE_INT16)
    {
        src0FixPointPos    = TENSOR_POS(input0);
        if (src0FixPointPos >= 0)
        {
            input_scale0 = 1.0f / (vx_float32) (1 << src0FixPointPos);
        }
        else if (src0FixPointPos < 0)
        {
            input_scale0 = (vx_float32) (1 << -src0FixPointPos);
        }

        inputZP0 = 0;
    }
    else if (input0_format == VX_TYPE_FLOAT16)
    {
        input_scale0    = 1.0f;
        inputZP0        = 0;
    }
    else if (input0_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input0) == VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
            vx_int8   input0_fixedPointPos    = TENSOR_POS(input0);
            if (input0_fixedPointPos >= 0)
            {
                input_scale0 = 1.0f / (vx_float32) (1 << input0_fixedPointPos);
            }
            else if (input0_fixedPointPos < 0)
            {
                input_scale0 = (vx_float32) (1 << -input0_fixedPointPos);
            }
            inputZP0        = 0;
        }
    }

    if (input1_format == VX_TYPE_INT8 || input1_format == VX_TYPE_INT16)
    {
        src1FixPointPos    = TENSOR_POS(input1);
        if (src1FixPointPos >= 0)
        {
            input_scale1 = 1.0f / (vx_float32) (1 << src1FixPointPos);
        }
        else if (src1FixPointPos < 0)
        {
            input_scale1 = (vx_float32) (1 << -src1FixPointPos);
        }

        inputZP1 = 0;
    }
    else if (input1_format == VX_TYPE_FLOAT16)
    {
        input_scale1    = 1.0f;
        inputZP1        = 0;
    }
    else if (input1_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input1) == VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
             vx_int8   input1_fixedPointPos    = TENSOR_POS(input1);
            if (input1_fixedPointPos >= 0)
            {
                input_scale1 = 1.0f / (vx_float32) (1 << input1_fixedPointPos);
            }
            else if (input1_fixedPointPos < 0)
            {
                input_scale1 = (vx_float32) (1 << -input1_fixedPointPos);
            }
            inputZP1        = 0;
        }
    }

    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        dstFixPointPos    = TENSOR_POS(output);
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }

        outputZP = 0;
    }
    else if (output_format == VX_TYPE_FLOAT16)
    {
        output_scale    = 1.0f;
        outputZP        = 0;
    }
    else if (output_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT )
        {
            dstFixPointPos    = TENSOR_POS(output);
            if (dstFixPointPos >= 0)
            {
                output_scale = (vx_float32) (1 << dstFixPointPos);
            }
            else if (dstFixPointPos < 0)
            {
                output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
            }
            outputZP = 0.0f;
        }
        else
        {
            output_scale = 1 / output_scale;
        }
    }

    if (operation == VX_TENSOR_OP_MUL)
    {
        input_scale     = input_scale0 * input_scale1 * output_scale;

        parameters[3]   = (vx_reference)scale_s;
        paramNum        = 4;
    }

    if (TENSOR_DIM_NUM(input0) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        src0 = vxoTensor_ReshapeTensor(input0, sizes, dims);
        parameters[0] = (vx_reference)src0;
    }

    if (TENSOR_DIM_NUM(input1) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        src1 = vxoTensor_ReshapeTensor(input1, sizes, dims);
        parameters[1] = (vx_reference)src1;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(output, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        dst = vxoTensor_ReshapeTensor(output, sizes, dims);
        parameters[2] = (vx_reference)dst;
    }

    if (input0_format == input1_format && input0_format == VX_TYPE_INT8 && output_format == VX_TYPE_INT8
        && scale_s->value->f32 == 1.0f && (width * height < IMG_MAX_WIDTH) && depth < IMG_MAX_WIDTH)
    {
        vx_uint32     dims0                 = TENSOR_DIM_NUM(input0);
        vx_uint32     width0                = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_uint32     height0               = dims0 > 1 ? TENSOR_VIEW_SIZE_INDEX(input0, 1) : 1;
        vx_uint32     dims1                 = TENSOR_DIM_NUM(input1);
        vx_uint32     width1                = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_uint32     height1               = dims1 > 1 ? TENSOR_VIEW_SIZE_INDEX(input1, 1) : 1;

        if (width0 == width1 && height0 == height1 && (src0FixPointPos + src1FixPointPos >= dstFixPointPos)
            && policyEnum == VX_CONVERT_POLICY_SATURATE)
        {
            useImage2DFlag = vx_true_e;
        }
    }

    if (useImage2DFlag)
    {
        vx_uint32     dims0                 = TENSOR_DIM_NUM(input0);
        vx_uint32     width0                = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_uint32     height0               = dims0 > 1 ? TENSOR_VIEW_SIZE_INDEX(input0, 1) : 1;
        vx_uint32     batch0                = dims0 > 3 ? TENSOR_VIEW_SIZE_INDEX(input0, 3) : 1;

        vx_uint32     dims1                 = TENSOR_DIM_NUM(input1);
        vx_uint32     width1                = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_uint32     height1               = dims1 > 1 ? TENSOR_VIEW_SIZE_INDEX(input1, 1) : 1;
        vx_uint32     batch1                = dims1 > 3 ? TENSOR_VIEW_SIZE_INDEX(input1, 3) : 1;

        vx_int32     sizes[4]               = {width * height, depth, 1, batch};
        vx_int32     sizes0[4]              = {width0 * height0, depth0, 1, batch0};
        vx_int32     sizes1[4]              = {width1 * height1, depth1, 1, batch1};

        src0 = src0 ? src0 : vxoTensor_ReshapeTensor(input0, sizes0, dims0);
        src1 = src1 ? src1 : vxoTensor_ReshapeTensor(input1, sizes1, dims1);
        dst  = dst ?  dst  :  vxoTensor_ReshapeTensor(output, sizes, dims);

        parameters[0] = (vx_reference)src0;
        parameters[1] = (vx_reference)src1;
        parameters[2] = (vx_reference)dst;
    }

    if (enable_broadcast_Z)
    {
        if (depth0 == 1)
        {
            parameters[0] = src1 ? (vx_reference)src1 : (vx_reference)input1;
            parameters[1] = src0 ? (vx_reference)src0 : (vx_reference)input0;
            inputSwap = vx_true_e;
        }
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorMul, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorMul.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorEltwise", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (useImage2DFlag)
    {
        vx_int8 postshift = gcmMIN(src0FixPointPos + src1FixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);
        vx_uint32 uniI8MulI8Lo_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x03020100, 0x07060504, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniI8MulI8Hi_2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x0b0a0908, 0x0f0e0d0c, // ABin
            0x11111111, // BSelt
            0x0b0a0908, 0x0f0e0d0c, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        uniI8MulI8Lo_2x8[7] |= (postshift & 0x1F);
        uniI8MulI8Hi_2x8[7] |= (postshift & 0x1F);

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8MulI8_2D", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8MulI8Lo_2x8", 1, uniI8MulI8Lo_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniI8MulI8Hi_2x8", 1, uniI8MulI8Hi_2x8);
        if (status != VX_SUCCESS) goto OnError;

        execution_parameters.globalWorkScale[0]  = 16;
        execution_parameters.globalWorkScale[1]  = 1;
    }
    else
    {
        char kernelName[1024];
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part0_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part1_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        switch (input0_format)
        {
        case VX_TYPE_FLOAT16:
            sprintf(kernelName, "_Fp16");
            break;
        case VX_TYPE_INT8:
            sprintf(kernelName, "_Int8");
            break;
        case VX_TYPE_UINT8:
            sprintf(kernelName, "_UInt8");
            break;
        case VX_TYPE_INT16:
            sprintf(kernelName, "_Int16");
            break;
        default:
            break;
        }

        switch (operation)
        {
        case VX_TENSOR_OP_ADD:
        case VX_TENSOR_OP_SUB:
            strcat(kernelName, "Add" );
            break;
        case VX_TENSOR_OP_MUL:
            strcat(kernelName, "Mul" );
            break;
        case VX_TENSOR_OP_DIV:
            strcat(kernelName, "Div" );
            break;
        default:
            break;
        }

        switch (input1_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "Fp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "Int8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "UInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "Int16" );
            break;
        default:
            break;
        }

        switch (output_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "toFp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "toInt8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "toUInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "toInt16" );
            break;
        default:
            break;
        }

        switch (policyEnum)
        {
        case VX_CONVERT_POLICY_SATURATE:
            strcat(kernelName, "_Sat" );
            break;
        case VX_CONVERT_POLICY_WRAP:
            strcat(kernelName, "_Warp" );
            break;
        default:
            strcat(kernelName, "_Sat" );
            break;
        }

        if (enable_broadcast_Z)
        {
            switch (roundingEnum)
            {
            case VX_ROUND_POLICY_TO_ZERO:
                strcat(kernelName, "_RTZ_Z_func" );
                break;
            case VX_ROUND_POLICY_TO_NEAREST_EVEN:
                strcat(kernelName, "_RTE_Z_func" );
                break;
            default:
                strcat(kernelName, "_RTE_Z_func" );
                break;
            }
        }
        else
        {
            switch (roundingEnum)
            {
            case VX_ROUND_POLICY_TO_ZERO:
                strcat(kernelName, "_RTZ_func" );
                break;
            case VX_ROUND_POLICY_TO_NEAREST_EVEN:
                strcat(kernelName, "_RTE_func" );
                break;
            default:
                strcat(kernelName, "_RTE_func" );
                break;
            }
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        if (inputSwap)
        {
            vx_int32 tmp;

            tmp = inputZP0;
            inputZP0 = inputZP1;
            inputZP1 = tmp;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale", 1, &input_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP0", 1, &inputZP0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP1", 1, &inputZP1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part0_4x4", 1, uniDataSubZPtoFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part1_4x4", 1, uniDataSubZPtoFp32Part1_4x4);
        if (output_format == VX_TYPE_FLOAT16)
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtractHalf8_2x8);
        else
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcTensorDiv****************************************************/
vxnne_shader_executable vxnneGetTensorDivShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input0,
    vx_tensor               input1,
    vx_scalar               scale_s,
    vx_scalar               convertPolicy,
    vx_int32                activation,
    vx_enum                 operation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]         = {(vx_reference)input0, (vx_reference)input1, (vx_reference)output, (vx_reference)NULL};
    vx_enum       policyEnum            = convertPolicy->value->e;
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(output, 2) : 1;
    vx_uint32     depth0                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input0, 2) : 1;
    vx_uint32     depth1                = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input1, 2) : 1;
    vx_enum       input0_format         = TENSOR_DATA_TYPE(input0);
    vx_enum       input1_format         = TENSOR_DATA_TYPE(input1);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_tensor     src0                  = NULL;
    vx_tensor     src1                  = NULL;
    vx_tensor     dst                   = NULL;
    vx_float32    input_scale           = 1.0f;
    vx_float32    input_scale0          = TENSOR_TF_SCALE(input0);
    vx_float32    input_scale1          = TENSOR_TF_SCALE(input1);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP0              = TENSOR_TF_ZEROPOINT(input0);
    vx_int32      inputZP1              = TENSOR_TF_ZEROPOINT(input1);
    vx_float32    outputZP              = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    vx_int8       dstFixPointPos        = 0;
    vx_uint32     paramNum              = 3;
    vx_bool       useImage2DFlag        = vx_false_e;
    vx_bool       enable_broadcast      = vx_false_e;
    vx_bool       enable_broadcast_Z0   = vx_false_e;
    vx_bool       enable_broadcast_Z1   = vx_false_e;
    vx_uint32     i                     = 0;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input0=%p, input1=%p, output=%p",
         context, kernelEnum, borderMode, input0, input1, output);

    borderMode->mode = VX_BORDER_REPLICATE;

    for (i = 0; i < TENSOR_DIM_NUM(output); i++)
    {
        vx_uint32 size0 = TENSOR_DIM_NUM(input0) > i ? TENSOR_VIEW_SIZE_INDEX(input0, i) : 1;
        vx_uint32 size1 = TENSOR_DIM_NUM(input1) > i ? TENSOR_VIEW_SIZE_INDEX(input1, i) : 1;

        if (size0 != size1)
        {
            enable_broadcast = vx_true_e;
            break;
        }
    }

    enable_broadcast_Z0 = (vx_bool)(enable_broadcast && (depth0 != depth1) && (depth0 == 1));
    enable_broadcast_Z1 = (vx_bool)(enable_broadcast && (depth0 != depth1) && (depth1 == 1));

    if (input0_format == VX_TYPE_INT8 || input0_format == VX_TYPE_INT16)
    {
        vx_int8   input0_fixedPointPos    = TENSOR_POS(input0);
        if (input0_fixedPointPos >= 0)
        {
            input_scale0 = 1.0f / (vx_float32) (1 << input0_fixedPointPos);
        }
        else if (input0_fixedPointPos < 0)
        {
            input_scale0 = (vx_float32) (1 << -input0_fixedPointPos);
        }

        inputZP0 = 0;
    }
    else if (input0_format == VX_TYPE_FLOAT16)
    {
        input_scale0    = 1.0f;
        inputZP0        = 0;
    }
    else if (input0_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input0) ==VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
            vx_int8   input0_fixedPointPos    = TENSOR_POS(input0);
            if (input0_fixedPointPos >= 0)
            {
                input_scale0 = 1.0f / (vx_float32) (1 << input0_fixedPointPos);
            }
            else if (input0_fixedPointPos < 0)
            {
                input_scale0 = (vx_float32) (1 << -input0_fixedPointPos);
            }
            inputZP0 = 0;
        }
    }


    if (input1_format == VX_TYPE_INT8 || input1_format == VX_TYPE_INT16)
    {
        vx_int8   input1_fixedPointPos    = TENSOR_POS(input1);
        if (input1_fixedPointPos >= 0)
        {
            input_scale1 = 1.0f / (vx_float32) (1 << input1_fixedPointPos);
        }
        else if (input1_fixedPointPos < 0)
        {
            input_scale1 = (vx_float32) (1 << -input1_fixedPointPos);
        }

        inputZP1 = 0;
    }
    else if (input1_format == VX_TYPE_FLOAT16)
    {
        input_scale1    = 1.0f;
        inputZP1        = 0;
    }
    else if (input1_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(input1) == VX_QUANT_DYNAMIC_FIXED_POINT) /*For OpenVX dynamic fix point uint8*/
        {
             vx_int8   input1_fixedPointPos    = TENSOR_POS(input1);
            if (input1_fixedPointPos >= 0)
            {
                input_scale1 = 1.0f / (vx_float32) (1 << input1_fixedPointPos);
            }
            else if (input1_fixedPointPos < 0)
            {
                input_scale1 = (vx_float32) (1 << -input1_fixedPointPos);
            }
            inputZP1        = 0;
        }
    }


    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        dstFixPointPos    = TENSOR_POS(output);
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }

        outputZP = 0;
    }
    else if (output_format == VX_TYPE_FLOAT16)
    {
        output_scale    = 1.0f;
        outputZP        = 0;
    }
    else if (output_format == VX_TYPE_UINT8)
    {
        if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT )
        {
            outputZP = 0;
            dstFixPointPos    = TENSOR_POS(output);
            if (dstFixPointPos >= 0)
            {
                output_scale = (vx_float32) (1 << dstFixPointPos);
            }
            else if (dstFixPointPos < 0)
            {
                output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
            }
        }
        else
        {
            output_scale = 1 / output_scale;
        }
    }

    if (operation == VX_TENSOR_OP_DIV)
    {
        input_scale     = input_scale0 / input_scale1;

        parameters[3]   = (vx_reference)scale_s;
        paramNum        = 4;
    }

    if (TENSOR_DIM_NUM(input0) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        src0 = vxoTensor_ReshapeTensor(input0, sizes, dims);
        parameters[0] = (vx_reference)src0;
    }

    if (TENSOR_DIM_NUM(input1) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        src1 = vxoTensor_ReshapeTensor(input1, sizes, dims);
        parameters[1] = (vx_reference)src1;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32     w             = TENSOR_VIEW_SIZE_INDEX(output, 0);
        vx_int32 sizes[4]           = {w, 1, 1, 1};
        dims = 2;

        dst = vxoTensor_ReshapeTensor(output, sizes, dims);
        parameters[2] = (vx_reference)dst;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorDiv, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorDiv.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorEltwise", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    {
        char kernelName[1024];
        vx_uint32 uniExtact8Bin_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part0_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniDataSubZPtoFp32Part1_4x4[16] = {
            0x09090909, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000, 0x3c003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        switch (input0_format)
        {
        case VX_TYPE_FLOAT16:
            sprintf(kernelName, "_Fp16");
            break;
        case VX_TYPE_INT8:
            sprintf(kernelName, "_Int8");
            break;
        case VX_TYPE_UINT8:
            sprintf(kernelName, "_UInt8");
            break;
        case VX_TYPE_INT16:
            sprintf(kernelName, "_Int16");
            break;
        default:
            break;
        }

        strcat(kernelName, "Div" );

        switch (input1_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "Fp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "Int8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "UInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "Int16" );
            break;
        default:
            break;
        }

        switch (output_format)
        {
        case VX_TYPE_FLOAT16:
            strcat(kernelName, "toFp16" );
            break;
        case VX_TYPE_INT8:
            strcat(kernelName, "toInt8" );
            break;
        case VX_TYPE_UINT8:
            strcat(kernelName, "toUInt8" );
            break;
        case VX_TYPE_INT16:
            strcat(kernelName, "toInt16" );
            break;
        default:
            break;
        }

        if (enable_broadcast_Z0)
        {
            switch (policyEnum)
            {
            case VX_CONVERT_POLICY_SATURATE:
                strcat(kernelName, "_Sat_Z0_func" );
                break;
            case VX_CONVERT_POLICY_WRAP:
                strcat(kernelName, "_Warp_Z0_func" );
                break;
            default:
                break;
            }
        }
        else if (enable_broadcast_Z1)
        {
            switch (policyEnum)
            {
            case VX_CONVERT_POLICY_SATURATE:
                strcat(kernelName, "_Sat_Z1_func" );
                break;
            case VX_CONVERT_POLICY_WRAP:
                strcat(kernelName, "_Warp_Z1_func" );
                break;
            default:
                break;
            }
        }
        else
        {
            switch (policyEnum)
            {
            case VX_CONVERT_POLICY_SATURATE:
                strcat(kernelName, "_Sat_func" );
                break;
            case VX_CONVERT_POLICY_WRAP:
                strcat(kernelName, "_Warp_func" );
                break;
            default:
                break;
            }
        }

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, kernelName, borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale", 1, &input_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_scale", 1, &output_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP0", 1, &inputZP0);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP1", 1, &inputZP1);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part0_4x4", 1, uniDataSubZPtoFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniDataSubZPtoFp32Part1_4x4", 1, uniDataSubZPtoFp32Part1_4x4);
        if (output_format == VX_TYPE_FLOAT16)
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtractHalf8_2x8);
        else
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtact8Bin_2x8", 1, uniExtact8Bin_2x8);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (useImage2DFlag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width  + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********Tensor Mean on x-axis****************************************************/
vxnne_shader_executable vxnneGetTensorMeanAxis0ShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_float32              axis_coef,
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]         = {(vx_reference)input, (vx_reference)output};
    vx_uint32     dims                  = TENSOR_DIM_NUM(input);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_uint32     batch                 = dims > 3 ? TENSOR_VIEW_SIZE_INDEX(input, 3) : 1;
    vx_enum       input_format          = TENSOR_DATA_TYPE(input);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_tensor     src                   = NULL;
    vx_tensor     dst                   = NULL;
    vx_float32    input_scale           = TENSOR_TF_SCALE(input);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP               = TENSOR_TF_ZEROPOINT(input);
    vx_int32      outputZP              = TENSOR_TF_ZEROPOINT(output);
    vx_int8       srcFixPointPos        = TENSOR_POS(input);
    vx_int8       dstFixPointPos        = TENSOR_POS(output);
    vx_bool       useImage2DFlag        = vx_false_e;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_CONSTANT;

    if (input_format == VX_TYPE_INT8 || input_format == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            input_scale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            input_scale = (vx_float32) (1 << -srcFixPointPos);
        }
    }

    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    useImage2DFlag = (vx_bool)(width < IMG_MAX_WIDTH && (height * depth < IMG_MAX_WIDTH));

    if (useImage2DFlag)
    {
        vx_uint32 sizes[4] = {1};

        sizes[0]    = width;
        sizes[1]    = height * depth;
        sizes[2]    = 1;
        sizes[3]    = batch;

        src         = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, 4);

        sizes[0]    = 1;
        dst         = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, 4);

        parameters[0] = (vx_reference)src;
        parameters[1] = (vx_reference)dst;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorMeanAxis0, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorMeanAxis0.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorMeanAxis0", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_FLOAT16)
    {
        vx_int32    width_align32           = gcmALIGN(width, 32);
        vx_float32  axis_scale              = axis_coef;
        vx_uint32 uniSumFp16toFp32_16x1[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "width_align32", 1, &width_align32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "axis_scale", 1, &axis_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumFp16toFp32_16x1", 1, uniSumFp16toFp32_16x1);
    }
    else if (input_format == VX_TYPE_INT16 && output_format == VX_TYPE_INT16)
    {
        vx_int32    width_align32           = gcmALIGN(width, 32);
        vx_float32  axis_scale              = input_scale * output_scale * axis_coef;
        vx_uint32 uniSumI16toFp32_16x1[16] = {
            0x55555555, // TCfg
            0x55550000, // ASelt
            0x76543210, 0x76543210, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000300, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "width_align32", 1, &width_align32);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "axis_scale", 1, &axis_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumI16toFp32_16x1", 1, uniSumI16toFp32_16x1);
    }
    else if (input_format == VX_TYPE_INT8 && output_format == VX_TYPE_INT8)
    {
        vx_int32    width_align64           = gcmALIGN(width, 64);
        vx_float32  axis_scale              = input_scale * output_scale * axis_coef;
        vx_uint32 uniSumI8toFp32_32x1[16] = {
            0x55555555, 0x55555555, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000400, // AccumType, ConstantType, and PostShift
            0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "width_align64", 1, &width_align64);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "axis_scale", 1, &axis_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumI8toFp32_32x1", 1, uniSumI8toFp32_32x1);
    }
    else if (input_format == VX_TYPE_UINT8 && output_format == VX_TYPE_UINT8)
    {
        vx_int32    width_align64           = gcmALIGN(width, 64);
        vx_float32  axis_scale              = input_scale * axis_coef / (vx_float32)(output_scale);
        vx_float32  offset_asymmetric       = outputZP - inputZP * input_scale / output_scale;
        vx_uint32 uniSumI8toFp32_32x1[16] = {
            0x55555555, 0x55555555, // TCfg
            0x8a418820, 0xc5a92839, 0xca307b9a, 0x38bdab49, 0xffbbcdeb, // BinSelect
            0x00000400, // AccumType, ConstantType, and PostShift
            0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101, 0x01010101 // Constant
        };

        if (useImage2DFlag)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8_2D", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "width_align64", 1, &width_align64);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "axis_scale", 1, &axis_scale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "offset_asymmetric", 1, &offset_asymmetric);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumI8toFp32_32x1", 1, uniSumI8toFp32_32x1);
    }

    if (useImage2DFlag)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN(height * depth, SHADER_THREAD_COUNT);
    }
    else
    {
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkScale[0]  = 1;
        execution_parameters.globalWorkScale[1]  = 1;
        execution_parameters.globalWorkScale[2]  = 1;
        execution_parameters.globalWorkSize[0]   = 1;
        execution_parameters.globalWorkSize[1]   = gcmALIGN(height, SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********Tensor crop****************************************************/
vxnne_shader_executable vxnneGetTensorCropShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_int32                start[4],
    vx_int32                stop[4],
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]         = {(vx_reference)input, (vx_reference)output};
    vx_uint32     dims                  = TENSOR_DIM_NUM(input);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_enum       input_format          = TENSOR_DATA_TYPE(input);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_float32    input_scale           = TENSOR_TF_SCALE(input);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP               = TENSOR_TF_ZEROPOINT(input);
    vx_int32      outputZP              = TENSOR_TF_ZEROPOINT(output);
    vx_int8       srcFixPointPos        = TENSOR_POS(input);
    vx_int8       dstFixPointPos        = TENSOR_POS(output);
    vx_tensor     src                   = NULL;
    vx_tensor     dst                   = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;

    if (input_format == VX_TYPE_INT8 || input_format == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            input_scale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            input_scale = (vx_float32) (1 << -srcFixPointPos);
        }
    }

    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    if (TENSOR_DIM_NUM(input) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]    = TENSOR_VIEW_SIZE_INDEX(input, 0);
        src         = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, 2);
        parameters[0] = (vx_reference)src;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]    = TENSOR_VIEW_SIZE_INDEX(output, 0);
        dst         = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, 2);
        parameters[1] = (vx_reference)dst;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorCrop, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorCrop.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensorCrop", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((input_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_FLOAT16)
     || (input_format == VX_TYPE_INT16 && output_format == VX_TYPE_INT16 && srcFixPointPos == dstFixPointPos)
     || (input_format == VX_TYPE_INT8 && output_format == VX_TYPE_INT8 && srcFixPointPos == dstFixPointPos)
     || (input_format == VX_TYPE_UINT8 && output_format == VX_TYPE_UINT8 && inputZP == outputZP && input_scale == output_scale))
    {
        if (input_format == VX_TYPE_FLOAT16 || input_format == VX_TYPE_INT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 8;
            execution_parameters.globalWorkScale[1]  = 4;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits", borderMode);
            if (!shaderExecutable) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
            execution_parameters.globalWorkScale[1]  = 4;
        }

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "offset4", 1, start);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkOffset[0] = start[0];
    execution_parameters.globalWorkOffset[1] = start[1];
    execution_parameters.globalWorkOffset[2] = start[2];
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1)
        / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1)
        / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********Tensor strided slice****************************************************/
vxnne_shader_executable vxnneGetTensorStridedSliceShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_int32                start[4],
    vx_int32                stop[4],
    vx_int32                stride[4],
    vx_tensor               input,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[2]         = {(vx_reference)input, (vx_reference)output};
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(output, 2) : 1;
    vx_enum       input_format          = TENSOR_DATA_TYPE(input);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_float32    input_scale           = TENSOR_TF_SCALE(input);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP               = TENSOR_TF_ZEROPOINT(input);
    vx_int32      outputZP              = TENSOR_TF_ZEROPOINT(output);
    vx_int8       srcFixPointPos        = TENSOR_POS(input);
    vx_int8       dstFixPointPos        = TENSOR_POS(output);
    vx_tensor     src                   = NULL;
    vx_tensor     dst                   = NULL;
    vx_bool       isStrideLE2           = (vx_bool)(stride[0] <= 2 && stride[1] <= 2 && stride[2] <= 2);
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    borderMode->mode = VX_BORDER_REPLICATE;

    if (input_format == VX_TYPE_INT8 || input_format == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            input_scale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            input_scale = (vx_float32) (1 << -srcFixPointPos);
        }
    }

    if (output_format == VX_TYPE_INT8 || output_format == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    if (TENSOR_DIM_NUM(input) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]    = TENSOR_VIEW_SIZE_INDEX(input, 0);
        src         = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, 2);
        parameters[0] = (vx_reference)src;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]    = TENSOR_VIEW_SIZE_INDEX(output, 0);
        dst         = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, 2);
        parameters[1] = (vx_reference)dst;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, TensorStridedSlice, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/TensorStridedSlice.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcStridedSlice", program, 2, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if ((input_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_FLOAT16)
        || (input_format == VX_TYPE_INT16 && output_format == VX_TYPE_INT16 && srcFixPointPos == dstFixPointPos)
        || (input_format == VX_TYPE_INT8 && output_format == VX_TYPE_INT8 && srcFixPointPos == dstFixPointPos)
        || (input_format == VX_TYPE_UINT8 && output_format == VX_TYPE_UINT8 && inputZP == outputZP && input_scale == output_scale))
    {
        if (input_format == VX_TYPE_FLOAT16 || input_format == VX_TYPE_INT16)
        {
            if (isStrideLE2 && stride[0] == 2)
            {
                vx_uint32 uniPackedEvenData_2x8[16] = {
                    0x11111111, // TCfg
                    0x11110000, // ASelt
                    0x06040200, 0x06040200, // ABin
                    0x22222222, // BSelt
                    0x00000000, 0x00000000, // BBin
                    0x00000400, // AccumType, ConstantType, and PostShift
                    0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
                };

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits_xstride2", borderMode);
                if (!shaderExecutable) goto OnError;

                status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPackedEvenData_2x8", 1, uniPackedEvenData_2x8);
                if (status != VX_SUCCESS) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 1;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else if (isStrideLE2 && stride[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits_ystride2", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else if (isStrideLE2 && stride[2] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits_zstride2", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_16Bits", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 1;
                execution_parameters.globalWorkScale[2]  = 1;
            }
        }
        else
        {
            if (isStrideLE2 && stride[0] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_xstride2", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 1;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else if (isStrideLE2 && stride[1] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_ystride2", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else if (isStrideLE2 && stride[2] == 2)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits_zstride2", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 16;
                execution_parameters.globalWorkScale[1]  = 2;
                execution_parameters.globalWorkScale[2]  = 1;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_8Bits", borderMode);
                if (!shaderExecutable) goto OnError;

                execution_parameters.globalWorkScale[0]  = 8;
                execution_parameters.globalWorkScale[1]  = 1;
                execution_parameters.globalWorkScale[2]  = 1;
            }
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "offset4", 1, start);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "stride4", 1, stride);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1)
        / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1)
        / execution_parameters.globalWorkScale[1];
    execution_parameters.globalWorkSize[2]   = depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 2);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src) vxoTensor_ReleaseTensor(&src);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

vxnne_shader_executable vxnneGetPReluShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               alpha,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength[2] = {0};
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[3]         = {(vx_reference)input, (vx_reference)alpha, (vx_reference)output};
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_uint32     depth                 = dims > 2 ? TENSOR_VIEW_SIZE_INDEX(output, 2) : 1;
    vx_uint32     batch                 = dims > 3 ? TENSOR_VIEW_SIZE_INDEX(output, 3) : 1;
    vx_enum       srcFormat             = TENSOR_DATA_TYPE(input);
    vx_enum       dstFormat             = TENSOR_DATA_TYPE(output);
    vx_float32    input_scale           = TENSOR_TF_SCALE(input);
    vx_float32    output_scale          = TENSOR_TF_SCALE(output);
    vx_int32      inputZP               = TENSOR_TF_ZEROPOINT(input);
    vx_int32      outputZP              = TENSOR_TF_ZEROPOINT(output);
    vx_int8       srcFixPointPos        = TENSOR_POS(input);
    vx_int8       dstFixPointPos        = TENSOR_POS(output);
    vx_tensor     src0                  = NULL;
    vx_tensor     src1                  = NULL;
    vx_tensor     dst                   = NULL;
    vx_bool       enable_image_2d       = vx_false_e;
    vx_uint32     hwLitimLen            = IMG_MAX_WIDTH;
    vx_uint16     M0                    = 0;
    vx_int8       postShift             = 0;
    char *programSources[2]             = {NULL, NULL};

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input=%p, output=%p",
         context, kernelEnum, borderMode, input, output);

    enable_image_2d = (vx_bool)((width * height < hwLitimLen) && depth < hwLitimLen);

    borderMode->mode = VX_BORDER_REPLICATE;

    if ((srcFormat == VX_TYPE_INT8 && dstFormat == VX_TYPE_INT8)
     || (srcFormat == VX_TYPE_INT16 && dstFormat == VX_TYPE_INT16))
    {
        if(enable_image_2d)
        {
            enable_image_2d = context->evisNoInst.isVX2;
        }
        else
        {
            enable_image_2d = vx_false_e;
        }
    }
    else if ((srcFormat == VX_TYPE_INT8 && dstFormat == VX_TYPE_FLOAT16)
          || (srcFormat == VX_TYPE_FLOAT16 && dstFormat == VX_TYPE_FLOAT16))
    {
        if (enable_image_2d)
            enable_image_2d = vx_true_e;
    }
    else if (srcFormat == VX_TYPE_UINT8 && enable_image_2d
        && (dstFormat == VX_TYPE_UINT8 || dstFormat == VX_TYPE_FLOAT16))
    {
        enable_image_2d = vx_true_e;
    }
    else
    {
        enable_image_2d = vx_false_e;
    }

    if(srcFormat == VX_TYPE_INT8 || srcFormat == VX_TYPE_INT16)
    {
        if (srcFixPointPos >= 0)
        {
            input_scale = 1.0f / (vx_float32) (1 << srcFixPointPos);
        }
        else if (srcFixPointPos < 0)
        {
            input_scale = (vx_float32) (1 << -srcFixPointPos);
        }
    }

    if(dstFormat == VX_TYPE_INT8 || dstFormat == VX_TYPE_INT16)
    {
        if (dstFixPointPos >= 0)
        {
            output_scale = (vx_float32) (1 << dstFixPointPos);
        }
        else if (dstFixPointPos < 0)
        {
            output_scale = 1.0f / (vx_float32) (1 << -dstFixPointPos);
        }
    }

    if(TENSOR_DIM_NUM(input) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]     = TENSOR_VIEW_SIZE_INDEX(input, 0);
        src0          = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, 2);
        parameters[0] = (vx_reference)src0;
    }
    else if (enable_image_2d)
    {
        vx_uint32 sizes[4] = {width * height, depth, 1, batch};

        src0          = vxoTensor_ReshapeTensor(input, (vx_int32*)sizes, dims);
        parameters[0] = (vx_reference)src0;
    }

    if(alpha)
    {
        vx_uint32 sizes[4] = {depth, 1, 1, 1};

        src1          = vxoTensor_ReshapeTensor(alpha, (vx_int32*)sizes, 2);
        parameters[1] = (vx_reference)src1;
    }

    if(TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32 sizes[4] = {1, 1, 1, 1};

        sizes[0]    = TENSOR_VIEW_SIZE_INDEX(output, 0);
        dst         = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, 2);
        parameters[2] = (vx_reference)dst;
    }
    else if (enable_image_2d)
    {
        vx_uint32 sizes[4] = {width * height, depth, 1, batch};

        dst         = vxoTensor_ReshapeTensor(output, (vx_int32*)sizes, dims);
        parameters[2] = (vx_reference)dst;
    }

    getFP32M0AndN(input_scale / output_scale, &M0, &postShift);

    execution_parameters.globalWorkScale[0]  = 8;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, PRelu, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path0[_vxcFILENAME_MAX];
        char path1[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/VXC_INS_HDR.vx", path0));
        vxmONERROR(getFilePath("nnvxc_kernels/PRelu.vx", path1));

        vxmONERROR_NULLPTR(programSources[0] = loadSources(path0, &programLength[0]));
        vxmONERROR_NULLPTR(programSources[1] = loadSources(path1, &programLength[1]));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 2, (const vx_char**)programSources, programLength));

        if (programSources[0])
        {
            vxFree(programSources[0]);
            programSources[0] = NULL;
        }

        if (programSources[1])
        {
            vxFree(programSources[1]);
            programSources[1] = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        if (context->evisNoInst.isVX2)
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=2"));
        else
            vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension -D VX_VERSION=1"));

        kernel = vxnneAddKernelShadersInProgram(context, "pRelu", program, 3, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (srcFormat == VX_TYPE_INT8 && dstFormat == VX_TYPE_INT8)
    {
        vx_uint32 uniConvertInt8FstFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt8SecFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt8TrdFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt8ForFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        uint32_t uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        ///
        vx_uint32 uniPreluInt8Lo_2x8b[16] = {
            0x77777777, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004000, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPreluInt8Hi_2x8b[16] = {
            0x77777777, // TCfg
            0x44444444, // ASelt
            0xbbaa9988, 0xffeeddcc, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004000, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPreluInt8_2x8[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0xb3a29180, 0xf7e6d5c4, // ABin
            0x66666666, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001, 0x00000001 // Constant
        };
        // output fl > input fl
        vx_uint32 uniMergeMultiplier_2x8[16] = {
            0x00000011, // TCfg
            0x00000010, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000021, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_image_2d)
        {
            if (srcFixPointPos > dstFixPointPos)
            {
                vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                uniPreluInt8Lo_2x8b[7] = uniPreluInt8Lo_2x8b[7] | (postshift & 0x1F);
                uniPreluInt8Hi_2x8b[7] = uniPreluInt8Hi_2x8b[7] | (postshift & 0x1F);
                uniPreluInt8_2x8[7]    = uniPreluInt8_2x8[7] | (postshift & 0x1F);

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_opt", borderMode);
                if (!shaderExecutable) goto OnError;

                if (context->evisNoInst.isVX2)
                {
                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt8Lo_2x8b", 1, uniPreluInt8Lo_2x8b);
                    status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt8Hi_2x8b", 1, uniPreluInt8Hi_2x8b);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt8_2x8", 1, uniPreluInt8_2x8);
                    if (status != VX_SUCCESS) goto OnError;
                }
            }
            else
            {
                vx_uint32 uniPreluInt8Lo_2x8b[16] = {
                    0x55555555, // TCfg
                    0x44444444, // ASelt
                    0x33221100, 0x77665544, // ABin
                    0x00000000, // BSelt
                    0x01010101, 0x01010101, // BBin
                    0x00000000, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_uint32 uniPreluInt8Hi_2x8b[16] = {
                    0x55555555, // TCfg
                    0x44444444, // ASelt
                    0xbbaa9988, 0xffeeddcc, // ABin
                    0x00000000, // BSelt
                    0x01010101, 0x01010101, // BBin
                    0x00000000, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_int32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);;

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8_opt1", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt8Lo_2x8b", 1, uniPreluInt8Lo_2x8b);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt8Hi_2x8b", 1, uniPreluInt8Hi_2x8b);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMergeMultiplier_2x8", 1, uniMergeMultiplier_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multiplier", 1, &multiplier);
                if (status != VX_SUCCESS) goto OnError;
            }
        }
        else
        {
            vx_float32 scale_inOut = input_scale * output_scale;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toI8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt8FstFp32_4x4", 1, uniConvertInt8FstFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt8SecFp32_4x4", 1, uniConvertInt8SecFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt8TrdFp32_4x4", 1, uniConvertInt8TrdFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt8ForFp32_4x4", 1, uniConvertInt8ForFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_inOut", 1, &scale_inOut);
            if (status != VX_SUCCESS) goto OnError;
        }

        execution_parameters.globalWorkScale[0]  = 16;
    }
    else if (srcFormat == VX_TYPE_INT8 && dstFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 UniFP16Mul_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniS8xFp16_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_image_2d)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toF16_2d", borderMode);
            if (!shaderExecutable) goto OnError;
        }
        else
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I8toF16", borderMode);
            if (!shaderExecutable) goto OnError;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16Mul_dp2x8", 1, UniFP16Mul_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniS8xFp16_dp2x8", 1, UniS8xFp16_dp2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &input_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_INT16 && dstFormat == VX_TYPE_INT16)
    {
        vx_uint32 uniPreluInt16_2x8b[16] = {
            0x77777777, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00003000, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniPreluInt16_4x4[16] = {
            0x05050505, // TCfg
            0x00000000, // ASelt
            0x00510040, 0x00730062, // ABin
            0x06060606, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000, 0x00000001, 0x00000000 // Constant
        };
        // output fl > input fl
        vx_uint32 uniMergeMultiplier_2x8[16] = {
            0x00000011, // TCfg
            0x00000010, // ASelt
            0x00000000, 0x00000000, // ABin
            0x00000021, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (enable_image_2d)
        {
            if (srcFixPointPos > dstFixPointPos)
            {
                vx_uint8  postshift      = gcmMIN(srcFixPointPos - dstFixPointPos, MAX_POST_SHIFT_BITS);

                uniPreluInt16_2x8b[7] = uniPreluInt16_2x8b[7] | (postshift & 0x1F);
                uniPreluInt16_4x4[7]  = uniPreluInt16_4x4[7] | (postshift & 0x1F);

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_opt", borderMode);
                if (!shaderExecutable) goto OnError;

                if (context->evisNoInst.isVX2)
                {
                    status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt16_2x8b", 1, uniPreluInt16_2x8b);
                    if (status != VX_SUCCESS) goto OnError;
                }
                else
                {
                    status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt16_4x4", 1, uniPreluInt16_4x4);
                    if (status != VX_SUCCESS) goto OnError;
                }
            }
            else
            {
                vx_uint32 uniPreluInt16_2x8b[16] = {
                    0x55555555, // TCfg
                    0x44444444, // ASelt
                    0x33221100, 0x77665544, // ABin
                    0x00000000, // BSelt
                    0x01010101, 0x01010101, // BBin
                    0x00000000, // AccumType, ConstantType, and PostShift
                    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
                };
                vx_int32 multiplier = gcmMIN(1 << (dstFixPointPos - srcFixPointPos), MAX_MULTIPLIER_NUM);

                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16_opt1", borderMode);
                if (!shaderExecutable) goto OnError;

                status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniPreluInt16_2x8b", 1, uniPreluInt16_2x8b);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniMergeMultiplier_2x8", 1, uniMergeMultiplier_2x8);
                status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "multiplier", 1, &multiplier);
                if (status != VX_SUCCESS) goto OnError;
            }
        }
        else
        {
            vx_uint32 uniConvertDirInt16Fp32_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00010000, 0x00030002, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniConvertEndInt16Fp32_4x4[16] = {
                0x01010101, // TCfg
                0x00000000, // ASelt
                0x00050004, 0x00070006, // ABin
                0x02020202, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
                0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
            };
            vx_uint32 uniConvertInt32toUint8_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_float32 scale_inOut = input_scale * output_scale;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toI16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirInt16Fp32_4x4", 1, uniConvertDirInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_inOut", 1, &scale_inOut);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (srcFormat == VX_TYPE_INT16 && dstFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniConvertDirInt16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertEndInt16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_I16toF16", borderMode);
        if (!shaderExecutable) goto OnError;

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirInt16Fp32_4x4", 1, uniConvertDirInt16Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &input_scale);
        if (status != VX_SUCCESS) goto OnError;
    }
    else if (srcFormat == VX_TYPE_UINT8 && dstFormat == VX_TYPE_UINT8)
    {
        if (enable_image_2d)
        {
            vx_uint32 idx = 0;
            vx_uint32 uniU8SubZP_MulM_PStoF16Lo_2x8[16] = {
                0x99999999, // TCfg
                0x44444444, // ASelt
                0x03020100, 0x07060504, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            vx_uint32 uniU8SubZP_MulM_PStoF16Hi_2x8[16] = {
                0x99999999, // TCfg
                0x44444444, // ASelt
                0x0b0a0908, 0x0f0e0d0c, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            vx_uint32 uniF16MulF16_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x03020100, 0x07060504, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniS16AddZP_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x03020100, 0x07060504, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            uniU8SubZP_MulM_PStoF16Lo_2x8[7] |= postShift;
            uniU8SubZP_MulM_PStoF16Hi_2x8[7] |= postShift;

            for (idx = 8; idx < 16; idx ++)
            {
                uniU8SubZP_MulM_PStoF16Hi_2x8[idx] = uniU8SubZP_MulM_PStoF16Lo_2x8[idx] = (vx_uint32)(M0 << 16) | M0;
            }

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8_2d", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP_MulM_PStoF16Lo_2x8", 1, uniU8SubZP_MulM_PStoF16Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP_MulM_PStoF16Hi_2x8", 1, uniU8SubZP_MulM_PStoF16Hi_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16MulF16_2x8", 1, uniF16MulF16_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddZP_2x8", 1, uniS16AddZP_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
        }
        else
        {
            vx_uint32 uniConvertUint8SubZpToFp32_4x4[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002100, // AccumType, ConstantType, and PostShift
                0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000 // Constant
            };

            vx_uint32 uniConvertSecUint8SubZpToFp32_4x4[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00050004, 0x00070006, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000 // Constant
            };
            uint32_t uniConvertInt32toUint8_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            vx_float32 scale_inOut_u8 = input_scale / output_scale;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toU8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8SubZpToFp32_4x4", 1, uniConvertUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSecUint8SubZpToFp32_4x4", 1, uniConvertSecUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "scale_inOut_u8", 1, &scale_inOut_u8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (srcFormat == VX_TYPE_UINT8 && dstFormat == VX_TYPE_FLOAT16)
    {
        if (enable_image_2d)
        {
            vx_uint32 idx = 0;
            vx_uint32 uniU8SubZP_MulM_PStoF16Lo_2x8[16] = {
                0x99999999, // TCfg
                0x44444444, // ASelt
                0x03020100, 0x07060504, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            vx_uint32 uniU8SubZP_MulM_PStoF16Hi_2x8[16] = {
                0x99999999, // TCfg
                0x44444444, // ASelt
                0x0b0a0908, 0x0f0e0d0c, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000600, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            vx_uint32 uniF16MulF16_2x8[16] = {
                0x11111111, // TCfg
                0x00000000, // ASelt
                0x03020100, 0x07060504, // ABin
                0x11111111, // BSelt
                0x03020100, 0x07060504, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };
            vx_uint32 uniS16AddZP_2x8[16] = {
                0x55555555, // TCfg
                0x44444444, // ASelt
                0x03020100, 0x07060504, // ABin
                0xaaaaaaaa, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000400, // AccumType, ConstantType, and PostShift
                0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
            };
            uniU8SubZP_MulM_PStoF16Lo_2x8[7] |= postShift;
            uniU8SubZP_MulM_PStoF16Hi_2x8[7] |= postShift;

            for (idx = 8; idx < 16; idx ++)
            {
                uniU8SubZP_MulM_PStoF16Hi_2x8[idx] = uniU8SubZP_MulM_PStoF16Lo_2x8[idx] = (vx_uint32)(M0 << 16) | M0;
            }

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toF16_2d", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP_MulM_PStoF16Lo_2x8", 1, uniU8SubZP_MulM_PStoF16Lo_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniU8SubZP_MulM_PStoF16Hi_2x8", 1, uniU8SubZP_MulM_PStoF16Hi_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16MulF16_2x8", 1, uniF16MulF16_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniS16AddZP_2x8", 1, uniS16AddZP_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            if (status != VX_SUCCESS) goto OnError;

            execution_parameters.globalWorkScale[0]  = 16;
        }
        else
        {
            vx_uint32 uniConvertUint8SubZpToFp32_4x4[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00010000, 0x00030002, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002100, // AccumType, ConstantType, and PostShift
                0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000 // Constant
            };

            vx_uint32 uniConvertSecUint8SubZpToFp32_4x4[16] = {
                0x05050505, // TCfg
                0x04040404, // ASelt
                0x00050004, 0x00070006, // ABin
                0x0a0a0a0a, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00000100, // AccumType, ConstantType, and PostShift
                0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000, 0xbc003c00, 0x00000000 // Constant
            };

            uint32_t uniConvertInt32toUint8_2x8[16] = {
                0x33333333, // TCfg
                0x11110000, // ASelt
                0x03020100, 0x03020100, // ABin
                0x00000000, // BSelt
                0x00000000, 0x00000000, // BBin
                0x00002400, // AccumType, ConstantType, and PostShift
                0x00000000, 0x00000000, 0x00000000, 0x00000000,
                0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
            };

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_U8toF16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertUint8SubZpToFp32_4x4", 1, uniConvertUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSecUint8SubZpToFp32_4x4", 1, uniConvertSecUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputScale", 1, &input_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &inputZP);
            if (status != VX_SUCCESS) goto OnError;
        }
    }
    else if (srcFormat == VX_TYPE_FLOAT16)
    {
        vx_uint32 UniFP16Mul_dp2x8[16] = {
            0x11111111, // TCfg
            0x00000000, // ASelt
            0x03020100, 0x07060504, // ABin
            0x11111111, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvertDirInt16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertEndInt16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000,
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000,
            0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (dstFormat == VX_TYPE_FLOAT16)
        {
            if (enable_image_2d)
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_2d", borderMode);
                if (!shaderExecutable) goto OnError;
            }
            else
            {
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16", borderMode);
                if (!shaderExecutable) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16Mul_dp2x8", 1, UniFP16Mul_dp2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (dstFormat == VX_TYPE_INT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirInt16Fp32_4x4", 1, uniConvertDirInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &output_scale);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (dstFormat == VX_TYPE_UINT8)
        {
            output_scale = 1.0f / output_scale;

            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirInt16Fp32_4x4", 1, uniConvertDirInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &output_scale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (dstFormat == VX_TYPE_INT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertDirInt16Fp32_4x4", 1, uniConvertDirInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertEndInt16Fp32_4x4", 1, uniConvertEndInt16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &output_scale);
            if (status != VX_SUCCESS) goto OnError;
        }
    }

    if (enable_image_2d)
    {
        execution_parameters.workDim             = 2;
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width * height + execution_parameters.globalWorkScale[0] - 1)
            / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (depth + execution_parameters.globalWorkScale[1] - 1)
            / execution_parameters.globalWorkScale[1];
    }
    else
    {
        execution_parameters.globalWorkOffset[0] = 0;
        execution_parameters.globalWorkOffset[1] = 0;
        execution_parameters.globalWorkOffset[2] = 0;
        execution_parameters.globalWorkSize[0]   = gcmALIGN((width + execution_parameters.globalWorkScale[0] - 1)
            / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
        execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1)
            / execution_parameters.globalWorkScale[1];
        execution_parameters.globalWorkSize[2]   = depth;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 3);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources[0])
    {
        vxFree(programSources[0]);
        programSources[0] = NULL;
    }

    if (programSources[1])
    {
        vxFree(programSources[1]);
        programSources[1] = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

VX_PRIVATE_API vx_string _getShaderNameEx(vx_string orignal)
{
    vx_char* pointer = strrchr(orignal, '.');

    if (pointer)
    {
        gctSTRING suffix = strchr(pointer, ':');
        pointer = pointer + 1;
        if (suffix)
        {
            return suffix;
        }
        else
        {
            return pointer;
        }
    }

    return orignal;
}

vxnne_shader_executable vxnneGetUserShaderExecutable(
    vx_context                           context,
    vx_kernel                            kernel,
    vx_reference                         parameters[],
    vx_enum                              datatypes[],
    vx_uint32                            param_num,
    vx_uniform_s                         uniforms[],
    vx_uint32                            uniform_num,
    vx_border_mode_t *                   border_mode,
    vx_kernel_execution_parameters_t *   execution_params
    )
{
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders    kernelWrap;
    vx_uint32               i, kernelEnum;
    vx_status               status = VX_SUCCESS;

    gcmHEADER_ARG("context=%p, kernel=%p, parameters=%p, datatypes=%p, param_num=0x%x, uniforms=%p, uniform_num=%p, border_mode=%p, execution_params=%p",
         context, kernel, parameters, datatypes, param_num, uniforms, uniform_num, border_mode, execution_params);

    for (i = 1; i <= VXNNE_KERNEL_DYNAMIC_COUNT; i++)
    {
        kernelEnum = VXNNE_KERNEL_FIXED_COUNT + i;
        kernelWrap = &context->kernels[kernelEnum];
        if (!kernelWrap->kernelEnum) break;
    }

    if (i > VXNNE_KERNEL_DYNAMIC_COUNT)
    {
        status = VX_FAILURE;
        goto OnError;
    }

    kernelWrap->kernelName        = _getShaderNameEx(kernel->name);
    kernelWrap->kernelEnum        = kernelEnum;
    kernelWrap->paramNum          = param_num;
    kernelWrap->kernelShaderCount = kernel->kernelShaderCount;
    kernelWrap->kernelShader      = kernel->kernelShader;

    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernelWrap, VX_NULL, border_mode);
    if (!shaderExecutable) goto OnError;

    for (i = 0; i < uniform_num; i++)
    {
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, uniforms[i].name, uniforms[i].count, uniforms[i].data);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (param_num > 0)
    {
        status = vxnneShaderExecutable_SetParametersEx(shaderExecutable, parameters, datatypes, param_num);
        if (status != VX_SUCCESS) goto OnError;
    }

    if (execution_params != VX_NULL)
    {
        status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, execution_params);
        if (status != VX_SUCCESS) goto OnError;
    }

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcLayerNormalization****************************************************/
vxnne_shader_executable vxnneGetLayerNormShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input,
    vx_tensor               bias,
    vx_tensor               scale,
    vx_tensor               output,
    vx_scalar               eps)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference    parameters[5]              = {(vx_reference)input, (vx_reference)bias, (vx_reference)scale, (vx_reference)output, (vx_reference)eps};
    vx_uint32       dims                       = TENSOR_DIM_NUM(input) == 1 ? 2 : TENSOR_DIM_NUM(input);
    vx_uint32       width                      = TENSOR_VIEW_SIZE_INDEX(input, 0);
    vx_uint32       height                     = (dims > 1) ? TENSOR_VIEW_SIZE_INDEX(input, 1) : 1;
    vx_uint32       depth                      = (dims > 2) ? TENSOR_VIEW_SIZE_INDEX(input, 2) : 1;
    vx_enum         inputFormat                = TENSOR_DATA_TYPE(input);
    vx_enum         outputFormat               = TENSOR_DATA_TYPE(output);
    vx_int32        input_ZP                   = TENSOR_TF_ZEROPOINT(input);
    vx_int32        output_ZP                  = TENSOR_TF_ZEROPOINT(output);
    vx_float32      scaleIn                    = TENSOR_TF_SCALE(input);
    vx_float32      scaleOut                   = TENSOR_TF_SCALE(output);
    vx_float32      dimRatio                   = 1.0f / (vx_float32)width;
    vx_float32      reScaleOut_u8              = 0.f;
    vx_float32      reOutZP                    = 0.f;
    vx_uint32       iter                       = 0;
    vx_int32        sumInZp                    = 0;
    vx_int32        tmpZp1                     = 0;
    vx_int32        tmpZp2                     = 0;
    vx_float32      e2InScale                  = 0.f;
    char *programSources = NULL;

    if (dims > 2)
    {
        vxError("Error:Dimension not support in shader Layer normalization at function %s line %d", __FUNCTION__, __LINE__);
        goto OnError;
    }
    if (outputFormat == VX_TYPE_UINT8)
    {
        reScaleOut_u8 = 1.0f / scaleOut;
        reOutZP = (vx_float32)output_ZP;
    }
    iter = ((width + 15) / 16) * 16;
    sumInZp = input_ZP * iter * (-1);
    tmpZp1 = (-2) * input_ZP;
    tmpZp2 = iter * input_ZP * input_ZP;
    e2InScale = scaleIn * scaleIn;

    borderMode->mode = VX_BORDER_CONSTANT;
    borderMode->constant_value.U32 = 0;
    borderMode->constant_value.S16 = 0;
    borderMode->constant_value.U8 = 0;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LayerNorm, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LayerNorm.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        vxmONERROR(vxGetStatus((vx_reference)program));

        vxmONERROR(vxBuildProgram(program, "-cl-viv-vx-extension"));

        vxmONERROR_NULLPTR(kernel = vxnneAddKernelShadersInProgram(context, "vxcLayerNorm", program, 5, kernelEnum));

        vxReleaseProgram(&program);
    }
    {
        vx_uint32 uniFp16SumSqr_dp8x2[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0x76543210, // ABin
            0x5555aaaa, // BSelt
            0x00000000, 0x76543210, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 UniFP16toFP32Lo4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_dp4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniConvertSecFp16Fp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniSumU8_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001, 0x00010001 // Constant
        };
        vx_uint32 uniSqrSum_16x1[16] = {
            0x55555555, // TCfg
            0x00000000, // ASelt
            0x76543210, 0xfedcba98, // ABin
            0x55555555, // BSelt
            0x76543210, 0xfedcba98, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniConvert1stUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00010000, 0x00030002, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert2ndUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00050004, 0x00070006, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert3rdUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x00090008, 0x000b000a, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvert4thUint8SubZpToFp32_4x4[16] = {
            0x05050505, // TCfg
            0x04040404, // ASelt
            0x000d000c, 0x000f000e, // ABin
            0x0a0a0a0a, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000, 0xffff0001, 0x00000000 // Constant
        };
        vx_uint32 uniConvertInt32toUint8_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };

        if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16SumSqr_dp8x2", 1, uniFp16SumSqr_dp8x2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_dp4x4", 1, uniExtractHalf4_dp4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_UINT8 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_u8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertSecFp16Fp32_4x4", 1, uniConvertSecFp16Fp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSumU8_16x1", 1, uniSumU8_16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniSqrSum_16x1", 1, uniSqrSum_16x1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert1stUint8SubZpToFp32_4x4", 1, uniConvert1stUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert2ndUint8SubZpToFp32_4x4", 1, uniConvert2ndUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert3rdUint8SubZpToFp32_4x4", 1, uniConvert3rdUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvert4thUint8SubZpToFp32_4x4", 1, uniConvert4thUint8SubZpToFp32_4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "inputZP", 1, &input_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "output_ZP", 1, &output_ZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "input_scale", 1, &scaleIn);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &reScaleOut_u8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &reOutZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "sumInZp", 1, &sumInZp);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZp1", 1, &tmpZp1);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "tmpZp2", 1, &tmpZp2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "e2InScale", 1, &e2InScale);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (inputFormat == VX_TYPE_FLOAT16 && outputFormat == VX_TYPE_UINT8)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_fp16tou8", borderMode);
            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16SumSqr_dp8x2", 1, uniFp16SumSqr_dp8x2);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_dp4x4", 1, uniExtractHalf4_dp4x4);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &reScaleOut_u8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &reOutZP);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniConvertInt32toUint8_2x8", 1, uniConvertInt32toUint8_2x8);
            if (status != VX_SUCCESS) goto OnError;
        }
        else
        {
            vxError("Error:Not support data format in shader Layer normalization at function %s line %d", __FUNCTION__, __LINE__);
            goto OnError;
        }
        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "width", 1, &width);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "dimRatio", 1, &dimRatio);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "UniFP16toFP32Lo4_dp4x4", 1, UniFP16toFP32Lo4_dp4x4);
        if (status != VX_SUCCESS) goto OnError;
    }

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkOffset[2] = 0;
    execution_parameters.globalWorkScale[0]  = width;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkScale[2]  = 1;
    execution_parameters.globalWorkSize[0]   = 1;
    execution_parameters.globalWorkSize[1]   = gcmALIGN((height + execution_parameters.globalWorkScale[1] - 1)
        / execution_parameters.globalWorkScale[1], 4);
    execution_parameters.globalWorkSize[2]   = depth;

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, 5);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    return shaderExecutable;

OnError:
    if (program)  vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);
    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    return VX_NULL;
}

vxnne_shader_executable vxnneGetLSTMUnitLayerNormStateOutShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               inputs_conv,
    vx_float32              forget_bias,
    vx_tensor               cell_state_in,
    vx_tensor               biases,
    vx_tensor               layer_norm_weights,
    vx_tensor               output,
    vx_tensor               cell_state_out,
    vx_tensor               hidden_state_out,
    vx_bool                 enable_cifg,
    vx_float32              cell_clip
    )
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength = 0;
#endif
    vx_reference  parameters[7]   = {(vx_reference)inputs_conv, (vx_reference)cell_state_in, (vx_reference)biases, (vx_reference)layer_norm_weights, (vx_reference)output, (vx_reference)cell_state_out, (vx_reference)NULL};
    vx_kernel_execution_parameters_t execution_parameters = {2, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vxnne_kernel_shaders    kernel           = VX_NULL;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vx_program    program           = VX_NULL;
    vx_status     status            = VX_FAILURE;
    vx_enum       input_format      = TENSOR_DATA_TYPE(inputs_conv);
    vx_enum       cell_format       = TENSOR_DATA_TYPE(cell_state_in);
    vx_enum       output_format     = TENSOR_DATA_TYPE(output);
    vx_uint32     num_units         = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     batch_size        = TENSOR_VIEW_SIZE_INDEX(output, 1);
    vx_int8       dstFixPointPos    = TENSOR_POS(output);
    vx_uint32     paramNum          = 6;
    vx_float32    outputZP          = 0;
    vx_float32    outputScale       = 1.0f;
    vx_tensor     biases_rs         = NULL;
    char *programSources = NULL;

    gcmHEADER_ARG("context=%p, kernelEnum=0x%x, borderMode=%p, input_conv=%p, output=%p",
        context, kernelEnum, borderMode, inputs_conv, output);

    if (TENSOR_DIM_NUM(biases) == 1)
    {
        vx_int32 sizes[4] = {1};

        sizes[0]      = TENSOR_VIEW_SIZE_INDEX(biases, 0);
        sizes[1]      = 1;

        biases_rs     = vxoTensor_ReshapeTensor(biases, sizes, 2);

        parameters[2] = (vx_reference)biases_rs;
    }

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        outputScale = 1.0f / TENSOR_TF_SCALE(output);
        outputZP    = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (dstFixPointPos >= 0)
            outputScale *= (vx_float32)(1 << dstFixPointPos);
        else if (dstFixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
    }

    if (hidden_state_out)
        parameters[paramNum ++] = (vx_reference)hidden_state_out;

    borderMode->mode = VX_BORDER_REPLICATE;

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);
    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, LSTMUnitLayerNormStateOut, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/LSTMUnitLayerNormStateOut.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/

        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcLSTMUnit_LayerNorm", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input_format == VX_TYPE_FLOAT16)
    {
        vx_uint32  uint_min   = 0xFBFFFFFF;
        vx_uint32  uint_max   = 0x7BFFFFFF;
        vx_float32 float_min = *(vx_float32 *)&uint_min;
        vx_float32 float_max = *(vx_float32 *)&uint_max;
        vx_uint32 i        = 0;
        vx_float32     logE             = (vx_float32)(log10(exp(1.0f)) / log10(2.0f));
        vx_float32     twoLogE          = 2 * logE;
        vx_float32     clip_Min_F[4]    = {0};
        vx_float32     clip_Max_F[4]    = {0};
        vx_uint32 uniFp16toFp32_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf4_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00020000, 0x00060004, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        if (cell_format == VX_TYPE_FLOAT16)
        {
            if (enable_cifg)
            {
                if (output_format == VX_TYPE_FLOAT16)
                {
                    if (hidden_state_out)
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16_CIFG", borderMode);
                    else
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16_Projection_CIFG", borderMode);
                }
                else if (output_format == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F16_CIFG", borderMode);
                else if (output_format == VX_TYPE_INT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F16_CIFG", borderMode);
                else if (output_format == VX_TYPE_UINT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F16_CIFG", borderMode);

                if (!shaderExecutable) goto OnError;
            }
            else
            {
                if (output_format == VX_TYPE_FLOAT16)
                {
                    if (hidden_state_out)
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16", borderMode);
                    else
                        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F16_Projection", borderMode);
                }
                else if (output_format == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F16", borderMode);
                else if (output_format == VX_TYPE_INT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F16", borderMode);
                else if (output_format == VX_TYPE_UINT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F16", borderMode);

                if (!shaderExecutable) goto OnError;
            }

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf4_4x4", 1, uniExtractHalf4_4x4);
            if (status != VX_SUCCESS) goto OnError;
        }
        else if (cell_format == VX_TYPE_FLOAT32)
        {
            if (enable_cifg)
            {
                if (output_format == VX_TYPE_FLOAT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F32_Projection_CIFG", borderMode);
                else if (output_format == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F32_Projection_CIFG", borderMode);
                else if (output_format == VX_TYPE_INT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F32_Projection_CIFG", borderMode);
                else if (output_format == VX_TYPE_UINT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F32_Projection_CIFG", borderMode);

                if (!shaderExecutable) goto OnError;
            }
            else
            {
                if (output_format == VX_TYPE_FLOAT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toF16_CELL_F32_Projection", borderMode);
                else if (output_format == VX_TYPE_INT16)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI16_CELL_F32_Projection", borderMode);
                else if (output_format == VX_TYPE_INT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toI8_CELL_F32_Projection", borderMode);
                else if (output_format == VX_TYPE_UINT8)
                    shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16toU8_CELL_F32_Projection", borderMode);

                if (!shaderExecutable) goto OnError;
            }
        }

        if (output_format == VX_TYPE_FLOAT16)
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtract8Data_2x8", 1, uniExtractHalf8_2x8);
        else
            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtract8Data_2x8", 1, uniExtractInteger_2x8);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32_4x4", 1, uniFp16toFp32_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "num_units", 1, &num_units);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "logE", 1, &logE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "forget_bias", 1, &forget_bias);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "twoLogE", 1, &twoLogE);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
        if (status != VX_SUCCESS) goto OnError;

        if (cell_clip > 0)
        {
            float_max = cell_clip;
            float_min = -cell_clip;
        }

        for (i = 0; i < 4; i++)
        {
            clip_Min_F[i] = float_min;
            clip_Max_F[i] = float_max;
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "clip_Min_F", 1, clip_Min_F);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "clip_Max_F", 1, clip_Max_F);
        if (status != VX_SUCCESS) goto OnError;
    }

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkScale[0]  = 4;
    execution_parameters.globalWorkScale[1]  = 1;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((num_units + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (batch_size + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (biases_rs) vxoTensor_ReleaseTensor(&biases_rs);

    gcmFOOTER_ARG("%p", shaderExecutable);
    return shaderExecutable;

OnError:
    if (biases_rs) vxoTensor_ReleaseTensor(&biases_rs);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    gcmFOOTER_NO();
    return VX_NULL;
}

/********vxcTensor2DAdd****************************************************/
vxnne_shader_executable vxnneGetTensor2DAddShaderExecutable(
    vx_context              context,
    vx_enum                 kernelEnum,
    vx_border_mode_t        *borderMode,
    vx_tensor               input0,
    vx_tensor               input1,
    vx_int32                activation,
    vx_tensor               output)
{
#if !gcdUSE_VXC_BINARY
    vx_size    programLength    = 0;
#endif
    vx_program program = VX_NULL;
    vx_status  status = VX_FAILURE;
    vxnne_shader_executable shaderExecutable = VX_NULL;
    vxnne_kernel_shaders        kernel;

    vx_kernel_execution_parameters_t execution_parameters = {3, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}, {0, 0, 0}};
    vx_reference  parameters[4]         = {(vx_reference)input0, (vx_reference)input1, (vx_reference)output, (vx_reference)NULL};
    vx_uint32     dims                  = TENSOR_DIM_NUM(output);
    vx_uint32     width                 = TENSOR_VIEW_SIZE_INDEX(output, 0);
    vx_uint32     height                = dims > 1 ? TENSOR_VIEW_SIZE_INDEX(output, 1) : 1;
    vx_enum       input0_format         = TENSOR_DATA_TYPE(input0);
    vx_enum       input1_format         = TENSOR_DATA_TYPE(input1);
    vx_enum       output_format         = TENSOR_DATA_TYPE(output);
    vx_int8       dstFixPointPos        = TENSOR_POS(output);
    vx_float32    outputZP              = 0;
    vx_float32    outputScale           = 1.0f;
    vx_tensor     src0                  = NULL;
    vx_tensor     src1                  = NULL;
    vx_tensor     dst                   = NULL;
    vx_uint32     paramNum              = 3;

    char *programSources = NULL;

    borderMode->mode = VX_BORDER_REPLICATE;

    if (TENSOR_QUANT_TYPE(output) == VX_QUANT_AFFINE_SCALE)
    {
        outputScale = 1.0f / TENSOR_TF_SCALE(output);
        outputZP    = (vx_float32)TENSOR_TF_ZEROPOINT(output);
    }
    else if (TENSOR_QUANT_TYPE(output) == VX_QUANT_DYNAMIC_FIXED_POINT)
    {
        if (dstFixPointPos >= 0)
            outputScale *= (vx_float32)(1 << dstFixPointPos);
        else if (dstFixPointPos < 0)
            outputScale *= 1.0f / (vx_float32) (1 << -dstFixPointPos);
    }

    if (TENSOR_DIM_NUM(input0) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(input0, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        src0 = vxoTensor_ReshapeTensor(input0, sizes, dims);
        parameters[0] = (vx_reference)src0;
    }

    if (TENSOR_DIM_NUM(input1) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(input1, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        src1 = vxoTensor_ReshapeTensor(input1, sizes, dims);
        parameters[1] = (vx_reference)src1;
    }

    if (TENSOR_DIM_NUM(output) == 1)
    {
        vx_uint32 w         = TENSOR_VIEW_SIZE_INDEX(output, 0);
        vx_int32  sizes[4]  = {w, 1, 1, 1};

        dims = 2;

        dst = vxoTensor_ReshapeTensor(output, sizes, dims);
        parameters[2] = (vx_reference)dst;
    }

    kernel = vxnneGetKernelShadersByEnum(context, kernelEnum);

    if (!kernel)
    {
        /* register an shader kernel */
#if gcdUSE_VXC_BINARY
        vx_uint32 len;
        void * ptr = getVXCKernelInfo(context, Tensor2DAdd, &len);
        program = vxCreateProgramWithBinary(context, ptr, len);
#else
        char path[_vxcFILENAME_MAX];

        vxmONERROR(getFilePath("nnvxc_kernels/Tensor2DAdd.vx", path));

        vxmONERROR_NULLPTR(programSources = loadSources(path, &programLength));

        vxmONERROR_NULLPTR(program = vxCreateProgramWithSource(context, 1, (const vx_char**)&programSources, &programLength));

        if (programSources)
        {
            vxFree(programSources);
            programSources = NULL;
        }
#endif /*gcdUSE_VXC_BINARY*/
        status = vxGetStatus((vx_reference)program);
        if (status != VX_SUCCESS) goto OnError;

        status = vxBuildProgram(program, "-cl-viv-vx-extension");
        if (status != VX_SUCCESS) goto OnError;

        kernel = vxnneAddKernelShadersInProgram(context, "vxcTensor2DAdd", program, paramNum, kernelEnum);
        if (!kernel) goto OnError;

        vxReleaseProgram(&program);
    }

    if (input0_format == VX_TYPE_FLOAT16 && input1_format == VX_TYPE_FLOAT16 && output_format == VX_TYPE_FLOAT16)
    {
        vx_uint32 uniF16AddF16toF16_2x8[16] = {
            0x55555555, // TCfg
            0x44444444, // ASelt
            0x33221100, 0x77665544, // ABin
            0xaaaaaaaa, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00, 0x3c003c00 // Constant
        };

        shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16AddF16toF16", borderMode);
        if (!shaderExecutable) goto OnError;

        status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniF16AddF16toF16_2x8", 1, uniF16AddF16toF16_2x8);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
    }
    else if (input0_format == VX_TYPE_FLOAT16 && input1_format == VX_TYPE_FLOAT32)
    {
        vx_uint32 uniFp16toFp32Part0_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00010000, 0x00030002, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniFp16toFp32Part1_4x4[16] = {
            0x01010101, // TCfg
            0x00000000, // ASelt
            0x00050004, 0x00070006, // ABin
            0x02020202, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00004100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000, 0x00003c00, 0x00000000 // Constant
        };
        vx_uint32 uniExtractInteger_2x8[16] = {
            0x33333333, // TCfg
            0x11110000, // ASelt
            0x03020100, 0x03020100, // ABin
            0x00000000, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00002400, // AccumType, ConstantType, and PostShift
            0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 // Constant
        };
        vx_uint32 uniExtractHalf8_2x8[16] = {
            0x11111111, // TCfg
            0x11110000, // ASelt
            0x06040200, 0x06040200, // ABin
            0x22222222, // BSelt
            0x00000000, 0x00000000, // BBin
            0x00000100, // AccumType, ConstantType, and PostShift
            0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00, 0x00003c00 // Constant
        };

        if (output_format == VX_TYPE_FLOAT16)
        {
            shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16AddF32toF16", borderMode);
            if (!shaderExecutable) goto OnError;

            status = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractHalf8_2x8", 1, uniExtractHalf8_2x8);
            vxmONERROR_STATUS(status);
        }
        else
        {
            if (output_format == VX_TYPE_INT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16AddF32toI8", borderMode);
            else if (output_format == VX_TYPE_UINT8)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16AddF32toU8", borderMode);
            else if (output_format == VX_TYPE_INT16)
                shaderExecutable = vxnneKernelShaders_CreateShaderExecutable(kernel, "_F16AddF32toI16", borderMode);

            if (!shaderExecutable) goto OnError;

            status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniExtractInteger_2x8", 1, uniExtractInteger_2x8);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputScale", 1, &outputScale);
            status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "outputZP", 1, &outputZP);
            vxmONERROR_STATUS(status);
        }

        status  = vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32Part0_4x4", 1, uniFp16toFp32Part0_4x4);
        status |= vxnneShaderExecutable_SetUniform(shaderExecutable, "uniFp16toFp32Part1_4x4", 1, uniFp16toFp32Part1_4x4);
        vxmONERROR_STATUS(status);

        execution_parameters.globalWorkScale[0]  = 8;
        execution_parameters.globalWorkScale[1]  = 1;
    }

    execution_parameters.workDim             = 2;
    execution_parameters.globalWorkOffset[0] = 0;
    execution_parameters.globalWorkOffset[1] = 0;
    execution_parameters.globalWorkSize[0]   = gcmALIGN((width   + execution_parameters.globalWorkScale[0] - 1) / execution_parameters.globalWorkScale[0], SHADER_THREAD_COUNT);
    execution_parameters.globalWorkSize[1]   = (height + execution_parameters.globalWorkScale[1] - 1) / execution_parameters.globalWorkScale[1];

    status = vxnneShaderExecutable_SetParameters(shaderExecutable, parameters, paramNum);
    if (status != VX_SUCCESS) goto OnError;

    status = vxnneShaderExecutable_SetExecutionParameters(shaderExecutable, &execution_parameters);
    if (status != VX_SUCCESS) goto OnError;

    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);

    return shaderExecutable;

OnError:
    if (src0) vxoTensor_ReleaseTensor(&src0);
    if (src1) vxoTensor_ReleaseTensor(&src1);
    if (dst) vxoTensor_ReleaseTensor(&dst);
    if (program) vxReleaseProgram(&program);
    if (shaderExecutable) vxnneShaderExecutable_Destroy(shaderExecutable);

    if (programSources)
    {
        vxFree(programSources);
        programSources = NULL;
    }

    return VX_NULL;
}

